

* 表查询处理

前面的章节强调了DBMS的宏观架构设计问题。现在，我们开始了一连串讨论设计的章节，依次讨论DBMS的每个主要组件。
按照我们在第1.1节中的讨论，我们从系统的顶部开始讨论查询处理器，在随后的章节中，我们将向下移动到存储管理、事务和
实用工具。
  
关系查询处理器接受一个声明性的SQL语句，对其进行验证，将其优化为程序化的数据流执行计划，并（根据准入控制）代表客
户程序执行该数据流程序。然后，客户程序获取（"拉"）结果元组，通常是一次一个或小批量的。关系查询处理器的主要组成部分
如图1.1所示。在本节中，我们将关注查询处理器和存储管理器访问方法的一些非交易方面。一般来说，关系型查询处理可以被
看作是一个单用户、单线程的任务。并发控制是由系统的下层透明地管理的，如第5节所述。这条规则的唯一例外是当DBMS在
对缓冲池页面进行操作时必须明确地 "钉住 "和 "解除钉住"，以便在短暂的、关键的操作中保持在内存中，正如我们在第4.4.5
节讨论的那样。

在这一节中，我们重点讨论普通情况下的SQL命令： 数据操作语言（DML）语句包括SELECT、INSERT、UPDATE和DELETE
数据定义语言（DDL）语句，如CREATE TABLE和CREATE INDEX，通常不被查询优化器处理。这些语句通常在静态DBMS逻
辑中通过显式调用存储引擎和目录管理器（在第6.1节中描述）程序性地实现。一些产品已经开始优化一小部分DDL语句，我们
预计这种趋势将继续下去。
  
** 查询解析器和验证
给定一个SQL语句，SQL解析器的主要任务是：（1）检查查询是否正确指定,（2）解析名称和引用,（3）将查询转换成优化
器使用的内部格式，以及（4）验证用户是否被授权执行查询。一些DBMS将部分或全部安全检查推迟到执行时进行，但是,即使
在这些系统中，解析器仍然负责收集执行时安全检查所需的数据。

给定一个SQL查询，解析器首先考虑FROM子句中的每个表的引用。它将表名规范化为server.database.schema.table
形式的完全合格名称。这也被称为四部分名称。不支持跨越多个服务器的查询的系统只需要规范化为数据库.schema.table，而
每个DBMS只支持一个数据库的系统可以规范化为schema.table。这种规范化是必须的，因为用户有依赖于上下文的默认
值，允许在查询规范中使用单一的部分名称。有些系统支持一个表的多个名称，称为表别名，这些名称也必须用完全合格的表名
来代替。
   
在对表名进行规范化处理后，查询处理器会调用目录管理器来检查该表是否已在系统目录中注册。在这一步骤中，它也可以在内部
查询数据结构中缓存关于表的元数据。基于关于表的信息，它将使用目录来确保属性引用是正确的。属性的数据类型被用来驱动重
载功能表达式、比较运算符和常量表达式的消歧逻辑。例如，考虑表达式（EMP.salary * 1.15）< 75000。乘法函数和比较运
算符的代码，以及假定的数据类型和字符串 "1.15 "和 "75000 "的内部格式，将取决于EMP.salary属性的数据类型。这个
数据类型可以是一个整数，一个浮点数，或者一个 "货币 "值。其他标准的SQL语法检查也被应用，包括元组变量的一致使用，
通过集合运算符（UNION/INTERSECT/EXCEPT）组合的表的兼容性，聚合查询的SELECT列表中属性的使用，子查询的嵌套，
等等。

如果查询解析成功，下一个阶段是授权检查，以确保用户对查询中引用的表、用户定义的函数或其他对象有适当的权限（SELECT/
DELETE/INSERT/UPDATE）。一些系统在语句解析阶段执行完全的授权检查。然而，这并不总是可能的。例如，支持行级安全的
系统，在执行之前不能进行完全的安全检查，因为安全检查可能是依赖于数据值的。即使理论上授权可以在编译时进行静态验证，
将部分工作推迟到查询计划的执行时间也有好处。将安全检查推迟到执行时间的查询计划可以在用户之间共享，并且在安全变化时
不需要重新编译。因此，安全验证的某些部分通常被推迟到查询计划的执行。

在编译过程中，也可以对常量表达式进行约束检查。例如，一个UPDATE命令可能有一个SET EMP.salary = -1这样的子
句。如果一个完整性约束规定了工资的正值，那么这个查询甚至不需要执行。然而，将这项工作推迟到执行时进行，是很常见的。
如果一个查询解析并通过验证，那么查询的内部格式将被传递给查询重写模块进行进一步处理。

   
** 查询重写
查询重写模块，或称重写器，负责简化和规范查询，而不改变其语义。它只能依靠查询和目录中的元数据，而不能访问表中的数据。
尽管我们说的是 "重写 "查询，但大多数重写器实际上是对查询的内部表示进行操作，而不是对原始SQL语句文本进行操作。
查询重写模块通常会输出一个与输入时接受的内部格式相同的查询内部表示。
在许多商业系统中，重写器是一个逻辑组件，其实际实现是在查询解析的后期阶段或查询优化的早期阶段。例如，在DB2中，重
写器是一个独立的组件，而在SQL Server中，查询重写是作为查询优化器的一个早期阶段完成的。尽管如此,单独考虑重写器
还是很有用的，即使明确的架构边界并不存在于所有系统中。

1. 视图扩展： 处理视图是改写者的主要传统角色。对于每个出现在FROM子句中的视图引用，重写器从目录管理器中检索视图
   定义。然后重写查询，(1)用视图引用的表和谓词替换该视图，(2)用视图中表的列引用替换对该视图的任何引用。这个过程是
   递归应用的，直到查询完全通过表来表达，不包括视图。这种视图扩展技术，首先在INGRES[85]中为基于集合的QUEL语
   言提出，需要在SQL中注意正确处理重复消除、嵌套查询、NULL和其他棘手的细节[68]。
2. 常数算术评估： 查询重写可以简化常数算术表达：例如，R.x < 10+2+R.y被重写为R.x < 12+R.y。
3. 谓词的逻辑重写： 逻辑重写是根据WHERE子句中的谓词和常数来应用的。简单的布尔逻辑经常被应用来改善表达式和基于索
   引的访问方法的能力之间的匹配。例如，像NOT Emp.Salary > 1000000这样的谓词，可以改写为Emp.Salary<=
   1000000。这些逻辑重写甚至可以通过简单的可满足性测试来缩短查询的执行时间。例如，表达式Emp.salary < 75000
   AND Emp.salary > 1000000，可以被替换为FALSE。这可能允许系统在不访问数据库的情况下返回一个空的查询结果。不
   可满足的查询可能看起来不靠谱，但是请记住，谓词可能被 "隐藏 "在视图定义中，不为外部查询的作者所知。例如，上面的
   查询可能是由一个名为 "高管 "的视图上的低薪雇员查询产生的。不可满足的谓词也构成了Microsoft SQL Server并行
   安装中 "分区消除 "的基础：当一个关系通过范围谓词在磁盘卷上进行水平范围分区时，如果其范围分区谓词与查询谓词一起
   是不可满足的，那么查询就不需要在卷上运行。
   一个额外的、重要的逻辑重写使用谓词的反证性来诱导新的谓词R.x < 10 AND R.x = S.y，例如，建议添加额外的谓词
   "AND S.y < 10"。添加这些反转谓词增加了优化器在执行早期选择过滤数据的计划的能力，特别是通过使用基于索引的访问
   方法。
4. 语义优化： 在许多情况下，模式的完整性约束被存储在目录中，并可以用来帮助重写一些查询。这种优化的一个重要例子是消
   除多余的连接。当一个外键约束将一个表的一个列（例如，Emp.deptno）绑定到另一个表（Dept）时，就会产生这种情况。
   考虑到这样的外键约束，我们知道每个Emp正好有一个Dept，如果没有相应的Dept元组（父级），Emp元组就不可能存
   在。
   考虑一个连接这两个表但不使用Dept列的查询：
   #+begin_src sql
	SELECT Emp.name Emp.salary
	FROM Emp, Dept
	WHERE Emp.deptno = Dept.dno
   #+end_src
   这样的查询可以被重写，以删除Dept表（假设Emp.deptno被约束为非空），因此也可以删除连接。同样，这种看似不靠
   谱的情况经常通过视图自然产生。例如，一个用户可能在连接这两个表的视图EMPDEPT上提交一个关于雇员属性的查询。像
   Siebel这样的数据库应用程序使用非常宽的表，在底层数据库不支持足够宽度的表的情况下，他们使用多个表，在这些表上
   有一个视图。如果没有多余的连接消除，这种基于视图的宽表实现将表现得非常糟糕。
   当表上的约束与查询谓词不兼容时，语义优化也可以完全规避查询的执行。
5. 子查询扁平化和其他启发式重写： 查询优化器是当前一代商业DBMS中最复杂的组件之一。为了保持这种复杂性，大多数优
   化器在单独的SELECTFROM-WHERE查询块上进行操作，而不是跨块优化。因此，与其让查询优化器进一步复杂化，许多系统
   将查询重写成更适合优化器的形式。这种转变有时被称为查询规范化。一类规范化的例子是将语义等同的查询重写成规范的形
   式，以确保语义等同的查询将被优化，产生相同的查询计划。另一个重要的启发式方法是在可能的情况下对嵌套的查询进行扁平
   化处理，以最大限度地为查询优化器的单块优化提供机会。由于重复语义、子查询、NULL和相关性等问题，这在SQL的某
   些情况下是非常棘手的[68, 80]。在早期，子查询扁平化是一种纯粹的启发式重写，但是现在一些产品将重写的决定建立在基
   于成本的分析之上。其他的重写也可以跨查询块进行。例如，谓词转义可以允许谓词在子查询中被复制[52]。扁平化相关的子
   查询对于在并行架构中实现良好的性能尤为重要：相关的子查询会导致跨查询块的 "嵌套循环 "式比较，尽管有并行资源，但
   会使子查询的执行串行化。


** 查询优化器
查询优化器的工作是将内部查询表示转化为执行查询的有效查询计划（图4.1）。一个查询计划可以被认为是一个数据流图，它
通过查询运算符的图形来输送表的数据。在许多系统中，查询首先被分解成SELECT-FROM-WHERE查询块。然后使用类似于
Selinger等人关于System R优化器的著名论文[79]中所描述的技术，对每个单独的查询块进行优化。完成后，通常会在每
个查询块的顶部添加一些运算符作为后处理，以计算GROUP BY、ORDER BY、HAVING和DISTINCT条款（如果存在）。然
后，不同的块会以一种直接的方式拼接起来。

产生的查询计划可以用多种方式表示。最初的System R原型将查询计划编译成机器代码，而早期的INGRES原型则产生了一
个可解释的查询计划。INGRES的作者在80年代初的回顾性论文[85]中把查询解释列为一个 "错误"，但摩尔定律和软件工程
在一定程度上证明了INGRES的决定。具有讽刺意味的是，编译成机器码被System R项目的一些研究人员列为一个错误。当
System R的代码库被制作成商业DBMS系统（SQL/DS）时，开发团队的第一个改变是用解释器取代机器码执行器。
    
[[./images/ntzGqQ.png]]

为了实现跨平台的可移植性，现在每个主要的DBMS都将查询编译成某种可解释的数据结构。它们之间唯一的区别是中间形式的
抽象程度。一些系统中的查询计划是一个非常轻量级的对象，与关系代数表达式不一样，它被注释为访问方法、连接算法等的名
称。其他系统使用较低级别的 "op-code"语言，在形式上更接近于Java字节码而不是关系代数表达式。为了讨论的简单性，
我们在本文的其余部分着重于代数式的查询表示。

尽管Selinger的论文被广泛认为是查询优化的 "圣经"，但它只是初步研究。所有的系统都在许多方面大大扩展了这项工作。
其中主要的扩展是：
1. 计划空间： System R优化器通过只关注 "left-deep"查询计划（其中连接的右侧输入必须是基表）和 "推迟笛卡尔产品
   "（确保笛卡尔积只出现在数据流的所有连接之后），在一定程度上限制了其计划空间。在今天的商业系统中，众所周知，
   "bushy "树（with nestsed right-hand inputs）和早期使用笛卡尔积在某些情况下是有用的。因此，在某些情况下，
   大多数系统都会考虑这两个选项。
2. 选择性估计： Selinger论文中的选择性估计技术是基于简单的表格和索引cardinalities，以目前一代系统的标准来
   看是幼稚的。今天，大多数系统通过直方图和其他汇总统计来分析和总结属性中的值的分布。由于这涉及到访问每一列中的每
   一个值，它可能是相对昂贵的。因此，一些系统使用抽样技术来获得对分布的估计，而不需要进行详尽的扫描。
   基表连接的选择性估计可以通过 "连接 "连接列的直方图来实现。为了超越单列直方图，最近有人提出了更复杂的方案，以
   纳入列之间的依赖关系等问题[16，69]。这些创新已经开始出现在商业产品中，但没有很大的进展。这些方案采用缓慢的原
   因之一是许多行业基准中长期存在的缺陷：像TPC-D和TPC-H这样的基准中的数据生成器在列中生成统计学上独立的值，
   因此不鼓励采用处理 "真实 "数据分布的技术。这个基准缺陷已经在TPC-DSbenchmark[70]中得到解决。尽管采用率很
   慢，但改进的选择性估计的好处被广泛认可。Ioannidis和Christodoulakis指出，在优化的早期，选择性的错误会在
   计划树上成倍地传播，并导致随后的估计变得糟糕[45]。
3. 搜索算法： 一些商业系统，特别是微软和Tandem的系统，抛弃了Selinger的动态编程优化方法，而采用了基于
   Cascades[25]中使用的技术的为 "自上而下 "搜索方案。自上而下的搜索在某些情况下可以降低优化器所考虑的计划数量
   [82]，但也会产生增加优化器内存消耗的负面效果。如果实际的成功是质量的标志，那么自上而下搜索和动态编程之间的选
   择是不相关的。每种方法在最先进的优化器中都表现得很好，而且两者都有运行时间和内存需求，不幸的是，它们都是查询中
   表的数量的指数级的。
   一些系统对于有 "太多 "表的查询会退回到启发式搜索方案。虽然随机查询优化启发式的研究文献很有趣[5, 18, 44, 84]
   ，但商业系统中使用的启发式往往是专有的，而且显然与随机查询优化文献不一样。一个有教育意义的练习是检查开源
   MySQL引擎的查询 "优化器"，在最后一次检查中，它完全是启发式的，主要依靠利用索引和键/外键约束。这让人想起早期
   （也是臭名昭著的）的Oracle版本。在一些系统中，只有当用户明确指示优化器如何选择计划（通过嵌入在SQL中的所
   谓优化器 "提示"），才能执行FROM子句中有太多表的查询。
4. 并行性： 今天，每一个主要的商业DBMS都对并行处理有一些支持。大多数还支持 "查询内 "的并行性：通过使用多个处
   理器来加快单个查询的能力。查询优化器需要参与确定如何安排运算符和并行运算符--跨越多个CPU，以及（在无共享或共
   享磁盘的情况下）跨越多个独立的计算机。Hong和Stonebraker[42]选择了避免并行优化的复杂性问题，并使用两个阶
   段：首先调用传统的单系统优化器来选择最佳的单系统计划，然后在多个处理器或机器上安排这个计划。关于这第二个优化阶
   段的研究已经发表[19, 21]，尽管不清楚这些结果在多大程度上影响了当前的实践。
   一些商业系统实现了上述的两阶段方法。其他系统则试图对集群网络拓扑结构和整个集群的数据分布进行建模，以便在单一阶
   段产生一个最佳计划。虽然在某些情况下，单阶段方法可以产生更好的计划，但目前还不清楚使用单阶段方法可能产生的额外
   查询计划质量是否能证明额外的优化器复杂性。因此，许多当前的实现仍然倾向于两阶段的方法。目前，这个领域似乎更像是
   艺术而不是科学。Oracle OPS（现在叫RAC）共享磁盘集群使用两阶段优化器。IBM DB2并行版（现在称为DB2数据库
   分区功能）最初是使用两相优化器实现的，但后来一直在向单阶段实现发展。
5. 自动调整： 各种正在进行的工业研究工作试图提高DBMS自动做出调整决定的能力。其中一些技术是基于收集查询的工作
   量，然后使用优化器通过各种 "假设 "分析来找到计划成本。例如，如果存在其他的索引，或者数据的布局不同，会怎么样
   正如Chaudhuri和Narasayya[12]所描述的，一个优化器需要在一定程度上进行调整，以有效地支持这一活动。Markl
   等人[57]的学习优化器（LEO）工作也是这个思路。


*** 关于查询编译和重新编译的说明
SQL支持 "准备 "查询的能力：通过解析器、重写器和优化器，存储所产生的查询执行计划，并在随后的 "执行"语句中使用
它。这甚至可以用于动态查询（例如来自网络表单），这些动态查询有程序变量来代替查询常量。唯一的问题是，在选择性估
计期间，由表单提供的变量被优化器假定为 "典型 "值。当选择非代表性的 "典型 "值时，可能会导致极差的查询执行计划。
查询准备对于表单驱动的、对相当可预测的数据进行的罐装查询特别有用：查询是在编写应用程序时准备的，而应用程序上线
时，用户不会经历解析、重写和优化的开销。

虽然在编写应用程序时准备查询可以提高性能，但这是一个非常局限的应用模式。许多应用程序员以及Ruby on Rails这样
的工具包在程序执行过程中动态构建SQL语句，所以预编译是不可能的。由于这种情况非常普遍，DBMS将这些动态查询执行
计划存储在查询计划缓存中。如果随后提交相同（或非常相似）的语句，就会使用缓存的版本。这种技术接近于预编译的静态
SQL的性能，没有应用模型的限制，并且被大量使用。

随着数据库的变化，经常需要重新优化准备好的计划。至少，当一个索引被放弃时，任何使用该索引的计划都必须从存储的计划
缓存中删除，以便在下次调用时选择一个新的计划。

其他关于重新优化计划的决定更加微妙，并且暴露了供应商之间的哲学区别。一些供应商（例如，IBM）非常努力地工作，以牺
牲每次调用的最佳性能为代价，提供跨调用的可预测性能。因此，他们不会重新优化一个计划，除非它不再执行，就像删除的索
引的情况。其他供应商（例如微软）则非常努力地使他们的系统自我调整，并且会更积极地重新优化计划。例如，如果一个表的
cardinality发生了重大变化，在SQL Server中就会触发重新编译，因为这种变化可能会影响索引和连接顺序的最佳使
用。可以说，自调谐系统的可预测性较低，但在动态环境中更有效率。

这种哲学上的区别产生于这些产品的历史客户群的不同。IBM传统上专注于拥有熟练DBA和应用程序员的高端客户。在这些高
预算的IT商店中，数据库的可预测性能是最重要的。在花了几个月的时间调整数据库设计和设置后，DBA不希望优化器不可
预测地改变它。相比之下，微软战略性地在低端进入数据库市场。因此，他们的客户往往拥有较低的IT预算和专业知识，并
希望DBMS能够尽可能地 "自我调整"。

随着时间的推移，这些公司的业务战略和客户基础已经趋于一致，因此它们直接竞争，而且它们的方法也在共同发展。微软有大
规模的企业客户，他们需要完全的控制和查询计划的稳定性。而IBM有一些没有DBA资源的客户需要完全自动管理。


** 查询执行器
查询执行器在一个完全指定的查询计划上运行。这通常是一个有向数据流图，它连接了封装基表访问和各种查询执行算法的操作符。
在一些系统中，这个数据流图已经被优化器编译成了低级别的操作代码。在这种情况下，查询执行器基本上就是一个运行时解释器。
在其他系统中，查询执行器接收数据流图的表示，并根据图的布局递归地调用操作程序。我们专注于后一种情况，因为操作码方法
基本上是将我们在这里描述的逻辑编译成一个程序。

[[./images/EBKmUE.png]]

大多数现代查询执行器采用了最早的关系型系统中使用的迭代器模型。迭代器可以用面向对象的方式简单描述。图4.2显示了一
个迭代器的简化定义。每个迭代器指定其输入，定义数据流图中的边。查询计划中的所有操作者，即数据流图中的节点，都是作为
迭代器类的子类来实现的。在一个典型的系统中，子类的集合可能包括文件扫描、索引扫描、排序、嵌套循环连接、合并连接、哈
希连接、重复消除和分组聚合。迭代器模型的一个重要特征是，任何迭代器的子类都可以被用作任何其他迭代器的输入。因此，每
个迭代器的逻辑都独立于它在图中的子代和父代，而且不需要为迭代器的特殊组合编写特殊情况代码。

Graefe在他的查询执行调查中提供了更多关于迭代器的细节[24]。我们也鼓励感兴趣的读者研究一下开源的PostgreSQL代
码库。PostgreSQL对大多数标准查询执行算法的迭代器进行了适度复杂的实现。

*** 迭代器讨论
迭代器的一个重要属性是它们将数据流和控制流结合起来。get_next()调用是一个标准的过程调用，它通过调用堆栈向调用者
返回一个元组引用。因此，当控制权被返回时，一个元组被返回到图中的一个父级。这意味着只需要一个DBMS线程来执行整
个查询图，而且不需要队列或迭代器之间的速率匹配。这使得关系型查询执行器易于实现和调试，并与其他环境中的数据流架构
形成对比。例如，网络依靠各种协议在并发的生产者和消费者之间进行排队和反馈。
单线程迭代器架构对于单系统（非集群）查询的执行也相当有效。在大多数数据库应用中，性能指标的优点是完成查询的时间，
但其他优化目标也是可能的。例如，最大限度地提高DBMS的吞吐量是另一个合理的目标。另一个受交互式应用欢迎的目标是到
达第一行的时间。在单处理器环境中，当资源被完全利用时，一个给定的查询计划的完成时间就会实现。在一个迭代器模型中，
由于其中一个迭代器总是处于活动状态，所以资源的利用率是最大化的。
正如我们之前提到的，大多数现代DBMS支持并行查询执行。幸运的是，这种支持可以在基本上不改变迭代器模型或查询执行
架构的情况下提供。并行性和网络通信可以被封装在特殊的交换迭代器中，正如Graefe[23]所描述的那样；这些迭代器也实
现了网络式的数据 "推送"，而DBMS的迭代器是看不见的，它保留了一个 "拉 "式的get_next()API。一些系统在其查询
执行模型中也明确了推送逻辑。

*** 数据存储位置
我们对迭代器的讨论很方便地回避了任何关于运行中数据的内存分配问题。我们既没有说明元组是如何存储在内存中的，也没有
说明它们是如何在迭代器之间传递的。在实践中，每个迭代器都预先分配了固定数量的元组描述符，一个用于其输入，一个用于
其输出。一个元组描述符通常是一个列引用数组，其中每个列引用是由对内存中其他地方的元组的引用和该元组中的一个列偏移
组成的。基本的迭代器超类逻辑从不动态地分配内存。这就提出了一个问题：实际被引用的元组在内存中存储在哪里。

对这个问题有两个可能的答案。第一个是元组驻留在缓冲池的页面中。如果一个迭代器构建了一个引用BP-元组的元组描述符，
它必须增加元组页面的pin计数--对该页面上元组的有效引用数量的计数。当元组描述符被清空时，它将减少pin计数。
第二种可能性是，迭代器的实现可以为内存堆上的元组分配空间。我们称之为M-tuple。迭代器可以通过从缓冲池中复制列来
构造一个M元组（该复制由pin增减对括起来），和/或通过评估查询规范中的表达式（例如，像 "EMP.sal ∗ 0.1 "的
算术表达式）。

一个一般的方法是总是将数据从缓冲池中立即复制到M-元组中。这种设计使用M元组作为唯一的机上元组结构，并简化了执
行者的代码。这个设计也规避了因缓冲池的pin和 unpin调用被长时间执行（和许多行代码）隔开而产生的错误。这类常见
的错误是忘记了完全解压页面（一个 "缓冲区泄漏"）。不幸的是，正如第4.2节所指出的，独占使用M元组可能是一个主要
的性能问题，因为内存拷贝通常是高性能系统的一个严重瓶颈。

另一方面，在某些情况下，构造一个M-tuple是有意义的。只要BP-元组被迭代器直接引用，BP-元组所在的页面就必须在
缓冲池中保持钉住。这消耗了缓冲池的一页内存，并且束缚了缓冲区替换策略的。如果一个元组将在很长一段时间内继续被引用，
那么将该元组从缓冲池中复制出来可能是有益的。这个讨论的结果是，最有效的方法是支持可以同时引用BP元组和M元组的
元组描述符。

*** 数据修改声明
到此为止，我们只讨论了查询，也就是只读的SQL语句。还有一类修改数据的DML语句存在： INSERT, DELETE, 和
UPDATE语句。这些语句的执行计划通常看起来像简单的直线查询计划，有一个单一的访问方法作为源，并在管道的末端有一个
数据修改操作者。

然而，在某些情况下，这些计划既查询又修改同一数据。这种对同一张表的读写混合（可能是多次）需要注意。一个简单的例子
是臭名昭著的 "万圣节问题"，2 因为它是由System R小组在10月31日发现的。万圣节问题是由 "给工资低于2万
美元的人加薪10%"这样的语句的特殊执行策略引起的。这个查询的原始计划是将Emp.salary字段的索引扫描迭代器输送到
更新迭代器中（图4.3的左侧）。这种管道化提供了良好的I/O定位，因为它在从B+树上获取图元后就对其进行修改。然
而，这种流水线也会导致索引扫描 "重新发现 "以前修改过的元组，该元组在修改后在树中向右移动，从而导致每个雇员被多次
提升。在我们的例子中，所有的低薪员工都会收到重复加薪，直到他们的收入超过2万美元。这不是原来的本意。


[[./images/rcrhdU.png]]

SQL语义学禁止这种行为：单个SQL语句不允许 "看到 "自己的更新。为了确保这个可见性规则被遵守，需要一些小心。一
个简单、安全的实现是让查询优化器选择避免更新列上索引的计划。在某些情况下，这可能是相当低效的。另一种技术是使用批
量读-然后写的方案。这在数据流中的索引扫描和数据修改操作之间插入了记录-ID物化和获取操作（图4.3的右侧）。物化操
作者接收所有要修改的元组的ID，并将其存储在临时文件中。然后，它扫描临时文件，通过RID获取每个物理元组的ID，并
将得到的元组反馈给数据修改操作者。如果优化器选择了一个索引，在大多数情况下，这意味着只有少数元组被改变。因此，这种
技术表面上的低效率可能是可以接受的，因为临时表可能完全保留在缓冲池中。管道式更新方案也是可能的，但需要存储引擎对
多版本的支持（有点奇怪）[74]。

*** 访问方法
访问方法是管理对系统支持的各种基于磁盘的数据结构的访问的程序。这些通常包括无序的文件（"堆"），以及各种索引。所有
主要的商业系统都实现了堆和B+树索引。Oracle和PostgreSQL都支持用于平等查询的哈希索引。一些系统开始引入对多
维索引的基本支持，比如R-树[32]。PostgreSQL支持一种叫做通用搜索树（GiST）的可扩展索引[39]，目前使用它来实现
多维数据的R树，以及文本数据的RD树[40]。IBM UDB第8版引入了多维聚类（MDC）索引，用于通过多维的范围访问数
据[66]。针对以读为主的数据仓库工作负载的系统通常也包括专门的位图变体索引[65]，我们在第4.6节中描述了这一点。

一个访问方法提供的基本API是一个迭代器API。init()例程被扩展为接受一个 "搜索参数"（或者用System R的术语
来说，是一个SARG），其形式为列操作符常数.ANULL SARG被视为一个扫描表中所有元组的请求。当没有更多的元组满足
搜索参数时，访问方法层的get_next()调用返回NULL。

有两个原因要把SARG传递到访问方法层。第一个原因应该很清楚：像B+树这样的索引访问方法需要SARG，以便有效地运
行。第二个原因是一个更微妙的性能问题，但它也适用于堆扫描和索引扫描。假设SARG是由调用访问方法层的例程检查的。
那么每次访问方法从get_next()返回时，它必须(a)返回驻留在缓冲池中某一帧的元组的句柄，并在该帧中钉住页面以避免
替换，或者(b)对该元组进行复制。如果调用者发现SARG没有得到满足，它就负责(a)减少该页的引脚数，或者(b)删除复制
的元组。然后它必须重新调用get_next()来尝试页面上的下一个元组。这种逻辑在函数调用/返回对中消耗了大量的CPU周
期，并且会不必要地钉住缓冲池中的页面（产生不必要的缓冲帧争夺），或者不必要地创建和销毁元组的副本--当流过数百万元
组时，这是一个重要的CPU开销。请注意，一个典型的堆扫描将访问一个给定页面上的所有图元，导致每个页面的这种互动的
多次迭代。相比之下，如果所有这些逻辑都是在访问方法层完成的，那么通过一次测试一个页面的SARG，并且只从满足SARG
的元组的get_next()调用中返回，就可以避免重复的调用/返回和pin/unpin或copy/delete的配对。SARGS在存储
引擎和关系引擎之间保持了一个干净的架构边界，同时获得了出色的性能。因此，许多系统支持非常丰富的SARG支持，并广泛
使用它们。从主题上讲，这是一个标准的DBMS智慧的实例，即在一个集合中的多个项目中摊派工作，但在这种情况下，它被应
用于CPU性能，而不是磁盘性能。

Oracle通过允许行跨越页面来避免在堆文件中移动行。因此，当一个行被更新为一个较长的值，不再适合在原来的页面上，而
不是被迫移动该行，他们存储适合在原来页面上的内容，其余的可以跨越到下一个页面。与所有其他迭代器相比，访问方法与围
绕事务的并发和恢复逻辑有很深的互动，如第4节所述。

*** 数据仓库
数据仓库--用于决策支持的大型历史数据库，定期加载新的数据--已经发展到需要专门的查询处理支持，在下一节中，我们将调
查它们往往需要的一些关键特征。这个话题之所以相关，主要有两个原因：

1. 数据仓库是DBMS技术的一个非常重要的应用。有人声称，仓库占所有DBMS活动的1/3。

2. 本节到目前为止讨论的传统查询优化和执行引擎在数据仓库上的工作并不顺利。因此，需要进行扩展或修改以实现良好的性
   能。

关系型数据库管理系统最早是在20世纪70年代和80年代设计的，以满足商业数据处理应用的需要，因为这是当时的主导
要求。在20世纪90年代初，出现了数据仓库和 "商业分析 "的市场，并从那时起急剧增长。

到20世纪90年代，在线交易处理（OLTP）已经取代了批量商业数据处理，成为数据库使用的主导模式。此外，大多数
OLTP系统的计算机操作员都是通过与终端客户的电话交谈或通过执行纸张上的数据输入来提交交易。自动柜员机已经很普遍，
允许客户直接进行某些互动，而不需要操作员的干预。这类交易的响应时间对生产力至关重要。今天，这种响应时间的要求变得
更加紧迫和多样，因为网络正在迅速取代操作员，由终端客户提供自助服务。

大约在同一时间，零售领域的企业有了捕捉所有历史销售交易的想法，并将它们通常存储一到两年。这样的历史销售数据可以被
买家用来弄清楚 "什么是热的，什么是不热的"。这样的信息可以被利用来影响购买模式。同样，这样的数据可以用来决定哪些
商品要促销，哪些商品要打折，哪些商品要送回给制造商。当时的普遍看法是，零售领域的历史数据仓库在几个月内就能通过更
好的库存管理、货架和商店布局来支付其费用。

当时很清楚，数据仓库应该部署在与OLTP系统分开的硬件上。使用这种方法，冗长的（而且往往是不可预测的）商业智能查
询不会破坏OLTP的响应时间。另外，数据的性质是非常不同的；仓库处理的是历史，OLTP处理的是 "现在"。最后，人们发
现，历史数据所需的模式往往与当前数据所需的模式不一致，需要进行数据转换，从一个转换到另一个。

由于这些原因，工作流程系统被建造出来，从OLTP系统中 "刮取 "数据并将其加载到数据仓库中。这种系统被称为 "提取、
转换和加载"（ETL）系统。流行的ETL产品包括IBM的Data Stage和Informatica的PowerCenter。在过去的
十年中，ETL供应商通过数据清洗工具、去重工具和其他面向质量的产品来扩展他们的产品。

在数据仓库环境中，有几个必须处理的问题，我们在下面讨论。

**** 位图索引
B+树为快速插入、删除和更新记录进行了优化。相比之下，数据仓库执行初始加载，然后数据在几个月或几年内都是静态的。
此外，数据仓库经常有一些数值较少的列。例如，考虑存储一个客户的性别。只有两个值，这可以用位图中每条记录的一个位
来表示。相比之下，B+tree对每条记录都需要（值，记录-指针）对，通常每条记录会消耗40比特。

位图对于共轭过滤器也很有利，比如Customer.sex = "F" and Customer.state = "California" 在这种情况下，
结果集可以通过位图的交叉来确定。有许多更复杂的位图算法技巧，可以用来提高普通分析查询的性能。关于位图处理的讨论
感兴趣的读者应该参考[65]。

在目前的产品中，位图索引是对Oracle中的B+树的补充，用于索引存储数据，而DB2提供了一个更有限的版本。
Sybase IQ大量使用了位图索引。当然，位图的缺点是，它们的更新成本很高，所以它们的效用仅限于仓库环境。

**** 快速加载
通常情况下，数据仓库是在半夜加载当天的交易数据。这对于只在白天营业的零售机构来说是一个明显的策略。大量夜间加载
的第二个原因是为了避免在用户互动期间出现更新。考虑到一个业务分析员希望制定某种特别的查询，也许是为了调查飓风对
客户购买模式的影响。这个查询的结果可能会建议一个后续的查询，比如调查大风暴期间的购买模式。这两个查询的结果应该
是兼容的，也就是说，答案应该是在同一个数据集上计算的。如果数据被同时加载，这对包括最近历史的查询来说可能是有问
题的。

因此，数据仓库能够快速批量加载是非常关键的。尽管人们可以用一连串的SQL插入语句来编程仓库加载，但这种策略在实
践中从未被使用。取而代之的是利用批量加载器，将大量的记录流向存储，而没有SQL层的开销，并利用特殊的批量加载方
法，如B+树的访问方法。从整数上看，批量加载器比SQL插入快一个数量级，所有主要供应商都提供高性能的批量加载器。

随着世界转向电子商务和每天24小时的销售，这种批量装载的策略就不那么合理了。但是向 "实时 "仓库的转移有几个问
题。首先，无论是来自批量加载器还是来自交易的插入，都必须设置写锁，正如第6.3节中所讨论的。这些锁与查询获得的
读锁相冲突，并可能导致仓库 "冻结"。第二，如上所述，在各查询集之间提供兼容的答案是有问题的。

这两个问题都可以通过避免原地更新和提供历史查询来规避。如果我们保留了更新的前后值，并附上适当的时间戳，那么我们
就可以提供最近一段时间的查询。在相同的历史时间内运行一系列的查询将提供兼容的答案。此外，同样的历史查询可以在不
设置读锁的情况下运行。

正如第5.2.1节所讨论的，一些供应商，特别是Oracle提供了像SNAPSHOT ISOLATION这样的多版本（MVCC）隔
离级别。随着实时仓库变得越来越流行，其他供应商大概也会效仿。

**** 物化视图
数据仓库通常是巨大的，连接多个大表的查询有一种 "永远运行 "的趋势。为了加快常用查询的性能，大多数供应商提供物
化视图。与本节前面讨论的纯逻辑视图不同，物化视图是可以被查询的实际表，但它对应于真正的 "基础 "数据表的逻辑视图
表达。对物化视图的查询将避免在运行时执行视图表达式中的连接。相反，随着更新的进行，物化视图必须保持最新的状态。

物化视图的使用有三个方面：（a）选择要物化的视图，（b）保持视图的新鲜度，以及（c）考虑在临时查询中使用物化视图。
（a）是我们在第4.3节中提到的自动数据库调整的一个高级方面。(c)在不同的产品中都有不同程度的实现；即使对于
简单的单块查询，这个问题在理论上也是具有挑战性的[51]，对于带有聚合和子查询的通用SQL更是如此。对于(b)，大多
数供应商提供了多种刷新技术，从在每次更新物化视图的表时执行物化视图更新，到定期丢弃然后重新创建物化视图。这种策
略在运行时间开销和物化视图的数据一致性之间进行了权衡。

**** OLAP和临时查询支持
一些仓库工作负载有可预测的查询。例如，在每个月的月底，可能会运行一个总结报告，提供一个零售连锁店的每个销售区域
的部门的总销售额。在这一工作负载中穿插着由业务分析员临时制定的临时查询。

很明显，可预测的查询可以由适当构建的物化视图来支持。更为普遍的是，由于大多数商业分析查询都要求汇总，我们可以计
算出一个物化视图，它是每个商店的部门的总销售额。然后，如果上述区域查询被指定，它可以通过 "滚动 "每个区域的各
个商店来满足。

这种聚合通常被称为数据立方体，是一类有趣的物化视图。在20世纪90年代早期，Essbase等产品提供了定制的工具，
用于以优先立方体格式存储数据，同时提供基于立方体的用户界面来浏览数据，这种能力被称为在线分析处理（OLAP）。随着
时间的推移，数据立方体的支持已经被添加到全功能的关系数据库系统中，并且通常被称为关系型OLAP（ROLAP）。许多提
供ROLAP的DBMS已经发展到在内部实现一些特殊情况下的早期OLAP式存储方案，因此有时被称为HOLAP（混合
OLAP）方案。

很明显，数据立方体为可预测的、有限的一类查询提供了高性能。然而，它们通常无助于支持临时性的查询。

**** 雪花模式查询的优化
许多数据仓库遵循一种特定的模式设计方法。具体来说，它们存储了一系列事实，在零售环境中，这些事实通常是简单的记
录，如 "客户X在T时间从Z商店购买了Y产品"。一个中央事实表记录了每个事实的信息，如购买价格、折扣、销售
税信息等。在事实表中，还有一组维度的外键。维度可以包括客户、产品、商店、时间等。这种形式的模式通常被称为星形模
式，因为它有一个中央事实表，周围有维度，每个维度与事实表有1-N个主键-外键关系。在实体关系图中，这种模式是星
形的。

许多维度是自然分层的。例如，如果商店可以被汇总到区域中，那么商店 "维度表 "就有一个添加到区域维度表中的外键。
类似的层次结构对于涉及到时间（月/日/年）、管理层次等的属性是很典型的。在这些情况下，会产生一个多层次的星形或
雪花模式。

基本上所有的数据仓库查询都需要在雪花模式中对这些表中的一些属性进行过滤，然后将结果连接到中央事实表，通过事实表
或维度表中的一些属性进行分组，然后计算SQL聚合。

随着时间的推移，供应商在他们的优化器中对这一类查询进行了特殊处理，因为这类查询非常流行，而且为这类长期运行的命
令选择一个好的计划至关重要。

**** 数据仓库： 结论

可以看出，数据仓库需要与OLTP环境完全不同的能力。除了B+树之外，我们还需要位图索引。人们不需要通用的优化器，
而是需要特别关注对雪花模式的聚合查询。我们不需要普通的视图，而需要物化的视图。不需要快速的事务性更新，而是需要
快速的批量加载，等等。关于数据仓库实践的更多概述可以在[11]中找到。

主要的关系型供应商从面向OLTP的架构开始，并随着时间的推移增加了面向仓库的功能。此外，还有各种小型供应商在这
个领域提供DBMS解决方案。这些供应商包括Teradata和Netezza，他们提供共享的专有硬件，他们的DBMS在上面
运行。此外，在这一领域销售的还有Greenplum（PostgreSQL的并行化）、DATAllegro和EnterpriseDB，他们都
是在更传统的硬件上运行。

最后，有一些人（包括一位作者）声称列存储在数据仓库领域与传统的存储引擎相比有巨大的优势，因为传统的存储单位是表
行。当表是 "宽"（高算术）的时候，单独存储每一列是特别有效的，而且访问往往只在几列上。列存储还可以实现简单有效
的磁盘压缩，因为列中的所有数据都来自同一类型。列式存储的挑战在于，表内行的位置需要在所有存储的列中保持一致，否
则就需要额外的机制来连接列。这对OLTP来说是个大问题，但对像仓库或系统日志库这样的主要应用数据库来说不是个大
问题。提供列存储的供应商包括Sybase、Vertica、Sand、Vhayu和KX。关于这个架构讨论的更多细节可以在
[36, 89, 90]中找到。

*** 数据库可扩展性
传统上，关系型数据库被认为在其存储的数据种类上是有限的，主要集中在企业和行政记录中使用的 "事实和数字"。然而，今
天，它们可以承载以各种流行的编程语言表达的广泛的数据类型。这是通过使核心的关系型DBMS以各种方式进行扩展来实现
的。在这一节中，我们简要地调查了被广泛使用的各种扩展，强调了在提供这种扩展性时出现的一些架构问题。这些功能在今天
大多数商业DBMS中都有不同程度的出现，在开源的PostgreSQL DBMS中也是如此。

**** 抽象数据类型
原则上，关系模型对于可以放在模式列上的标量数据类型的选择是不可知的。但是最初的关系型数据库系统只支持一组静态的
字母数字列类型，这种限制与关系型模型本身相关联。关系型数据库系统可以在运行时扩展到新的抽象数据类型，这在早期的
IngresADT系统中得到了说明，在后续的Postgres系统中得到了更积极的说明[88]。为了实现这一点，DBMS的类型
系统--因此解析器必须由系统目录驱动，目录维护着系统已知的类型列表，以及用于操作类型的 "方法"（代码）的指针。在
这种方法中，DBMS不解释类型，它只是在表达式评估中适当地调用它们的方法；因此被称为 "抽象数据类型"。作为一个典
型的例子，我们可以为二维空间的 "矩形 "注册一个类型，以及矩形相交或联合等操作的方法。这也意味着，系统必须为用户
定义的代码提供一个运行时引擎，并安全地执行该代码，而不会有数据库服务器崩溃或破坏数据的风险。今天所有的主要DBMS
都允许用户在现代SQL的命令式 "存储过程 "子语言中定义函数。除了MySQL之外，大多数都至少支持其他几种语言，通
常是C和Java。在Windows平台上，Microsoft SQL Server和IBM DB2支持编译到Microsoft. 在
Windows平台上，Microsoft SQL Server和IBM DB2支持编译到Microsoft.Net Common Language Runtime
的代码，这些代码可以用多种语言编写，最常见的是Visual Basic、C++和C#。PostgreSQL支持C、Perl、Python
和Tcl，并允许在运行时将对新语言的支持添加到系统中--有流行的第三方插件用于Ruby和开源的R统计包。

为了使抽象数据类型在DBMS中高效运行，查询优化器必须考虑到选择和连接谓词中 "昂贵的 "用户定义的代码，并且在某
些情况下将选择推迟到连接之后[13, 37]。为了使ADTs更加高效，能够对其定义索引是非常有用的。至少，B+树需要被
扩展到ADT上的索引表达，而不仅仅是列（有时被称为 "功能索引"），并且优化器必须被扩展到在适用时选择它们。对于
除线性顺序（<, >, =）以外的谓词，B+树是不够的，系统需要支持可扩展的索引方案；文献中的两种方法是原始的
Postgres可扩展访问方法接口[88]，以及GiST[39]。

**** 结构化类型和XML
ADTs被设计成与关系模型完全兼容，它们没有以任何方式改变基本的关系代数，它们只是改变了属性值的表达方式。然而，
多年来，有许多建议对数据库进行了更积极的改变，以支持非关系结构化类型：即嵌套的集合类型，如数组、集合、树，以及
嵌套的图元和/或关系。也许今天这些建议中最相关的是通过像XPath和XQuery这样的语言对XML的支持。3 大概有
三种方法来处理像XML这样的结构化类型。第一种是建立一个定制的数据库系统，对具有结构化类型的数据进行操作；从历
史上看，这些尝试已经被在传统的关系型数据库管理系统中容纳结构化类型的方法所掩盖，这种趋势在 XML 的情况下也被遵
循。第二种方法是将复杂类型作为一个ADT。例如，我们可以定义一个具有XML类型的列的关系表，该表每行存储一个
XML文档。这意味着搜索XML的表达式--例如XPath树形匹配模式--是以一种对查询优化器不透明的方式执行的。第三
种方法是DBMS在插入时将嵌套结构 "规范化 "为一组关系，用外键将子对象连接到它们的父对象。这种技术，有时被称为
"粉碎 "XML，在关系框架内向DBMS暴露了所有的数据结构，但是增加了存储开销，并且需要在查询时连接 "重新连接 "
数据。今天，大多数DBMS供应商为存储提供了ADT和粉碎的选项，并允许数据库设计者在两者之间进行选择。在XML
的情况下，切碎的方法也很常见，它提供了删除嵌套在同一级别的XML元素之间的排序信息的选项，这可以通过允许连接重
新排序和其他关系优化来提高查询性能。

一个相关的问题是对关系模型进行更适度的扩展，以处理嵌套表和图元以及数组。例如，这些在Oracle的安装中被广泛使
用。设计上的权衡在许多方面与处理XML的权衡相似。

**** 全文搜索
传统上，关系型数据库在处理丰富的文本数据和通常与之相关的关键词搜索方面是出了名的差。原则上，在数据库中对自由文
本进行建模只是一个简单的问题，即存储文档，用形式为（词，文档ID，位置）的图元定义一个 "倒置的文件 "关系，并在
词列上建立一个B+树的索引。这大致上就是任何文本搜索引擎所发生的事情，再加上一些词语的语言规范化，以及一些额外
的每个图元的属性来帮助搜索结果的排序。但是，除了这个模式之外，大多数文本索引引擎还实现了一些专门针对这个模式的
性能优化，这些优化在典型的数据库管理系统中是没有实现的。其中包括 "去规范化 "模式，使每个词只出现一次，每个词有
一个出现次数的列表，即（词，列表<documentID，位置>）这允许对列表（通常称为 "张贴列表"）进行积极的delta压
缩，鉴于文档中词的特征性倾斜（Zipfian）分布，这一点至关重要。此外，文本数据库往往以数据仓库的方式使用，绕过了
任何DBMS的交易逻辑。人们普遍认为，在DBMS中，像上面这样的文本搜索的实现比定制的文本索引引擎要慢大约一个数
量级。

然而，今天的大多数DBMS要么包含一个用于文本索引的子系统，要么可以与一个单独的引擎捆绑在一起来完成这项工作。
文本索引设施通常既可用于全文文档，也可用于元组中的简短文本属性。在大多数情况下，全文索引是异步更新的（"抓取"）
，而不是以事务方式维护；PostgreSQL在提供全文索引与事务性更新的选项方面是不寻常的。在一些系统中，全文索引被
存储在DBMS之外，因此需要单独的工具进行备份和恢复。在关系型数据库中处理全文搜索的一个关键挑战是如何将关系型
查询的语义（无序和完整的结果集）与使用关键词的分级文档搜索（有序和通常不完整的结果）以一种有用和灵活的方式联系
起来。例如，当每个关系上有一个关键词搜索谓词时，如何对两个关系上的连接查询的输出进行排序是不清楚的。这个问题在
目前的实践中仍然是临时性的。考虑到查询输出的语义，另一个挑战是关系查询优化器要对文本索引的选择性和成本估计进行
推理，以及对答案集在用户界面上被排序和分页的查询判断适当的成本模型，而且可能不会被完全检索到。根据所有的报告，
这最后一个主题正在一些流行的DBMS中被积极地追求。

**** 额外的可扩展性问题

除了数据库可扩展性的三个驱动使用场景外，我们还提出了引擎内的两个核心组件，这些组件经常被做成可扩展的各种用途。

已经有许多关于可扩展查询优化器的提议，包括支撑IBM DB2优化器的设计[54, 68]，以及支撑Tandem和微软优化器
的设计[25]。所有这些方案都提供了规则驱动的子系统，生成或修改查询计划，并允许独立注册新的优化规则。这些技术有助
于在向查询执行器添加新功能时，或者在为特定的查询重写或计划优化开发新想法时，更容易扩展优化器。这些通用架构对于
实现上述许多具体的可扩展类型功能非常重要。

自早期系统以来出现的另一种交叉形式的可扩展性是数据库能够在模式中 "包裹 "远程数据源，就像它们是本地表一样，并在
查询处理中访问它们。这方面的一个挑战是，优化器要处理不支持扫描的数据源，但会响应为变量赋值的请求；这就需要概括
优化器的逻辑，将索引SARG与查询谓词相匹配[33]。另一个挑战是让执行器有效地处理远程数据源，这些数据源在产生输
出时可能是缓慢的或突发性的；这概括了让查询执行器做异步磁盘I/O的设计挑战，使访问时间的变化性增加一个数量级或
更多[22, 92] 。

*** 标准做法
基本上所有关系型数据库查询引擎的粗略架构都与System R原型的架构相似[3]。多年来，查询处理的研究和开发集中在该
框架内的创新上，以加速越来越多的查询和模式类别。不同系统之间的主要设计差异出现在优化器的搜索策略（自上而下与自下
而上），以及查询执行器的控制流模型，特别是对于无共享和共享磁盘并行（迭代器和交换运算器与异步生产者/消费者方案）。
在更细的层次上，在优化器、执行器和访问方法中使用的方案组合有很大的区别，以实现不同工作负载的良好性能，包括OLTP、
仓储的决策支持和OLAP。商业产品中的这种 "秘方 "决定了它们在特定情况下的表现，但从第一种情况来看，所有的商业系统
在广泛的工作负载中都表现得相当好，而且可以在特定的工作负载中显得很慢。

在开源领域，PostgreSQL有一个相当复杂的查询处理器，有一个传统的基于成本的优化器，有一套广泛的执行算法，还有一
些商业产品中没有的可扩展功能。MySQL的查询处理器要简单得多，它是围绕索引上的嵌套循环连接建立的。MySQL查询优化
器专注于分析查询，以确保常见的操作是轻量级和高效的--特别是键/外键连接、外连接到连接的重写，以及只要求结果集的前
几行的查询。阅读MySQL手册和查询处理代码，并将其与更多的传统设计进行比较，是很有启发的，要记住MySQL在实践中
的高采用率，以及它擅长的任务。

** 讨论和补充材料
由于查询优化和执行的清洁模块化，多年来在这种环境下开发了大量的算法、技术和技巧，而且关系查询处理的研究一直持续到今
天。令人高兴的是，大多数已经在实践中使用的想法（以及许多没有使用的想法）都可以在研究文献中找到。Chaudhuri的简短
调查[10]是查询优化研究的一个良好起点。对于查询处理研究，Graefe提供了一个非常全面的调查[24]。

除了传统的查询处理，近年来有大量的工作将丰富的统计方法纳入到大数据集的处理中。一个自然的扩展是使用抽样或汇总统计来
为聚合查询提供数字近似值[20]，可能是以一种持续改进的在线方式[38]。然而，尽管有相当成熟的研究成果，这在市场上的接
受程度相对较慢。Oracle和DB2都提供了简单的基表抽样技术，但是并没有对涉及一个以上的表的查询提供统计上的稳健估计。
大多数供应商没有关注这些功能，而是选择了丰富他们的OLAP功能，这些功能限制了可以快速回答的查询系列，但为用户提供了
100%的正确答案。

另一个重要但更基本的扩展是在DBMS中包括 "数据挖掘 "技术。流行的技术包括统计聚类、分类、回归和关联规则[14]。除了
研究文献中所研究的这些技术的独立实现外，在将这些技术与丰富的关系查询整合在一起时，还存在着架构上的挑战[77]。

最后，值得注意的是，更广泛的计算社区最近对数据并行化感到兴奋，如谷歌的Map-Reduce、微软的Dryad和雅虎支持的开
源Hadoop代码等框架所体现的那样。 这些系统非常像共享无并行关系查询执行器，由应用逻辑的程序员实现自定义查询操作。
它们还包括简单但合理的工程方法来管理参与节点的故障，这在大规模的情况下是一个常见的现象。也许这一趋势最有趣的方面是，
它正被创造性地用于计算中的各种数据密集型问题，包括文本和图像处理以及统计方法。看看这些框架的用户是否借用了数据库引擎
的其他想法将是很有趣的--例如，雅虎有早期的工作，用声明式查询和优化器来扩展Hadoop。建立在这些框架上的创新也可以被
重新纳入数据库引擎中。





* 存储管理


目前有两种基本类型的DBMS存储管理程序在商业上使用：(1)DBMS直接与磁盘的低级块模式设备驱动程序交互（通常称为原始模
式访问），或者(2)DBMS使用标准的操作系统文件系统设施。这个决定影响了DBMS在空间和时间上控制存储的能力。我们依次考
虑这两个方面，并继续详细讨论存储层次的使用。

** 空间控制
进出磁盘的顺序带宽比随机访问快10到100倍，而且这个比例还在增加。磁盘密度每18个月翻一番，带宽大约以密度的平方
根上升（并与旋转速度呈线性关系）。然而，磁盘臂运动的改进速度要慢得多--大约7%/年[67]。因此，对于DBMS的存储管理
来说，在磁盘上放置块是至关重要的，这样需要大量数据的查询就可以按顺序访问它。由于DBMS能够比底层操作系统更深入地了
解其工作负载的访问模式，所以DBMS的架构师对磁盘上数据库块的空间定位进行完全控制是有意义的。

DBMS控制其数据的空间定位的最好方法是将数据直接存储到 "原始 "磁盘设备上，而完全避免使用文件系统。这是因为原始设备
地址通常与存储位置的物理接近性密切对应。大多数商业数据库系统都提供这种功能，以获得最佳性能。这种技术，虽然有效，但
也有一些缺点。首先，它要求DBA将整个磁盘分区用于DBMS，这使得那些需要文件系统接口的实用程序（备份等）无法使用这
些分区。第二，"原始磁盘 "访问接口通常是操作系统特有的，这可能使DBMS更难移植。然而，这是一个障碍，大多数商业
DBMS供应商在几年前就克服了这个障碍。最后，存储行业的发展，如RAID、存储区域网络（SAN）和逻辑卷管理器已经变得流行。
我们现在正处于这样一个阶段："虚拟 "磁盘设备是当今大多数情况下的常态--"原始 "设备接口实际上被设备或软件所截获，这些
设备或软件在一个或多个物理磁盘上积极地重新定位数据。因此，DBMS的显式物理控制的好处已经随着时间的推移而被削弱。我们
在第7.3节进一步讨论这个问题。

DBMS控制其数据的空间定位的最好方法是将数据直接存储到 "原始 "磁盘设备上，而完全避免使用文件系统。这是因为原始设备
地址通常与存储位置的物理接近性密切对应。大多数商业数据库系统都提供这种功能，以获得最佳性能。这种技术，虽然有效，但
也有一些缺点。首先，它要求DBA将整个磁盘分区用于DBMS，这使得那些需要文件系统接口的实用程序（备份等）无法使用这
些分区。第二，"原始磁盘 "访问接口通常是操作系统特有的，这可能使DBMS更难移植。然而，这是一个障碍，大多数商业
DBMS供应商在几年前就克服了这个障碍。最后，存储行业的发展，如RAID、存储区域网络（SAN）和逻辑卷管理器已经变得流
行。我们现在正处于这样一个阶段："虚拟 "磁盘设备是当今大多数情况下的常态--"原始 "设备接口实际上被设备或软件所截获，
这些设备或软件在一个或多个物理磁盘上积极地重新定位数据。因此，DBMS的显式物理控制的好处已经随着时间的推移而被削弱。
我们在第7.3节进一步讨论这个问题。

原始磁盘访问的一个替代方法是，DBMS在操作系统文件系统中创建一个非常大的文件，并将数据定位为该文件中的偏移量。该文
件基本上被视为一个驻留在磁盘上的页面的线性阵列。这避免了原始设备访问的一些缺点，并且仍然提供相当好的性能。在大多数
流行的文件系统中，如果你在一个空的磁盘上分配一个非常大的文件，该文件中的偏移量将相当接近于存储区域的物理距离。因此，
这是对原始磁盘访问的良好近似，而不需要直接进入原始设备接口。大多数虚拟化的存储系统也被设计为将文件中的近似偏移量放在
附近的物理位置。因此，在使用大文件而不是原始磁盘时，失去的相对控制权随着时间的推移变得不那么重要。使用文件系统接口在
时间控制方面还有其他影响，我们在下一小节讨论。

作为一个数据点，我们最近在一个使用主要商业DBMS的中型系统上比较了直接原始访问和大文件访问，发现在运行TPC-C基
准[91]时，只有6%的降级，而且对I/O密集度较低的工作负载几乎没有负面影响。DB2报告说，在使用直接I/O（DIO）及
其变体（如并发I/O（CIO））时，文件系统开销低至1%。因此，DBMS供应商通常不再推荐原始存储，而且很少有客户以这种
配置运行。在主要的商业系统中，它仍然是一个被支持的功能，主要用于基准测试。

一些商业DBMS也允许将数据库页面大小自定义为适合预期工作负载的大小。IBM DB2和Oracle都支持这个选项。其他的商
业系统，如Microsoft SQL Server，不支持多种页面大小，因为这样会增加管理的复杂性。如果支持可调整的页面大小，选择
的大小应该是文件系统使用的页面大小的倍数（如果使用的是原始I/O，则是原始设备）。在 "5分钟规则 "一文中给出了关于适
当选择页面大小的讨论，该文后来被更新为 "30分钟规则"[27]。如果使用的是文件系统而不是原始设备访问，可能需要特殊的接
口来写入与文件系统不同大小的页面；例如，POSIX的mmap/msync调用就提供了这种支持。

一些商业DBMS也允许将数据库页面大小自定义为适合预期工作负载的大小。IBM DB2和Oracle都支持这个选项。其他的商
业系统，如Microsoft SQL Server，不支持多种页面大小，因为这样会增加管理的复杂性。如果支持可调整的页面大小，选择
的大小应该是文件系统使用的页面大小的倍数（如果使用的是原始I/O，则是原始设备）。在 "5分钟规则 "一文中给出了关于适
当选择页面大小的讨论，该文后来被更新为 "30分钟规则"[27]。如果使用的是文件系统而不是原始设备访问，可能需要特殊的接
口来写入与文件系统不同大小的页面；例如，POSIX的mmap/msync调用就提供了这种支持。

** 时间控制： 缓冲
除了控制数据在磁盘上的位置外，DBMS还必须控制数据何时被实际写入磁盘。正如我们将在第5节中讨论的那样，DBMS包含
了关键的逻辑，来推理何时将数据块写入磁盘。大多数操作系统的文件系统也提供了内置的I/O缓冲机制来决定何时对文件块进
行读写。如果DBMS使用标准的文件系统接口进行写入，操作系统的缓冲可以通过默默地推迟或重新排序写入来混淆DBMS逻辑
的意图。这可能会给DBMS带来重大问题。

第一组问题是关于数据库的ACID事务承诺的正确性：如果不明确控制磁盘写入的时间和顺序，DBMS不能保证在软件或硬件故障
后的原子恢复。正如我们将在第5.3节中讨论的那样，超前写日志协议要求对日志设备的写入必须先于对数据库设备的相应写入，
并且在提交日志记录被可靠地写入日志设备之前，提交请求不能返回给用户。

操作系统缓冲的第二组问题涉及性能，但对正确性没有影响。现代操作系统的文件系统通常有一些内置的对前读（推测性读取）和
后写（延迟的、成批的写入）的支持。这些通常不适合DBMS的访问模式。文件系统的逻辑依赖于文件中物理字节偏移的连续性，
以做出提前读取的决定。DBMS级I/O设施可以支持基于未来读取请求的逻辑预测I/O决策，这些请求在SQL查询处理层面是
已知的，但在文件系统层面不容易辨别。例如，在扫描不一定连续的B+树的叶子（行存储在B+树的叶子中）时，可以请求逻辑
DBMS级的超前读取。在DBMS逻辑中，通过让DBMS在其需求之前发出I/O请求，可以很容易地实现逻辑超前阅读。查询执行
计划包含了数据访问算法的相关信息，并且有关于查询的未来访问模式的全部信息。同样地，DBMS可能想自己决定何时冲刷日志尾
部，基于将锁争用与I/O吞吐量等问题混合在一起的考虑。这种详细的未来访问模式知识对DBMS来说是可用的，但对操作系统
的文件系统来说不是。

最后的性能问题是 "双重缓冲 "和内存拷贝的高CPU开销。鉴于DBMS必须为正确性仔细做自己的缓冲，操作系统的任何额外
缓冲都是多余的。这种冗余导致了两种成本。首先，它浪费了系统内存，有效地减少了可用于做有用工作的内存。第二，它浪费了
时间和处理资源，因为它导致了额外的复制步骤：在读取时，数据首先从磁盘复制到操作系统的缓冲区，然后再复制到DBMS的
缓冲池。在写的时候，这两个拷贝都需要反向进行。

在内存中复制数据可能是一个严重的瓶颈。复制会造成延迟，消耗CPU周期，并可能淹没CPU的数据缓存。这个事实对于那些
没有操作或实施过数据库系统的人来说往往是一个惊喜，他们认为与磁盘I/O相比，主内存操作是 "免费的"。但是在实践中，
一个经过良好调整的事务处理DBMS的吞吐量通常不受I/O的限制。在高端安装中，通过购买足够的磁盘和RAM，使重复的页
面请求被缓冲池吸收，磁盘I/O在磁盘臂上共享，其速度可以满足系统中所有处理器的数据需求。一旦实现了这种 "系统平衡"，
I/O延迟就不再是主要的系统吞吐量瓶颈，剩下的主内存瓶颈就成为系统的限制因素。内存拷贝正在成为计算机架构中的主导瓶颈：
这是由于每美元的原始CPU每秒周期（遵循摩尔定律）和RAM访问速度（明显落后于摩尔定律）之间的性能演变差距[67]。

在数据库研究文献[86]和行业中，操作系统缓冲的问题已经有一段时间是众所周知的。大多数现代操作系统现在都提供了钩子（例
如，POSIX mmap套件调用或平台特定的DIO和CIO API集），以便数据库服务器等程序可以规避文件缓存的双重缓冲。这确
保了在请求时写到磁盘上，避免了双重缓冲，而且数据库管理系统可以控制页面替换策略。

** 缓冲区管理

为了提供对数据库页面的有效访问，每个DBMS都在自己的内存空间中实现了一个大的共享缓冲池。在早期，缓冲池被静态地分配
到一个管理员选择的值，但现在大多数商业DBMS根据系统需要和可用资源动态地调整缓冲池的大小。缓冲池被组织成一个框架的
阵列，每个框架是一个数据库磁盘块大小的内存区域。块从磁盘复制到缓冲池而不改变格式，在内存中以这种本地格式进行操作，
然后再写回去。这种免翻译的方法避免了CPU在 "marshalling "和 "unmarshalling "数据到/从磁盘时的瓶颈；也许更重
要的是，固定大小的框架避免了通用技术导致的外部碎片和压缩的内存管理复杂性。

与缓冲池框架阵列相关的是一个哈希表，它将（1）当前在内存中持有的页数映射到它们在框架表中的位置，（2）该页在备份磁盘
存储中的位置，以及（3）关于该页的一些元数据。元数据包括一个脏位，用来指示该页在从磁盘读出后是否有变化，以及页面替换
策略所需要的任何信息，以便在缓冲池满时选择要驱逐的页面。大多数系统还包括一个引脚计数，以示该页不符合参与页面替换算
法的条件。当引脚计数为非零时，该页被 "钉 "在内存中，不会被强制到磁盘或被盗。这使得DBMS的工作线程可以在操作页面
之前增加pin计数，然后再减少，从而在缓冲池中钉住页面。这样做的目的是为了在任何固定的时间点上只钉住缓冲池中的一小
部分。一些系统还提供了在内存中钉住表的能力，作为一种管理选项，这可以改善对小型、大量使用的表的访问时间。然而，钉住
的页面减少了可用于正常缓冲池活动的页面数量，并且随着钉住的页面比例的增加，会对性能产生负面影响。

在关系型系统的早期，很多研究都集中在页面替换策略的设计上，因为在DBMS中发现的数据访问模式的多样性使得简单的技术
没有效果。例如，某些数据库操作往往需要全表扫描，当扫描的表比缓冲池大得多时，这些操作往往会清除池中所有经常引用的数
据。对于这样的访问模式，参考的经常性是未来参考概率的一个很差的预测因素，所以像LRU和CLOCK这样的操作系统页面替
换方案在许多数据库访问模式中表现不佳[86]。各种替代方案被提出，包括一些试图通过查询执行计划信息来调整替换策略的方案
[15]。今天，大多数系统使用LRU方案的简单改进来考虑全表扫描的情况。一个出现在研究文献中并已在商业系统中实施的方案
是LRU-2[64]。在商业系统中使用的另一个方案是让替换策略取决于页面类型：例如，B+树的根部可能会被替换成与堆文件中的
页面不同的策略。这让人想起Reiter的域分离方案[15, 75]。

最近的硬件趋势，包括64位寻址和内存价格下降，使得非常大的缓冲池在经济上成为可能。这为利用大型主存储器提高效率提供
了新的机会。作为反面教材，大型和非常活跃的缓冲池也带来了重启恢复速度和有效检查点等问题的更多挑战。这些话题将在第6
节进一步讨论。

** 标准做法
在过去的十年中，商业文件系统已经发展到可以很好地支持数据库存储系统的程度。在标准的使用模式中，系统管理员在DBMS的
每个磁盘或逻辑卷上创建一个文件系统。然后，DBMS在每个文件系统中分配一个大文件，并通过mmap套件等低级接口控制文件
中的数据放置。DBMS基本上把每个磁盘或逻辑卷当作一个（几乎）连续的数据库页面的线性阵列。在这种配置中，现代文件系统为
DBMS提供了合理的空间和时间控制，这种存储模型基本上在所有的数据库系统实现中都可用。在大多数数据库系统中，原始磁盘支
持仍然是一个常见的高性能选项，然而，它的使用范围正在迅速缩小，只限于性能基准。

** 讨论和补充材料
数据库存储子系统是一项非常成熟的技术，但近年来在数据库存储方面出现了一些新的考虑，这些考虑有可能以多种方式改变数据
管理技术。

一个关键的技术变化是闪存的出现，它是一种经济上可行的随机存取持久性存储技术[28]。自从数据库系统研究的早期以来，人们
一直在讨论由于新的存储技术取代了磁盘而引起的DBMS设计上的巨大变化。闪存似乎在技术上是可行的，在经济上也得到了广泛
的市场支持，相对于磁盘和RAM，它提出了一个有趣的中间成本/性能权衡。闪存是三十多年来第一个在这方面取得成功的新的持久
性存储介质，因此它的特点可能对未来的DBMS设计产生重大影响。

另一个最近才出现的传统话题是数据库数据的压缩。早期关于这个话题的工作集中在磁盘上的压缩，以减少读取时的磁盘延迟，并
最大限度地提高数据库缓冲池的容量。随着处理器性能的提高和RAM延迟的跟不上，考虑在计算过程中保持数据的压缩变得越来
越重要，以便最大限度地提高数据在处理器缓存中的停留时间。但是，这就要求压缩后的表现形式能够适应数据处理，并且查询处
理的内部结构能够处理压缩的数据。关系数据库压缩的另一个问题是，数据库是可重新排序的元组集，而大多数压缩工作集中在字
节流上，没有考虑重新排序。最近关于这个主题的研究表明，在不久的将来，数据库压缩有很大的前景[73]。

最后，在传统的关系型数据库市场之外，人们对大规模但稀疏的数据存储技术的兴趣增强，在这种情况下，逻辑上有成千上万的列，
其中大部分对任何给定的行来说都是空的。这些情况通常是通过某种属性-价值对或三要素的集合来表示。实例包括谷歌的
BigTable[9]，微软的Active Directory和Exchange产品所使用的标签列，以及为 "语义网 "提出的资源描述框架
（RDF）。这些方法的共同点是使用存储系统，按照数据表的列而不是行来组织磁盘。在最近的一些数据库研究工作中，面向列的存
储的想法被重新提出并进行了详细探讨[36, 89, 90]。

* 事务：并发控制和恢复

数据库系统经常被指责为巨大的、单一的软件系统，不能被分割成可重用的组件。在实践中，数据库系统--以及实现和维护它们的开
发团队--确实被分解成了独立的组件，它们之间的接口都有记录。关系查询处理器和事务存储引擎之间的接口尤其如此。在大多数商
业系统中，这些组件是由不同的团队编写的，它们之间有明确的接口。

DBMS中真正的单体部分是事务性存储管理器，它通常包括四个深深交织在一起的组件：

1. 并发控制的锁管理
2. 用于恢复的日志管理
3. 用于数据库I/O的缓冲池
4. 组织磁盘上数据的访问方法

大量的篇幅已经被用来描述数据库系统中事务性存储算法和协议的棘手细节。希望对这些系统有所了解的读者至少应该读一读基础的
本科数据库教科书[72]，关于ARIES日志协议的期刊文章[59]，以及至少一篇关于事务性索引并发和日志的严肃文章[46, 58]。
更高级的读者会想参考Gray和Reuter的交易教科书[30]。要想真正成为专家，在阅读之后还必须进行实施工作。我们在这里不
纠结于算法和协议，而是调查这些不同组件的作用。我们把重点放在教科书中经常忽略的系统基础设施上，强调组件之间的相互依赖关
系，这导致了使简单协议可行的许多微妙和复杂之处。

** 关于ACID的说明
很多人都熟悉 "ACID事务 "这个术语，这是Haerder和Reuter[34]提出的记忆法。ACID代表了原子性、一致性、隔离性
和持久性。这些术语没有被正式定义，也不是保证事务一致性的数学公理。所以仔细区分这些术语和它们之间的关系并不重要。但
是，尽管是非正式的，ACID的缩写对于组织交易系统的讨论是很有用的，而且足够重要，所以我们在这里回顾一下：

+ 原子性是对事务的 "全有或全无 "的保证--要么一个事务的所有行为都提交，要么都不提交。
+ 一致性是一种特定于应用的保证；SQL完整性约束通常被用来在DBMS中捕获这些保证。考虑到由一组约束条件提供的一致性
  定义，一个事务只有在离开数据库时处于一致性状态才能提交。
+ 隔离是对应用程序编写者的一种保证，即两个并发的事务不会看到对方的进行（尚未提交）的更新。因此，应用程序不需要进行
   "防御性 "编码以担心其他并发事务的 "脏数据"；它们可以被编码为程序员对数据库的唯一访问。
+ 持久性是一种保证，已提交事务的更新在数据库中对后续事务是可见的，不受后续硬件或软件错误的影响，直到它们被另一个已
  提交事务覆盖。

粗略的说，现代DBMS通过锁协议实现隔离。持久性通常通过日志和恢复来实现。隔离和原子性是由锁（防止瞬时数据库状态的可
见性）和日志（确保可见数据的正确性）的组合来保证的。一致性是通过查询执行器的运行时检查来管理的：如果一个事务的行为将
违反SQL的完整性约束，该事务将被中止并返回一个错误代码。

** 对可序列化的简要回顾
我们在开始讨论事务时，简要回顾了数据库并发控制的主要目标，并在下一节描述了在大多数多用户事务存储管理程序中用来实现这
一概念的两个最重要的构件：（1）锁定和（2）锁存。

可序列化是教科书上定义的关于并发事务正确性的概念。它规定了多个提交事务的交错动作序列必须对应于事务的某些串行执行--
就像根本没有并行执行一样。可序列化是描述一组事务的期望行为的一种方式。从单个事务的角度来看，隔离是同样的想法。如果一
个事务没有看到任何并发性的异常情况，就可以说它是在隔离状态下执行的--ACID的 "I"。

可序列化是由DBMS的并发控制模型强制执行的。有三种广泛的并发控制执行技术。这些在教科书和早期的调查报告[7]中都有很
好的描述，但我们在这里非常简要地回顾一下：

1. 严格的两阶段锁（2PL）： 事务在读取每条数据记录之前都会获得一个共享锁，在写入每条数据之前都会获得一个独占锁。所
   有的锁都保持到交易结束，这时它们都被原子化地释放。一个事务在等待获得锁的过程中会在等待队列中阻塞。
2. 多版本并发控制（MVCC）： 事务不持有锁，而是保证在过去的某个时间段对数据库状态的一致看法，即使行在那个固定的时间
   点后发生了变化。
3. 优化的并发控制（OCC）： 允许多个事务在不阻塞的情况下读取和更新一个项目。相反，事务维护其读和写的历史，在提交事
   务之前，检查历史上可能发生的隔离冲突；如果发现任何冲突，冲突的事务之一将被回滚。

大多数商业关系型数据库管理系统通过2PL实现完全可序列化。锁管理器是负责为2PL提供设施的代码模块。

为了减少锁和锁冲突，一些DBMS支持MVCC或OCC，通常是作为2PL的一个附加功能。在MVCC模型中，不需要读锁，但
是这通常是以不提供完全可序列化为代价实现的，我们将在第4.2.1节中讨论。为了避免写在读后面受阻，在行的前一个版本被
保存，或者保证可以快速获得之后，允许写继续进行。进行中的读事务继续使用先前的行值，就像它被锁定并被阻止改变一样。在商
业的MVCC实现中，这个稳定的读值被定义为读事务开始时的值或该事务最近的SQL语句开始时的值。

虽然OCC避免了锁的等待，但在事务之间的真正冲突中，它可能会导致更高的惩罚。在处理跨事务的冲突时，OCC就像2PL一
样，只是它将2PL中的锁等待转换为事务回滚。在冲突不常见的情况下，OCC表现得非常好，避免了过于保守的等待时间。然而，
在冲突频繁的情况下，过度的回滚和重试会对性能产生负面影响，使其成为一个糟糕的选择[2]。

** 锁定和闩锁
数据库锁是系统内约定俗成的名称，代表DBMS管理的物理项目（例如，磁盘页）或逻辑项目（例如，元组、文件、卷）。请注
意，任何名字都可以有一个与之相关的锁--即使这个名字代表一个抽象的概念。锁定机制只是提供了一个注册和检查这些名称的地
方。每个锁都与一个事务相关联，每个事务都有一个唯一的事务ID。锁有不同的锁 "模式"，这些模式与锁-模式兼容表相关。在
大多数系统中，这种逻辑是基于Gray关于锁的粒度的论文[29]中介绍的著名的锁模式。那篇论文也解释了在商业系统中如何实
现分层锁。分层锁允许用一个锁来锁定整个表，同时，在同一个表中支持行颗粒度的锁，既高效又正确。

锁管理器支持两个基本调用；锁（lockname，transactionID，mode），和删除事务（transactionID）。请注意，由于严
格的2PL协议，不应该有单独的调用来单独解锁资源--remove transaction()调用将解锁与一个事务相关的所有资源。然而，
正如我们在第5.2.1节中所讨论的，SQL标准允许较低程度的事务隔离，因此也需要一个unlock（lockname, transact-
ionID）调用。还有一个锁升级（lockname, transactionID, newmode）调用，允许事务以两阶段的方式 "升级 "到更高
的锁模式（例如，从共享模式到独占模式），而不需要丢弃和重新获取锁。此外，一些系统还支持条件锁（lockname, transa-
ctionID, mode）调用。有条件的lock()调用总是立即返回，并指出它是否成功地获取了锁。如果没有成功，调用的DBMS
线程就不会排队等待锁的到来。条件锁在索引并发中的使用在[60]中讨论。

为了支持这些调用，锁管理器维护两个数据结构。一个全局锁表被维护，以保存锁名及其相关信息。该锁表是一个动态的哈希表，
由锁名的哈希函数作为钥匙。与每个锁相关的是一个表示锁模式的模式标志，以及一个锁请求对（事务ID，模式）的等待队列。
此外，锁管理器还维护一个以transactionID为键的事务表，其中包含每个事务T的两个项目：（1）一个指向T的DBMS
线程状态的指针，以允许T的DBMS线程在获得它正在等待的任何锁时被重新安排，以及（2）一个指向锁表中所有T的锁请
求的指针列表，以方便移除与特定事务相关的所有锁（例如，在事务提交或中止时）。

在内部，锁管理器利用一个死锁检测器DBMS线程，定期检查锁表以检测等待周期（DBMS工作者的一个周期，其中每个人都在
等待下一个，形成一个周期）。一旦检测到死锁，死锁检测器就会中止其中一个死锁的事务。终止哪个死锁事务的决定是基于研究
文献[76]中已经研究过的启发式方法。在无共享和共享磁盘系统中，需要分布式死锁检测[61]或更原始的基于超时的死锁检测器。
Gray和Reuter的文章[30]中对锁管理器的实现作了更详细的描述。

作为数据库锁的辅助工具，较轻量级的锁存器也被提供给相互排斥。与锁相比，锁更类似于监视器[41]或信号灯；它们被用来提
供对DBMS内部数据结构的独占访问。例如，缓冲池页表有一个与每个帧相关的锁，以保证在任何时候只有一个DBMS线程在替
换一个给定的帧。闩锁被用于实现锁，并短暂地稳定可能被并发修改的内部数据结构。

门闩与锁有许多不同之处：
- 锁保存在锁表中，并通过哈希表定位；锁驻留在它们所保护的资源附近的内存中，并通过直接寻址访问。
- 在一个严格的2PL实现中，锁受制于严格的2PL协议。在交易过程中，锁可以根据特殊情况下的内部逻辑来获得或放弃。
- 锁的获取完全由数据访问驱动，因此锁获取的顺序和寿命主要由应用程序和查询优化器掌握。锁是由DBMS内部的专门代码获
  取的，DBMS的内部代码战略性地发出锁请求和释放。
- 允许锁产生死锁，锁死锁通过事务重启来检测和解决。必须避免锁死锁；锁死锁的发生代表了DBMS代码中的一个错误。
- 锁存器是通过原子硬件指令来实现的，或者在极少数情况下，在操作系统内核中通过相互排斥来实现。
- 闩锁调用最多需要几十个CPU周期，而锁请求则需要数百个CPU周期。
- 锁管理器跟踪事务持有的所有锁，并在事务抛出异常时自动释放锁，但是操作锁的DBMS内部例程必须仔细跟踪它们，并将手动
  清理作为其异常处理的一部分。
- 锁存器没有被跟踪，因此在任务发生故障时不能自动释放。


闩锁API支持latch(object, mode)、unlatch(object)和conditional latch(object, mode)这几个例程。在大
多数DBMS中，锁存模式的选择只包括共享或独占。锁存器保持一个模式，以及一个等待锁存器的DBMS线程的等待队列。
latch和unlatch调用的工作方式与人们所期望的一样。有条件的latch()调用类似于上面描述的有条件的lock()调用，
也被用于索引并发[60]。

   
*** 事务隔离级别
在事务概念发展的早期，人们试图通过提供比可序列化更 "弱 "的语义来提高并发性。挑战在于如何在这些情况下为语义提供强
有力的定义。在这方面最有影响力的工作是Gray早期关于 "一致性程度 "的工作[29]。这项工作试图提供一致性程度的声明
性定义，以及在锁定方面的实现。受这项工作的影响，ANSI SQL标准定义了四个 "隔离级别"：

1. 读取未提交： 一个事务可以读取任何版本的数据，无论是否提交。这在锁的实现中是通过读取请求的进行而不获取任何锁来
   实现的。
2. 读取已提交： 一个事务可以读取任何已提交版本的数据。对一个对象的重复读取可能导致不同的（已提交）版本。这是通过
   读取请求在访问一个对象之前获得一个读取锁，并在访问之后立即解锁来实现的。
3. 可重复读取：一个事务将只读取一个版本的承诺数据；一旦事务读取一个对象，它将始终读取该对象的同一版本。这是通过
   读取请求在访问一个对象之前获得一个读取锁，并保持该锁直到交易结束来实现的。
4. 可序列化： 保证了完全可序列化的访问。


乍一看，REPEATABLE READ似乎提供了完全的可序列化，但事实并非如此。在System R项目的早期[3]，出现了一个被称
为 "幻影问题 "的问题。在幻影问题中，一个事务在同一事务中以相同的谓词多次访问一个关系，但在再次访问时看到了新的
"幻组 "元组，而这些元组在第一次访问时并没有看到。这是因为在元组级粒度的两阶段锁定并不能阻止新的元组插入到表中。
表的两阶段锁定可以防止幻读，但是在事务通过索引只访问少数元组的情况下，表级的锁定可能会有限制。我们将在第5.4.3
节讨论索引中的锁时进一步研究这个问题。

1. 读取未提交的数据： 一个事务可以读取任何版本的数据，无论是否提交。这在锁的实现中是通过读取请求的进行而不获取任
   何锁来实现的。
2. 读取已提交： 一个事务可以读取任何已提交版本的数据。对一个对象的重复读取可能导致不同的（已提交）版本。这是通过
   读取请求在访问一个对象之前获得一个读取锁，并在访问之后立即解锁来实现的。
3. 可重复读取：一个事务将只读取一个版本的承诺数据；一旦事务读取一个对象，它将始终读取该对象的同一版本。这是通过
   读取请求在访问一个对象之前获得一个读取锁，并保持该锁直到交易结束来实现的。
4. 可序列化： 保证了完全可序列化的访问。

乍一看，REPEATABLE READ似乎提供了完全的可序列化，但事实并非如此。在System R项目的早期[3]，出现了一个被
称为 "幻读问题 "的问题。在幻读问题中，一个事务在同一事务中以相同的谓词多次访问一个关系，但在再次访问时看到了新
的 "幻读 "元组，而这些元组在第一次访问时并没有看到。这是因为在元组级粒度的两阶段锁定并不能阻止新的元组插入到表
中。表的两阶段锁定可以防止幻读，但在事务通过索引只访问少数元组的情况下，表级锁定可能会有限制。我们将在第5.4.3
节讨论索引中的锁时进一步研究这个问题。

商业系统通过基于锁的并发控制实现来提供上述四个隔离级别。不幸的是，正如Berenson等人[6]所指出的，Gray的早期
工作和ANSI标准都没有实现提供真正声明性定义的目标。两者都以微妙的方式依赖于一个假设，即锁定方案被用于并发控制，
而不是乐观的[47]或多版本[74]并发方案。这意味着所提出的语义是定义不清的。我们鼓励感兴趣的读者看看Berenson的
论文，它讨论了SQL标准规范中的一些问题，以及Adya等人的研究[1]，它为这个问题提供了一种新的、更简洁的方法。

除了标准的ANSI SQL隔离级别外，各种供应商还提供了额外的级别，这些级别在特定情况下被证明是受欢迎的。

+ CURSOR STABILITY：这个级别是为了解决READ COMMITTED的 "丢失更新 "问题。考虑两个事务 T1 和 T2。T1在
  READ COMMITTED模式下运行，读取一个对象X（比如说一个银行账户的价值），记住它的价值，随后根据记住的价值写入
  对象X（比如说在原始账户价值上增加100美元）。T2也读和写X（例如从账户中减去300美元）。如果T2的操作发
  生在T1的读和T1的写之间，那么T2的更新效果就会丢失--在我们的例子中，账户的最终价值将增加100美元，而不
  是像预期的那样减少200美元。在CURSOR STABILITY模式下的事务对查询游标上最近读到的项目持有一个锁；当游标被
  移动（例如，通过另一个FETCH）或者事务终止时，这个锁会自动丢弃。CURSOR STABILITY允许事务在单个项目上进行读-
  思-写的顺序，而不需要其他事务的介入更新。
+ SNAPSHOT ISOLATION：在SNAPSHOT ISOLATION模式下运行的事务是在事务开始时存在的数据库版本上运行的；其他
  事务的后续更新对该事务来说是不可见的。这是MVCC在生产数据库系统中的主要用途之一。当事务开始时，它从一个单调
  增长的计数器中获得一个唯一的开始时间戳；当它提交时，它从计数器中获得一个唯一的结束时间戳。只有当没有其他具有重
  叠的开始/结束交易对的交易写了该交易也写的数据时，该交易才会提交。这种隔离模式依赖于多版本并发的实现，而不是锁
  定。然而，在支持SNAPSHOT ISOLATION的系统中，这些方案通常是共存的。
+ READ CONSISTENCY：这是由Oracle定义的MVCC方案；它与SNAPSHOT ISOLATION有细微的不同。在Oracle
  方案中，每个SQL语句（在一个事务中可能有很多）看到的都是该语句开始时的最新提交的值。对于从游标中获取的语句，
  游标集是基于它被打开时的值。这是通过维护单个元组的多个逻辑版本来实现的，一个事务可能引用一个元组的多个版本。与
  其存储可能需要的每个版本，Oracle只存储最新的版本。如果需要一个较早的版本，它通过采取当前版本并根据需要应用撤
  销日志记录来 "回滚 "来产生较早的版本。修改是通过长期的写锁来维护的，所以当两个事务想写同一个对象时，第一个写者
   "赢 "了，第二个写者必须等待第一个写者的事务完成后才能继续写。相比之下，在SNAPSHOT ISOLATION中，第一个提
   交者 "赢"，而不是第一个写者。

弱隔离方案可以提供比完全可序列化更高的并发性。因此，一些系统甚至将弱一致性作为默认值。例如，Microsoft SQL
Server默认为READ COMMITTED。缺点是，隔离（ACID意义上的隔离）是不保证的。因此，应用程序编写者需要推理这些
方案的微妙之处，以确保他们的事务正确运行。考虑到这些方案在操作上定义的语义，这可能很棘手，并可能导致应用程序更难
在DBMS之间移动。

** 日志管理

日志管理器负责维护已提交事务的持久性，促进已中止事务的回滚以确保原子性，并从系统故障或无序关闭中恢复。为了提供这些
功能，日志管理器在磁盘上维护一连串的日志记录，并在内存中维护一组数据结构。为了支持崩溃后的正确行为，驻留在内存中的
数据结构显然需要可以从日志和数据库中的持久性数据重新创建。

数据库日志是一个极其复杂和注重细节的话题。关于数据库日志的典型参考文献是ARIES的期刊论文[59]，数据库专家应该熟悉
该论文的细节。ARIES的论文不仅解释了日志协议，而且还提供了关于替代设计可能性的讨论，以及它们可能导致的问题。这使得
阅读变得很密集，但最终是有收获的。作为一个更容易消化的介绍，Ramakrishnan和Gehrke的教科书[72]提供了对基本的
ARIES协议的描述，没有旁的讨论或改进。在这里，我们讨论一些恢复的基本想法，并试图解释教科书和期刊描述之间的复杂性差
距。

数据库恢复的标准主题是使用Write-Ahead Logging（WAL）协议。WAL协议由三个非常简单的规则组成：
1. 对数据库页面的每一次修改都应该产生一条日志记录，在数据库页面被刷新之前，日志记录必须被刷新到日志设备。
2. 数据库的日志记录必须按顺序刷新；在r之前的所有日志记录被刷新之前，日志记录r不能被刷新。
3. 在事务提交请求时，在提交请求成功返回之前，必须将提交日志记录刷新到日志设备。


许多人只记得这些规则中的第一条，但这三条都是正确行为的要求。
第一条规则确保在交易中止的情况下，不完整的事务的行为可以被撤销，以确保原子性。规则(2)和(3)的组合确保了持久性：如果
一个已提交的事务尚未反映在数据库中，那么在系统崩溃后可以重新执行这些行动。

鉴于这些简单的原则，高效的数据库日志是令人惊讶的，因为它是如此微妙和详细。然而，在实践中，上面的简单故事因为需要极
强的性能而变得复杂。我们面临的挑战是如何保证提交事务的 "快速路径 "的效率，同时为中止的事务提供高性能的回滚，以及崩
溃后的快速恢复。当添加特定的应用优化时，日志变得更加复杂，例如，支持提高只能增减的字段的性能（"托管事务"）。

为了最大限度地提高快速路径的速度，大多数商业数据库系统的运行模式被Haerder和Reuter称为 "DIRECT,STEAL/
NOT-FORCE "[34]：(a)数据对象被就地更新，(b)未钉住的缓冲池框架可以被 "stolen"（并将修改的数据页写回磁盘），即使
它们包含未提交的数据，以及(c)在提交请求返回给用户之前缓冲池页不需要被 "forced"（冲刷）到数据库。这些策略将数据保持
在DBA选择的位置，它们给了缓冲区管理器和磁盘调度器充分的自由来决定内存管理和I/O策略，而不考虑事务的正确性。这些
功能可以带来很大的性能优势，但是需要日志管理器有效地处理所有的微妙问题，即撤销从中止的事务中偷来的页面的冲刷，以及重
做对已提交的事务中因崩溃而丢失的非强制页面的修改。一些DBMS使用的一种优化方法是将DIRECT, STEAL/NOT-FORCE系
统的可扩展性优势与DIRECT NOT-STEAL/NOT-FORCE系统的性能结合起来。在这些系统中，除非缓冲池中没有干净的页面，否
则页面不会被盗，在这种情况下，系统会退化到STEAL策略，并产生上述的额外开销。

日志中的另一个快速路径挑战是保持尽可能小的日志记录，以提高日志I/O活动的吞吐量。一个自然的优化是记录逻辑操作（例
如，"将(Bob, $25000)插入EMP"）而不是物理操作（例如，通过插入元组修改的所有字节范围的后映像，包括堆文件和索引块
上的字节）。这样做的好处是，重做和撤销逻辑操作的逻辑变得相当复杂。2 在实践中，物理和逻辑日志的混合物（所谓的 "
physiological "日志）被使用。在ARIES中，物理日志通常被用来支持REDO，而逻辑日志被用来支持UNDO。这是ARIES
规则的一部分，即在恢复过程中 "重复历史 "以达到崩溃状态，然后从该点回滚事务。

崩溃恢复是需要在系统故障或非有序关闭后将数据库恢复到一个一致的状态。如上所述，恢复在理论上是通过重放历史，从第一条
一直到最近的记录，一步步通过日志记录实现的。这种技术是正确的，但效率不高，因为日志可能是任意长的。与其从第一条日志
记录开始，不如从这两条日志记录中最古老的一条开始恢复，就能得到正确的结果：（1）描述缓冲池中最古老的脏页的最早变化的
日志记录；（2）代表系统中最古老的事务开始的日志记录。这个点的序列号被称为恢复性日志序列号（recovery LSN）。由于计
算和记录恢复LSN会产生开销，而且我们知道恢复LSN是单调增长的，所以我们不需要一直保持它的更新。相反，我们在称为检
查点的周期性间隔中计算它。

本机检查点将强制执行所有脏的缓冲池页面，然后计算和存储恢复LSN。对于一个大的缓冲池，这可能会导致几秒钟的延迟，以完
成待处理页面的I/O。因此，需要一个更有效的 "模糊 "检查点方案，以及通过处理尽可能少的日志将检查点正确带到最近的一致
状态的逻辑。ARIES使用了一个非常聪明的方案，其中实际的检查点记录非常小，只包含足够的信息来启动日志分析过程，并能够
重新创建崩溃时丢失的主内存数据结构。在ARIES模糊检查点期间，恢复LSN被计算出来，但不需要同步写出缓冲池页面。一个
单独的策略被用来决定何时异步写出旧的脏缓冲池页面。

请注意，回滚将要求写入日志记录。这可能会导致困难的情况，即由于日志空间耗尽，进行行中的事务不能继续进行，但它们也不能
被回滚。这种情况通常是通过空间预留方案来避免的，然而，这些方案很难在系统通过多个版本的演变中得到并保持正确。

最后，由于数据库不仅仅是磁盘页上的一组用户数据元组，它还包括各种 "物理 "信息，使其能够管理其内部基于磁盘的数据结
构，因此日志和恢复的任务变得更加复杂。我们在下一节的索引日志中讨论这个问题。

** 索引中的锁定和日志

索引是用于访问数据库中的数据的物理存储结构。索引本身对于数据库应用程序的开发者来说是不可见的，除非它们提高了性能或
者执行了唯一性约束。开发人员和应用程序不能直接观察或操作索引中的条目。这使得索引可以通过更有效的（和复杂的）事务性
方案来管理。索引并发和恢复需要保留的唯一不变因素是，索引总是从数据库中返回事务中一致的元组。

*** B+树中的锁存
在B+树锁存中出现了这个问题的一个被充分研究的例子。B+树由数据库磁盘页组成，通过缓冲池访问，就像数据页一样。因此，
索引并发控制的一个方案是对索引页使用两阶段锁。这意味着每一个接触到索引的事务都需要锁定B+树的根部，直到提交时间--
这是一个有限的并发性的秘诀。为了解决这个问题，人们开发了各种基于闩锁的方案，而不在索引页上设置任何事务锁。这些方案
的关键是对树的物理结构的修改（例如，拆分页面）可以以非交易的方式进行，只要所有并发的事务继续在叶子上找到正确的数
据。这方面大致有三种方法：
+ 保守主义的做法： 只有当多个想要访问相同页面的事务能够保证在使用页面内容时不发生冲突时，才允许这些事务的访问。
  一个这样的冲突是，一个读事务想要遍历树的一个完全打包的内部页面，而一个并发的插入事务正在该页面下方操作，可能需
  要分割该页面[4]。这些保守的方案与下面较新的想法相比，牺牲了太多的并发性。
+ 闩锁耦合方案： 树的遍历逻辑在每个节点被访问之前都会锁住它，只有当下一个要访问的节点被成功锁住时才会解除锁住。
  这种方案有时被称为锁存器 "抓取"（crabbing），因为在树上 "抓 "住一个节点，"抓 "住它的子节点，释放父节点，然
  后重复这种动作。闩锁耦合在一些商业系统中使用；IBM的ARIESIM版本被很好地描述了[60]。ARIES-IM包括一些相当
  复杂的细节和角落案例--有时它必须在分裂后重新启动遍历，甚至设置（非常短暂的）全树的锁存器。
+ 右链路方案： 简单的附加结构被添加到B+树中，以尽量减少对锁存器和重新遍历的要求。特别是，从每个节点到其右边的邻
  居之间增加了一个链接。在遍历过程中，右链方案不做锁存器耦合--每个节点都被锁存、读取和解除锁存。右链方案的主要直
  觉是，如果一个遍历事务跟踪一个指向节点n的指针，发现n在中间被分割了，遍历事务可以检测到这个事实，并通过右链
   "右移"，找到树中新的正确位置[46, 50]。一些系统也支持使用反向链接进行反向遍历。
+ Kornacker等人[46]对闩锁耦合和右键方案之间的区别进行了详细的讨论，并指出闩锁耦合只适用于B+树，对于更复杂的
  数据的索引树，例如不具有单一线性顺序的地理数据，将无法发挥作用。PostgreSQL的通用搜索树（GiST）的实现是基于
  Kornacker等人的可扩展右键方案。

*** 物理结构的记录
除了特例并发逻辑外，索引还使用特例日志逻辑。这种逻辑使得记录和恢复更加有效，但代价是增加代码的复杂性。主要的想法
是，当相关的事务被中止时，结构性的索引变化不需要被撤销；这样的变化通常不会对其他事务所看到的数据库元组产生影响。
例如，如果一个B+树页面在一个插入事务中被分割，而该事务随后中止，那么在中止处理过程中就没有迫切的需要撤销分割。

这就提出了将一些日志记录标记为只重做的挑战。在对日志的任何撤销处理过程中，只做重做的修改可以留在原地。ARIES为
这些情况提供了一种优雅的机制，称为嵌套顶层行动，它允许恢复过程在恢复期间 "跳过 "物理结构修改的日志记录，而不需
要任何特殊情况下的代码。

这个想法也被用于其他情况，包括堆文件。对堆文件的插入可能需要在磁盘上扩展该文件。为了捕捉这一点，必须对文件的范围
图进行修改。这是磁盘上的一个数据结构，指向构成文件的连续块的运行。如果插入的事务中止了，对范围图的这些改变不需要
撤销。文件变大的事实是一个事务上不可见的副作用，而且事实上可能对吸收未来的插入流量很有用。

*** 下一个键的锁定： 逻辑属性的物理替代物
我们用最后一个索引并发问题来结束本节，这个问题说明了一个微妙但重要的想法。挑战在于提供完全的可序列化（包括幻影保
护），同时允许元组级锁和索引的使用。请注意，这种技术只适用于完全的可序列化，在宽松的隔离模型中不需要或不使用。

当一个事务通过索引访问元组时，就会出现幻影问题。在这种情况下，事务通常不会锁定整个表，只是锁定表中通过索引访问的
元组（例如，"Name BETWEEN 'Bob' AND 'Bobby' "）。在没有表级锁的情况下，其他事务可以自由地向表中插入新的元组
（例如，"Name='Bobbie'"）。当这些新插入的数据落在查询谓词的值范围内时，它们将出现在随后通过该谓词进行的访问中。
请注意，幻影问题与数据库元组的可见性有关，因此是一个锁的问题，而不仅仅是锁的问题。原则上，我们需要的是以某种方式
锁定原始查询的搜索谓词所代表的逻辑空间的能力，例如，所有可能的字符串的范围，在 "Bob "和 "Bobby "之间，按词汇
学顺序。不幸的是，谓词锁定是昂贵的，因为它需要一种方法来比较任意的谓词是否重叠。这不能用基于散列的锁表来完成[3]。

在B+树中，解决幻影问题的一种常见方法被称为下一个键锁定。在下一个键锁定中，索引插入代码被修改，这样，一个索引键
为km的元组的插入必须在索引中存在的下一个键元组上分配一个独占锁，其中下一个键元组具有大于k的最低键。它还确保
元组不能被插入到之前返回的最低键的图元下面。例如，如果在第一次访问中没有发现 "Bob "键，那么在同一事务中的后续访
问中也不应该发现 "Bob "键。还有一种情况：插入刚刚超过先前返回的最高键位元组的元组。为了防止这种情况，下一个键锁
定协议要求读事务在索引中的下一个键元组上也获得一个共享锁。在这种情况下，下一个键元组是不满足查询前提条件的最小键
元组。更新在逻辑上表现为先删除后插入，尽管优化是可能的和常见的。

下一个键的锁定，虽然有效，但确实存在过度锁定的问题，这在某些工作负载中可能会出现问题。例如，如果我们扫描从键1
到键10的记录，但是被索引的列只存储了键1、5和100，那么从1到100的整个范围都会被读取锁定，因为100是
10之后的下一个键。

下一个键锁定并不是简单的一个聪明的方法。它是一个使用物理对象（当前存储的元组）作为逻辑概念（谓词）的代名词的例子。
这样做的好处是，简单的系统基础设施，如基于哈希的锁表，可以用于更复杂的目的，只需修改锁协议。当这种语义信息可用时，
复杂软件系统的设计者应该把这种逻辑代用的一般方法放在他们的 "bag of tricks "中。

** 事务性存储的相互依赖性

我们在本节的早期声称，事务性存储系统是单体的、深度纠缠的系统。在本节中，我们讨论了事务性存储系统的三个主要方面之间
的一些相互依赖关系：并发控制、恢复管理和访问方法。在一个更幸福的世界里，有可能在这些模块之间确定狭窄的API，从而使
这些API背后的实现可以被交换。我们在本节中的例子表明，这并不容易做到。我们不打算在这里提供一份相互依赖关系的详尽
清单；生成和证明这样一份清单的完整性将是一项非常具有挑战性的工作。然而，我们确实希望能够说明交易存储的一些曲折逻辑，
从而证明商业DBMS中的单体实现是合理的。

我们首先只考虑并发控制和恢复，而不考虑访问方法的进一步复杂化。即使是这样的简化，各部分也是深深交织在一起的。并发和
恢复之间关系的一个表现是，写前日志对锁定协议进行了隐含的假设。写入式日志需要严格的两阶段锁定，而在非严格的两阶段锁
定下，将无法正确操作。要看到这一点，请考虑在一个中止的事务的回滚过程中会发生什么。恢复代码开始处理中止的事务的日志
记录，撤销其修改。一般来说，这需要改变事务之前修改的页面或元组。为了进行这些修改，该事务需要在这些页面或图元上拥有
锁。在一个非严格的2PL方案中，如果事务在中止前放弃了任何锁，它可能无法重新获得完成回滚过程所需的锁。

访问方法使事情进一步复杂化。将教科书上的访问方法算法（例如线性散列[53]或R-树[32]），在交易系统中实现一个正确的、
高并发的、可恢复的版本，这是一个重大的智力和工程挑战。由于这个原因，大多数领先的DBMS仍然只实现堆文件和B+树作为
交易保护的访问方法；PostgreSQL的GiST实现是一个明显的例外。正如我们在上面对B+树所做的说明，事务性索引的高性
能实现包括复杂的锁存、锁定和记录协议。严重的DBMS中的B+树充满了对并发和恢复代码的调用。即使是像堆文件这样简单的
访问方法，也有一些围绕描述其内容的数据结构（例如，程度图）的棘手的并发和恢复问题。这种逻辑对所有的访问方法都不是通
用的--它在很大程度上是根据访问方法的具体逻辑和它的特定实现而定制的。

访问方法中的并发控制只在面向锁的方案中得到了很好的发展。其他的并发方案（例如，乐观或多版本并发控制）通常根本不考虑
访问方法，或者只是以一种不经意的和不切实际的方式提到它们[47]。因此，对于一个给定的访问方法的实现，混合和匹配不同的
并发机制是困难的。

访问方法中的恢复逻辑是特别针对系统的：访问方法日志记录的时间和内容取决于恢复协议的细节，包括对结构修改的处理（例如，
它们是否在事务回滚时被撤销，如果不是，如何避免），以及物理和逻辑日志的使用。即使是像B+树这样的特定访问方法，恢复
和并发逻辑也是相互交织的。在一个方向上，恢复逻辑取决于并发协议：如果恢复管理器必须恢复树的物理一致状态，那么它需要
知道哪些不一致的状态可能会出现，以便用日志记录适当地括住这些状态以实现原子性（例如，通过嵌套的顶部动作）。在相反的
方向，一个访问方法的并发协议可能依赖于恢复逻辑。例如，B+树的右键方案假设树中的页在分裂后永远不会 "重新合并"。这个
假设要求恢复方案使用一种机制，如嵌套的顶部行动，以避免撤销由中止的事务产生的分裂。

这种设计的一个亮点是，缓冲区管理与存储管理器的其他组件相对隔离得很好。只要页面被正确地钉住，缓冲区管理器就可以自由
地封装它的其余逻辑，并根据需要重新实现它。例如，缓冲区管理器可以自由地选择要替换的页面（因为有STEAL属性），以及
页面刷新的调度（由于有NOT FORCE属性）。当然，实现这种隔离是造成并发和恢复方面的许多复杂性的直接原因。因此，这种
设计并没有想像中的很好。

** 标准做法

今天所有的生产数据库都支持ACID事务。作为一项规则，它们使用写前日志来保证持久性，并使用两阶段锁来控制并发性。一
个例外是PostgreSQL，它在整个过程中使用多版本并发控制。Oracle率先将多版本并发与锁定并列使用，作为提供宽松的一
致性模式（如快照隔离和读一致性）的一种方式；这些模式在用户中的普及已经导致它们在不止一个商业DBMS中被采用，在
Oracle中这是默认的。B+树索引是所有生产型数据库的标准，大多数商业数据库引擎都提供了某种形式的多维索引，要么嵌入到
系统中，要么作为一个 "插件 "模块。只有PostgreSQL通过其GiST实现，提供了高并发的多维和文本索引。

MySQL的独特之处在于积极支持下面的各种存储管理器，以至于DBA经常为同一数据库中的不同表选择不同的存储引擎。它的
默认存储引擎MyISAM只支持表级锁，但被认为是主要读工作负载的高性能选择。对于读/写工作负载，推荐使用InnoDB存储
引擎；它提供行级锁定。(InnoDB几年前被甲骨文公司收购，但目前仍然是开源的，可以免费使用）。MySQL的两个存储引擎都
没有提供著名的为System R[29]开发的分层锁方案，尽管它在其他数据库系统中被普遍使用。这使得InnoDB和MyISAM之
间的选择对MySQL DBA来说很棘手，在一些混合工作负载的情况下，这两个引擎都不能提供良好的锁粒度，需要DBA开发一个
使用多表和/或数据库复制的物理设计来支持扫描和高选择性的索引访问。MySQL还支持用于主内存和基于集群的存储引擎，一些
第三方供应商已经宣布了与MySQL兼容的存储引擎，但目前MySQL用户群中的大部分精力都集中在MyISAM和InnoDB上。

** 讨论和补充材料
到现在为止，事务机制已经是一个非常成熟的话题了，大多数可能的技巧在过去的几年里都以这样或那样的形式被尝试过；新的设
计往往涉及现有想法的排列组合。也许这个领域中最引人注目的变化是由于RAM价格的迅速下降。这增加了将数据库的大部分
"热 "部分保留在内存中并以内存速度运行的动力，这使得将数据频繁刷新到持久性存储以保持低重启时间的挑战变得复杂。闪存
在事务管理中的作用是这种不断变化的平衡行为的一部分。

近年来，一个有趣的发展是操作系统界相对广泛地采用了写前日志，通常是在日志文件系统的名义下。这些已经成为今天所有操作
系统的标准选项。由于这些文件系统通常仍然不支持文件数据的交易，所以看看它们如何以及在什么地方使用写前日志来实现耐久
性和原子性是很有趣的。有兴趣的读者可以参考[62, 71]以进一步阅读。这方面另一个有趣的方向是关于Stasis的工作[78]，
它试图更好地模块化ARIES风格的日志和恢复，并使其可用于系统程序员的各种用途。





