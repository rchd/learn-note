








* hash索引
** 概览
散列索引提供了通过特定索引键快速查找元组ID(TID)的能力。粗略地说，它只是一个存储在磁盘上的哈希表。散列索引所支持的
唯一操作是通过平等条件进行搜索。

当一个值被插入到一个索引中时，索引键的哈希函数被计算出来。在PostgreSQL中，哈希函数返回32位或64位的整数；这
些值的几个最低位被用作相应的桶的编号。键的TID和哈希代码被添加到选择的桶中。密钥本身并不存储在索引中，因为处理小的
固定长度的值更方便。

一个索引的哈希表是动态扩展的。集群的最小数量是两个。随着索引元组数量的增加，其中一个桶会被拆成两个。这个操作多用了一
个哈希代码的位，所以元素只在分割后的两个桶之间重新分配；哈希表的其他桶的组成保持不变。

索引搜索操作会计算索引键的哈希函数和相应的桶号。在所有桶的内容中，搜索将只返回那些与键的哈希代码相对应的TID。由于
桶中的元素是按键的哈希代码排序的，二进制搜索可以相当有效地返回匹配的TID。

由于键没有存储在哈希表中，索引访问方法可能因为哈希碰撞而返回多余的TID。因此，索引引擎必须重新检查由访问方法获取的
所有结果。由于同样的原因，不支持仅有索引的扫描。
** 页面布局

与普通的哈希表不同，哈希索引是存储在磁盘上的。因此，所有的数据必须被排列成页，最好是使索引操作（搜索、插入、删除）需
要访问尽可能少的页。

一个哈希索引有以下四种页面

+ 元页－提供索引的目录
+ 桶页－索引的主要页面
+ 溢出页－当前主桶页不能容纳所有的元素时使用的附加页
+ 位图页－包含位数组的页，用于跟踪已经释放并可重复使用的溢出页

可以使用pageinspect扩展来查看索引页面

创建一个空的表

#+begin_src sql
  create extension pageinspect;
  create table t(n integer);
  analyze t;
  create index on t using hash(n);
#+end_src

对表进行了分析，所以创建的索引将具有尽可能小的尺寸；否则，将根据表包含10个页面的假设来选择桶的数量。索引包含四
个页面：元页面、两个桶页面和一个位图页面（一次性创建，供将来使用）：

#+begin_src sql
  select page, hash_page_type(get_raw_page('t_n_idx', page))
  from generate_series(0, 3) page;
#+end_src

[[./images/hySCnE.png]]

元页包含所有关于索引的控制信息。我们目前只对几个值感兴趣：

#+begin_src sql
  select ntuples, ffactor, maxbucket
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

每个桶的估计行数显示在ffactor字段。这个值是根据块的大小和fillfactor存储参数值计算的。通过绝对均匀的数据分布
和没有哈希碰撞，你可以使用一个更高的fillfactor值，但在现实生活中的数据库，它增加了页面溢出的风险。

对于散列索引来说，最糟糕的情况是数据分布有很大的偏斜，当一个键重复多次时。由于散列函数将返回一个相同的值，所有的数据
都将被放入同一个桶中，增加桶的数量将无济于事。

现在索引是空的，如ntuples字段所示。让我们通过插入多条具有相同索引键值的行来引起一个桶状页溢出。一个溢出的页面出
现在索引中：


#+begin_src sql
  insert into t(n)
  select 0 from generate_series(1, 500);
  select page, hash_page_type(get_raw_page('t_n_idx', page))
  from generate_series(0, 4) page;
#+end_src

[[./images/RSwyo0.png]]

对所有页面的综合统计显示，桶0是空的，而所有的值都被放入桶1：其中一些位于主页面，而那些不适合它的值可以在溢出页面
找到。

#+begin_src sql
  select page, live_items, free_size, hasho_bucket
  from (values (1), (2), (4)) p(page),
  hash_page_stats(get_raw_page('t_n_idx', page));
#+end_src

很明显，如果一个相同的桶的元素分布在几个页面上，性能会受到影响。如果数据分布均匀，散列索引显示出最好的结果。

现在让我们来看看一个桶是如何被分割的。当索引中的行数超过可用桶的估计ffactor值时，它就会发生。这里我们有两个桶，
ffactor是307，所以当第615行被插入到索引中时，它就会发生：

#+begin_src sql
  select ntuples, ffactor, maxbucket, ovflpoint
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
  insert into t(n)
  select n from generate_series(1, 115) n;
  select nutples, ffactor, maxbucket, ovflpoint
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

最大bucket值已经增加到两个：现在我们有三个bucket，编号从0到2。 但是，尽管我们只增加了一个bucket，页面
的数量却增加了一倍：

#+begin_src sql
  select page, hash_page_type(get_raw_page('t_n_idx', page))
  from generate_series(0, 6) page;
#+end_src

[[./images/tNA8od.png]]

其中一个新页面被桶2使用，而另一个保持空闲，一旦出现就会被桶3使用。



#+begin_src sql
  select page, live_items, free_size, hasho_bucket
  from (values(1), (2), (4), (5)) p(page),
  hash_page_stats(get_raw_page('t_n_idx', page));
#+end_src

因此，从操作系统的角度来看，哈希指数是呈井喷式增长的，尽管从逻辑的角度来看，哈希表显示的是逐步增长。

为了在一定程度上平衡这种增长，并避免一次分配太多的页面，从第十次增加开始，页面将分四批平均分配，而不是一次全部分配。

元页的另外两个字段，实际上是位掩码，提供了关于bucket地址的细节：

#+begin_src sql
  select maxbucket, highmask::bit(4), lowmask::bit(4)
  from hash_metapage_info(get_raw_page('t_n_idx' , 0));
#+end_src

一个桶号是由对应于高掩码的哈希码位定义的。但如果收到的桶号不存在（超过了maxbucket），就会取低掩码位。1 在这种特
殊情况下，我们取两个最低位，这样就有了0到3的值；但如果我们得到3，我们就只取一个最低位，也就是用桶1而不是
桶3。

每次大小翻倍时，新的bucket页被分配为一个连续的chunk，而溢出页和位图页根据需要被插入这些片段之间。元页在备用数
组中保留了插入每个块的页数，这让我们有机会根据桶的数量用简单的算术来计算其主页的数量。

在这个特殊的案例中，第一次增加后插入了两个页面（一个位图页和一个溢出页），但第二次增加后还没有发生新的增加：

#+begin_src sql
  select spares[2], spares[3]
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

元页还存储了一个指向位图页的指针数组：

#+begin_src sql
  select mapp[1]
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

[[./images/xr92tr.png]]

当指向死元组的指针被移除时，索引页内的空间被释放出来。这发生在修剪页面的过程中（这是由试图将一个元素插入到一个完全
填充的页面中所引发的）1，或者是在进行常规回收的时候。

然而，散列索引不能缩减：一旦分配，索引页将不会返回到操作系统。主页面被永久地分配给它们的桶，即使它们根本不包含任何
元素；被清除的溢出页面在位图中被跟踪，可以被重新使用（可能被另一个桶使用）。减少索引的物理尺寸的唯一方法是使用
REINDEX或VACCUM FULL命令重建它

查询计划中没有显示索引类型：

#+begin_src sql
  create index on flights using hash(flight_no);
  explain (costs off)
  select * from flights where flight_no = 'PG0001';
#+end_src

** 操作类

在Postgre 10之前，哈希索引是没有记录的，也就是说，它们既没有对故障的保护，也没有复制，因此，不建议使用它们。但
即使如此，它们也有自己的价值。事情是这样的，散列算法被广泛使用（特别是执行散列连接和分组），系统必须知道哪种散列函数
可以用于某种数据类型。然而，这种对应关系不是静态的：它不能被一劳永逸地定义，因为Postgre 10允许在运行中添加新的数
据类型。因此，它是由散列索引和特定数据类型的运算器类来维护的。散列函数本身由该类的支持函数来表示：

#+begin_src sql
  select opfname as opfamily_name,
  amproc::regproc as opfamily_procedure
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_amproc amproc on amprocfamily=opf.oid
  where amname='hash'
  and amprocnum=1
  order by opfamily_name, opfamily_procedure;
#+end_src

这些函数返回32位整数。尽管它们没有被记录下来，但它们可以用来计算相应类型的值的哈希代码。

例如，text_ops系列使用hashtext函数：

#+begin_src sql
  select hashtext('one'), hashtext('two');
#+end_src

散列索引的运算符类只提供等于运算符：

#+begin_src sql
  select opfname as opfamily_name
  left(amopopr::regoperator::text, 20) as opfamily_operator
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_amop amop on amopfamily=opf.oid
  where amname='hash'
  order by opfamily_name, opfamily_operator;
#+end_src


** 属性

让我们看一下哈希访问方法赋予系统的索引级属性

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ])p(name)
  where a.amname = 'hash';
#+end_src

很明显，哈希索引不能用于行排序：哈希函数或多或少地随机混合了数据。

唯一性约束也不被支持。然而，哈希索引可以执行排除性约束，由于唯一支持的函数是等于，这种排除性达到了唯一性的含义：

#+begin_src sql
  alter table aircrafts_data
  add constraint unique_range exclude using hash(range with =);
  insert into aircrafts_data
  values('744', '{"ru":"Boeing 747-400"}', 11100);
#+end_src

多列索引和额外的INCLUDE列也不被支持。

索引级属性

#+begin_src sql
  select p.name, pg_index_has_property('flights_flight_no_idx', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backward_scan'
  ]) p(name);
#+end_src

散列索引同时支持常规的索引扫描和位图扫描。

不支持通过哈希索引进行表的聚类。这很符合逻辑，因为很难想象为什么可能需要根据哈希函数值对堆数据进行物理排序。

列级属性

#+begin_src sql
  select p.name,
  pg_index_column_has_property('flights_flight_no_idx', 1, p.name)
  from unnest(arrary[
  'asc', 'desc', 'nulls_first', 'nulls_last', 'orderable',
  'distance_orderable', 'returnable', 'search_array', 'search_nulls'
  ]) p(name);
#+end_src

由于散列函数不保留值的顺序，所有与排序有关的属性都不适用于散列索引。

散列索引不能参与仅有索引的扫描，因为它不存储索引键，需要堆访问。

散列索引不支持NULL值，因为等于操作对它们不适用。

对数组中的元素的搜索也没有实现。



* B-tree索引

** 概览
B树（实现为btree访问方法）是一种数据结构，它可以使你从树的根部往下走，快速找到树的叶子节点中的所需元素。为了使
搜索路径能够被明确地确定，所有的树元素必须是有序的。B树是为有序数数据类型设计的，其数值可以被比较和排序。
以下是代码上建立索引的示意图，内部节点是水平的矩形；叶子节点是垂直排列的。

[[./images/1nM4AH.png]]

每个树节点包含几个元素，这些元素由一个索引键和一个指针组成。内部节点元素引用下一级的节点；叶子节点元素引用堆图元
（图示中没有显示这些引用）。

B树具有以下重要特性：
+ 它们是平衡的，这意味着一棵树的所有叶子结点都位于相同的深度。因此，它们保证所有数值的搜索时间相等。
+ 在这个过程中，每个节点都有大量的分支，也就是说，每个节点都包含许多元素，通常是数百个（图中显示的是三元素节点，只
  是为了清晰起见）。因此，B树的深度总是很小，即使是非常大的表。
  #+begin_comment
  我们不能绝对肯定地说这种结构的名称中的字母B代表什么。平衡型和灌木型都同样适合。令人惊讶的是，你经常可以看到它被
  解释为二进制，这当然是不正确的。
  #+end_comment
+ 索引中的数据是按升序或降序排序的，在每个节点内和同一级别的所有节点中都是如此。对等节点被绑定到一个双向的列表中，因
  此可以通过简单地扫描列表来获得一个有序的数据集，而不必每次都从根部开始。


** 搜索和插入
*** 等值搜索
让我们来看看我们如何通过条件 "indexedcolumn = expression "在树中搜索一个值。我们将尝试找到KJA机场

搜索从根节点开始，访问方法必须确定要下降到哪个子节点。它选择Ki键，对于Ki⩽表达式<Ki+1是满足的。

根节点包含键AER和OVB。 条件AER⩽ KJA < OVB成立，所以我们需要下降到有AER键的元素所引用的子节点。

[[./images/jQgP3H.png]]


这个过程是递归重复的，直到我们到达包含所需元组ID的叶节点。在这种特殊情况下，子节点满足条件DME⩽ KJA < KZN，
所以我们必须下降到有DME键的元素所引用的叶节点。

你可以注意到，树的内部节点中最左边的键是多余的：要选择根的子节点，只要满足条件KJA < OVB就可以了。B树并不存储这
样的键，所以在接下来的插图中，我将把相应的元素留空。

叶子节点中的所需元素可以通过二进制搜索快速找到。

然而，搜索过程并不像它看起来那么简单。必须考虑到，索引中数据的排序顺序可以是升序，如上图所示，也可以是降序。即使是
一个唯一的索引也可以有几个匹配的值，而所有这些值都必须被返回。此外，可能会有很多重复的数据，以至于它们不适合一个节
点，所以邻近的叶子节点也要被处理。

由于一个索引可以包含非唯一的值，将其顺序称为非降序而不是升序（非升序而不是降序）会更准确。但我将坚持使用一个更简单
的术语。此外，元组ID是索引键的一部分，这让我们认为索引条目是唯一的，即使这些值实际上是相同的。

除此之外，在搜索过程中，其他进程可能会修改数据，页面可能会被分割成两个，树状结构可能会改变。所有的算法都是为了尽可能
地减少这些并发操作之间的争夺，避免过多的锁，但我们在这里不打算讨论这些技术问题。

*** 不等值搜索
如果按条件 "索引列⩽表达式"（或 "索引列⩾表达式"）进行搜索，我们必须首先在索引中搜索满足平等条件的值，然后按要求的
方向遍历其叶子节点，直到到达树的末端。

这张图说明了搜索小于或等于DME的机场代码。

[[./images/V61w6w.png]]

对于小于和大于运算符，过程是相同的，只是必须排除第一个发现的值。

*** 范围搜索

当按范围 "expression1 ⩽ 索引列 ⩽ expression2 "搜索时，我们必须首先找到expression1，然后沿正确方向遍历叶
子节点，直到找到expression2。这张图说明了在LED和ROV之间（含）搜索的过程。

[[./images/wgP1TQ.png]]


*** 插入
新元素的插入位置是由键的顺序明确定义的。例如，如果你在表中插入RTW机场代码（萨拉托夫），新元素将出现在最后一个
叶子节点，在ROV和SGC之间。

但是，如果叶子节点没有足够的空间容纳新的元素呢？例如（假设一个节点最多可以容纳三个元素），如果我们插入TJM机场代
码，最后一个叶子节点将被过度填充。在这种情况下，节点会被分成两个，旧节点的一些元素被移到新节点中，而新的子节点的
指针会被添加到父节点中。很明显，父节点也会被填满。然后它也被分割成两个节点，以此类推。如果要拆分根节点，则在产生
的节点上方再创建一个节点，成为树的新根。在这种情况下，树的深度会增加一级。

在这个例子中，TJM机场代码的插入导致了两个节点的分裂；由此产生的新节点在下图中被突出显示。为了确保任何节点都能被
拆分，双向列表绑定了所有级别的节点，而不仅仅是最低级别的节点。

[[./images/Mkersy.png]]

所描述的插入和拆分程序保证了树保持平衡，由于一个节点可以容纳的元素数量通常相当大，所以树的深度很少增加。

问题是，一旦被分割，节点就不能被合并在一起，即使它们在清理回收后只包含很少的元素。这个限制不是与树形数据结构本身有
关，而是与它的Postgre实现有关。因此，如果在尝试插入时，节点被证明是满的，访问方法首先尝试修剪多余的数据，以清
除一些空间，避免额外的分裂。

** 页布局
B树的每个节点需要一个页面。该页的大小定义了节点的容量。

由于页面的分割，树的根部在不同的时间可以由不同的页面来代表。但是搜索算法必须总是从根开始扫描。它在零索引页（称为
metapage）中找到当前根页的ID。metapage还包含一些其他的元数据。

[[./images/Zikz1R.png]]

索引页中的数据布局与我们到目前为止所看到的有点不同。所有的页面，除了每一级的最右边，都包含一个额外的 "高键"，它保
证不比这一页的任何键小。在上图中，高键被突出显示。

让我们使用pageinspect扩展来看看一个建立在六位数的预订参考上的真实索引的一个页面。metapage列出了根页面ID和
树的深度（级别编号从叶子节点开始，以0为基础）：

#+begin_src sql
  select root, level
  from bt_metap('bookings_pkey')
#+end_src

存储在索引项中的键被显示为字节序列，这其实并不方便：

#+begin_src sql
  select data
  from bt_page_items('bookings_pkey', 290)
  where itemoffset=2;
#+end_src

为了破译这些值，我们将不得不写一个特设的函数。它不支持所有的平台，也可能对某些特定的场景不起作用，但它对本章的例子
来说是可行的：

#+begin_src sql
  create function data_to_text(data text)
  returns text
  as $$
  declare
  raw bytea := ('\x' || replace(data, ' ', ''))::bytea;
  pos integer := 0;
  len integer;
  res text := '';
  begin
  while(octet_length(raw) > pos)
  loop
  len := (get_byte(raw, pos)-3)/2;
  exit when len<=0;
  if pos>0 then
  res := res || ', ';
  end if;
  res := res || (
  select string_agg( chr(get_byte(raw, i)), '')
  from generate_series(pos+1, pos+len) i
  );
  pos := pos+len+1;
  end loop;
  return res;
  end;
  $$ LANGUAGE plpgsql
#+end_src

现在我们可以看一下根页面的内容了：

#+begin_src sql
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('bookings_pkey', 5135);
#+end_src

正如我所说的，第一个条目不包含键。ctid列提供了指向子页面的链接。

需要在booking查找E2D725.在这个例子中，必须选择19到页5135

#+begin_src sql
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('bookings_pkey', 5135);
#+end_src

本页的第一个条目包含了高调，这可能看起来有点出乎意料。从逻辑上讲，它应该被放在页面的末尾，但从实现的角度来看，把它
放在开头更方便，以避免每次页面内容发生变化时移动它。这里我们选择条目3，然后下到页面11919。

#+begin_src sql
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('bookings_pkey', 5133);
#+end_src

它是索引的一个叶子页。第一个条目是高键；所有其他条目都指向堆元组

这是bookings元组数据

#+begin_src sql
  select * from bookings
  where ctid='(11919, 77)'
#+end_src

这是bookings表中搜索，低层次执行的操作

#+begin_src sql
  explain (costs off)
  select * from bookings
  where book_ref='E2D725';
#+end_src

重复数据删除

非唯一的索引可能包含很多重复的键，这些键指向不同的堆元组。由于非唯一的键会出现不止一次，因此会占用很多空间，重复的
键会被折叠成一个索引条目，其中包含键和相应元组ID的列表。在某些情况下，这个程序（被称为重复数据删除）可以大大
减少索引的大小。

然而，由于MVCC的原因，唯一索引也可能包含重复的内容：一个索引会保留对表行所有版本的引用。HOT更新的机制可以帮助
你回收因引用过时的、通常是很短的行版本而导致的索引膨胀，但有时它可能并不适用。在这种情况下，重复数据删除可以争取一
些时间来删除多余的堆元组，并避免额外的页面分割。

为了避免在重复数据删除没有带来直接好处的情况下浪费资源，只有在叶子页没有足够的空间来容纳一个更多的元组时才会进行折
叠。然后页面修剪和重复数据删除可以释放一些空间，并防止不希望的页面分割。然而，如果重复的情况很少，你可以通过关闭
deduplicate_items存储参数来停用重复数据删除功能。

一些索引不支持重复数据删除。主要的限制是，键的相等必须通过简单的二进制比较它们的内部表示来检查。到目前为止，并非
所有的数据类型都可以通过这种方式进行比较。例如，浮点数（浮点数和双精度）对零有两种不同的表示。任意精度的数字
（numeric）可以用不同的尺度表示一个相同的数字，而jsonb类型可以使用这样的数字。如果你使用非确定性排序4，允许
相同的符号由不同的字节序列来表示，那么文本类型也不可能进行重复数据删除（标准排序是确定性的）。

此外，对于复合类型、范围和数组，以及用INCLUDE子句声明的索引，目前不支持重复数据删除。

要检查一个特定的索引是否可以使用重复数据删除，你可以看一下其metapage中的allequalimage字段：

#+begin_src sql 
  create index on tickets(book_ref);
  select allequalimage from bt_metap('tickets_book_ref_idx');
#+end_src

在这种情况下，重复数据删除得到了支持。而事实上，我们可以看到，其中一个叶子页既包含有单一元组ID( htid)的索引条目，
也包含有IDS(tids)的列表：

#+begin_src sql
  select itemoffset, htid, left(tids::text, 27) tids,
  data_to_text(data) as data
  from bt_page_items('tickets_book_ref_idx', 1)
  where itemoffset > 1;
#+end_src

内部索引条目的存储

重复数据删除能够在索引的叶子页中容纳更多的条目。但是，即使叶子页构成了索引的大部分，在内部页中进行的数据压缩以防止额
外的分裂也同样重要，因为搜索效率直接取决于树的深度。

内部索引条目包含索引键，但是它们的值只用来确定搜索时要下到的子树。在多列索引中，通常取第一个关键属性（或几个第一属
性）就足够了。其他属性可以被截断以节省页面空间。这种后缀截断发生在一个叶子页被分割，而内部页必须容纳一个新的指针的
时候。

#+begin_comment
  理论上，我们甚至可以更进一步，只保留属性的有意义的部分，例如，一行的前几个符号足以区分子树。但是现在还没有实现：
  一个索引条目要么包含整个属性，要么完全排除这个属性。
#+end_comment

例如，这里是建立在机票表上的索引的根页面的几个条目，包含booking引用的passenger_name列：

#+begin_src sql
  create index tickets_bref_name_idx
  on tickets(book_ref, passenger_name);
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('tickets_bref_name_idx', 229)
  where itemoffset between 8 and 13;
#+end_src

我们可以看到，一些索引条目没有第二个属性。

当然，叶子页必须保留所有的键属性和INCLUDE列值（如果有的话）。否则，就不可能进行仅有索引的扫描了。唯一的例外是
高键；它们可以被部分保留。

** 操作类

比较语义

除了散列值之外，系统还必须知道如何对各种类型的值进行排序，包括自定义的值。这对于排序、分组、合并连接和其他一些操作来
说是不可缺少的。而就像散列的情况一样，特定数据类型的比较运算符是由运算符类定义的。

操作符类允许我们从名称中抽象出来（如>、<、=），甚至可以提供几种方法来排列同一类型的值。

下面是必须在btree方法的任何运算符类中定义的强制性比较运算符（所示为bool_ops系列）：

#+begin_src sql
  select amopopr::regoperator as opfamily_operator,
  amopstrategy
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_amop amop on amopfamily=opf.oid
  where amname='btree' and opfname='bool_ops'
  order by amopstrategy;
#+end_src

这五个比较运算符中的每一个都对应于一个策略，这就定义了它们的语义：

1. 小于
2. 小于或等于
3. 等于
4. 大于或等于
5. 大于

一个B-树操作符类还包括几个支持函数。3 第一个必须返回1，如果它的第一个参数大于第二个参数，-1，如果它小于第二个参
数，0，如果参数相等。其他支持函数是可选的，但它们可以提高访问方法的性能。

为了更好地理解这一机制，我们可以定义一个具有非默认排序的新数据类型。文档中给出了一个关于复数的例子，1但它是用C语
言写的。幸运的是，B-树操作符类也可以用解释语言来实现，所以我将利用它，做一个尽可能简单的例子（即使是明知效率低下）。

让我们为信息单元定义一个新的复合类型：

#+begin_src sql
  create type capacity_unit as enum (
   'B', 'kB', 'MB','GB', 'TB','PB'
   );
   create type capacity as (
   amount integer,
   unit capacity_unit
   );
#+end_src

现在创建一个带有新类型的列的表，并用随机值填充它：

#+begin_src sql
  create table test as
  select ((random()*1023)::integer, u.unit)::capacity as cap
  from generate_series(1,100),
     unnest(enum_range(NULL::capacity_units)) as u(unit);
#+end_src

默认情况下，复合类型的值是按词汇表顺序排序的，这与这种特定情况下的自然顺序不一样：

#+begin_src sql
  select * from test order by cap;
#+end_src

现在让我们开始创建我们的操作者类。我们将首先定义一个将体积转换为字节的函数：

#+begin_src sql
  create function capacity_to_bytes(a capacity) returns numeric
  as $$
  select a.amount::numeric *
  1024::numeric ^ (array_position(enum_range(a.unit), a.unit) -1 );
  $$ language sql strict immutable;
  select capacity_to_bytes((1, kB)::capacity);
#+end_src

为该数据类型创建一个操作者函数

#+begin_src sql
  create function capacity_cmp(a capacity, b capacity)
  returns integer
  as $$
  select sign(capacity_to_bytes(a)-capacity_to_bytes(b));
  $$ language sql strict immutable;
#+end_src

现在，使用这个支持函数来定义比较运算符是很容易的。我故意使用奇特的名字来证明它们可以是任意的：

#+begin_src sql
  create function capacity_lt(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b)<0;
  end;
  $$ language plpgsql immutable strict;

  create operator #<# (
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_lt
  );
#+end_src

其他四个运算符的定义与此类似。

#+begin_src sql
  create function capacity_le(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b) <= 0;
  end;
  $$  language plpgsql immutable strict;
  create operator #<=# (
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_le
  );
#+end_src

#+begin_src sql
  create function capaity_eq(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b) = 0;
  end;
  $$ language plpgsql immutable strict;
  create operator #=#(
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_eq,
  merges -- can be used in merge joins
  );
#+end_src

#+begin_src sql
  create function capacity_ge(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a, b) >= 0;
  end;
  $$ language plpgsql immutable strict;
  create operator #>=#(
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_ge
  );
#+end_src

#+begin_src sql
  create function capacity_gt(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b) > 0;
  end;
  $$ language plpgsql immutable strict;
  create operator #>#(
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_gt
  );
#+end_src

在这个阶段，我们已经可以进行比较:

#+begin_src sql
  select (1, 'MB')::capacity #># (512, 'KB')::capacity
#+end_src

一旦操作者类被创建，排序也将按预期开始工作：

#+begin_src sql
  create operator class capacity_ops
  default for type capacity -- to be used by default
  using btree as
  operator 1 #<#,
  operator 2 #<=#,
  operator 3 #=#,
  operator 4 #>=#,
  operator 5 #>#,
  function 1 capacity_cmp(capacity, capacity);
  select * from test order by cap;
#+end_src

当一个新的索引被创建时，我们的操作者类被默认使用，这个索引以正确的顺序返回结果：

#+begin_src sql
  create index on test(cap);
  select * from test where cap #<# (100, 'B')::capacity
  order by cap;
  explain (consts off) select *
  from test where cap #<# (100, 'B')::capacity order by cap;
#+end_src

在平等运算符声明中指定的MERGE子句可以对该数据类型进行合并连接。

多列索引和排序

让我们仔细看看多列索引的排序问题。

首先，在声明索引时，选择最佳的列序是非常重要的：页面内的数据排序将从第一列开始，然后转到第二列，以此类推。多列索引
只有在所提供的过滤条件从第一列开始跨越一个连续的序列时才能保证高效的搜索：第一列、前两列、第一列和第三列之间的范围，
等等。其他类型的条件只能用于过滤掉根据其他标准获取的多余的值。

下面是在tickets表上创建的索引的第一叶页中的索引条目顺序，其中包括tickets引用的乘客姓名：

#+begin_src sql
  select itemoffset, data_to_text(data)
  from bt_page_items('tickets_bref_name_idx', 1)
  where itemoffset > 1;
#+end_src

在这种情况下，只有通过订票信息和乘客姓名，或仅通过订票信息，才能有效地搜索到票。

#+begin_src sql
  explain (costs off) select *
  from tickets
  where book_ref = '000010';
#+end_src

#+begin_src sql
  explain (costs off) select *
  from tickets
  where book_ref='000010' and passenger_name='LYUDMILA BOGDANOVA';
#+end_src

但如果我们决定寻找一个乘客的名字，我们必须扫描所有的行：

#+begin_src sql
  explain (costs off) select *
  from tickets
  where passenger_name='LYUDMILA BOGDANOVA';
#+end_src

即使规划器选择执行索引扫描，所有的索引条目仍然要被遍历。不幸的是，规划器不会显示条件实际上只用于过滤结果。

#+begin_comment
如果第一列没有太多不同的值v1, v2, ... vn，那么在相应的子树上执行几次就会有好处，实际上就是用一系列的搜索条件
"col2 = value "来代替一次搜索：col1 = v1 and col2 = value col1 = v2 and col2 = value ⋯ col1 = vn
and col2 = value 这种类型的索引访问被称为跳过扫描，但是它还没有实现。
#+end_comment

反之亦然，如果在乘客姓名和订票号码上创建索引，它将更适合通过乘客姓名单独查询，或者同时查询乘客姓名和订票参考：

#+begin_src sql
  create index tickets_name_bref_idx
  on tickets(passenger_name, book_ref);
  select itemoffset, data_to_text(data)
  from bt_page_items('tickets_name_bref_idx', 1)
  where itemoffset > 1;
  explain (costs off) select * from tickets
  where passenger_name='LYUDMILA BOGDANOVA';
#+end_src

除了列的顺序之外，在创建新的索引时，你还应该注意排序顺序。默认情况下，数值是按升序排序的（ASC），但如果需要的话，你
可以把它倒过来（DESC）。如果一个索引是在单列上建立的，这并不重要，因为它可以在任何方向上被扫描。但是在一个多列索引
中，顺序就变得很重要了。

我们新创建的索引可以用来检索按两列升序或降序排序的数据：

#+begin_src sql
  explain(costs off) select *
  from tickets
  order by passenger_name, book_ref;
  explain (costs off) select *
  from tickets order by passenger_name desc, book_ref desc;
#+end_src

但是，如果需要同时按一列升序排序和按另一列降序排序，这个索引就不能马上返回数据。在这种情况下，索引提供的是部分排序
的数据，必须按第二个属性进一步排序：

#+begin_src sql
  explain (costs off) select *
  from tickets order by passenger_name asc, book_ref desc;
#+end_src

NULL值的位置也会影响到使用索引进行排序的能力。默认情况下，NULL值在排序时被认为比普通值 "大"，也就是说，如果排序
顺序是升序，它们就位于树的右侧，如果排序顺序是降序，它们就位于左侧。NULL值的位置可以通过NULL LAST和NULL
FIRST子句来改变。

在下一个例子中，索引不满足ORDER BY子句，所以必须对结果进行排序：

#+begin_src sql
  explain (costs off) select *
  form tickets order by passenger_name nulls first, book_ref desc;
#+end_src

但是，如果我们创建一个遵循所需顺序的索引，它将被使用：

#+begin_src sql
  create index tickets_name_bref_idx2
  on tickets(passenger_name nulls first, book_ref desc);
  explain (costs off) select *
  from tickets order by passenger_name nulls first, book_ref desc;
#+end_src

** 属性
让我们来看看B树的接口属性。

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include']) p(name)
  where a.amname='btree';
#+end_src

B树可以对数据进行排序并确保其唯一性。它是唯一具有这种特性的访问方法。

许多访问方法都支持多列索引，但由于B树中的值是有序的，所以你必须密切注意索引中各列的顺序。

从形式上看，支持排除式约束，但它们仅限于平等条件，这使得它们类似于唯一约束。使用成熟的唯一约束更为可取。

B树索引也可以用额外的不参与搜索的INCLUDE列来扩展。

索引级的属性

#+begin_src sql
  select p.name, pg_index_has_property('flights_pkey', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backward_scan'
  ])p(name)
#+end_src

B树索引可用于集群化。

索引扫描和位图扫描都被支持。由于叶子页被绑定成一个双向的列表，一个索引也可以被反向遍历，这将导致反向的排序顺序：

#+begin_src sql
  explain (costs off) select *
  from bookings order by book_ref desc;
#+end_src

列级属性

#+begin_src sql
  select p.name
  pg_index_column_has_property('flight_pkey', 1, p.name)
  from unnest(array[
  'asc', 'desc', 'nulls_first', 'nulls_last', 'orderable',
  'distance_orderable', 'returnable', 'search_array', 'search_nulls'
  ])p(name);
#+end_src

ORDERABLE 属性表示存储在 B 树中的数据是有序的，而前四个属性（ASC 和 DESC、NULLS FIRST 和 NULLS LAST）定义
了特定列中的实际顺序。在这个例子中，列值是按升序排序的，NULL值列在最后。

SEARCH NULLS 属性指示是否可以搜索 NULL 值。

B树不支持排序运算符（DISTANCE ORDERABLE），尽管已经试图实现它们。

B-树支持在一个数组中搜索多个元素（SEARCH ARRAY属性），并且可以在不访问堆的情况下返回结果数据（RETURNABLE）。



* GiST

** 概要
GiST(广义搜索树)是一种访问方法，它实际上是平衡搜索树的广义化，适用于支持值的相对定位的数据类型。B-树的适用性仅限于
允许比较操作的序数类型（但为此类类型提供的支持极为高效）。至于GiST，它的操作符类允许为数据在树中的分布定义任意的标
准。GiST索引可以容纳空间数据的R树、集合的RD树以及任何数据类型（包括文本和图像）的签名树。

得益于可扩展性，你可以通过实现索引引擎的接口，在 PostgreSQL 中从头开始创建一个新的访问方法。然而，除了设计索引逻
辑，您还必须定义页面布局、有效的锁定策略和WAL支持。这一切都需要强大的编程能力和大量的实施工作。GiST简化了这一任
务，解决了所有底层技术问题，并为搜索算法提供了基础。要在新的数据类型中使用GiST方法，只需添加一个新的运算符类，其
中包括十几个支持函数。与为B树提供的琐碎的操作符类不同，这样的类包含了大部分的索引逻辑。在这方面，GiST可以被视为
构建新访问方法的框架。

一般来说，属于叶子节点的每个条目（叶子条目）都包含一个谓词（逻辑条件）和一个堆元组 ID。索引关键字必须满足谓词的要
求；至于关键字本身是否属于该条目，则无关紧要。

内叶中的每个条目（内条目）也包含一个谓词和一个指向子节点的引用；子子树的所有索引数据都必须满足这个谓词。换句话说，内
部条目的谓词是其所有子条目谓词的联合。GiST的这一重要特性为B树的简单排序提供了服务。

GiST树搜索依赖于一致性函数，这是运算符类定义的支持函数之一。

一致性函数在索引条目上调用，以确定该条目谓词是否与搜索条件（"索引列运算符表达式"）"一致"。对于内条目，它显示我们是
否必须进入相应的子树；对于叶条目，它检查其索引键是否满足条件。

搜索从根节点开始，这是典型的树形搜索。一致性函数决定了哪些子节点必须遍历，哪些可以跳过。与B树不同，GiST索引可能
有多个这样的节点。由一致性函数选择的叶节点条目将作为结果返回。

搜索总是深度优先的：算法试图尽快进入叶页。因此，它可以立即开始返回结果，如果用户只需要得到前几行，这就非常有意义了。

要在 GiST树中插入一个新值，不可能使用一致性函数，因为我们需要选择一个节点作为下行节点。

就像在 B 树中一样，被选中的节点可能没有空闲空间，从而导致拆分。这一操作还需要两个函数，其中一个在新旧节点之间分配条
目；另一个形成两个谓词的联合，以更新父节点的谓词。

随着新值的不断增加，现有的谓词也在不断扩充，通常只有在拆分页面或重建整个索引时才会缩小谓词的范围。因此，GiST索引的
频繁更新会导致其性能下降。

由于所有这些理论讨论可能显得过于空泛，而且确切的逻辑大多取决于特定的运算符类，因此我将提供几个具体的例子。

** 积分R树

第一个示例涉及平面上点（或其他几何图形）的索引。常规的B树不能用于这种数据类型，因为没有为点定义比较运算符。显然，
我们可以自己实现这样的运算符，但几何图形需要索引支持完全不同的运算。我将只介绍其中的两种：搜索特定区域内的对象和最近
邻搜索。

B-树在平面上绘制矩形，这些矩形必须覆盖所有索引点。索引项存储了边界框，谓词可定义如下：点位于此边界框内。

B型树的根节点包含几个大矩形（也可能重叠）。子节点包含与其父节点相匹配的较小矩形，它们共同覆盖所有底层点。

叶节点应包含索引点本身，但GiST要求所有条目具有相同的数据类型；因此，叶条目也用矩形表示，矩形被简单地简化为点。

为了更直观地展示这种结构，让我们来看一看在机场坐标上建立的三层 B 树。在这个示例中，我将演示数据库中的机场表扩展到了
五千行。此外，我还降低了填充因子值，以使树更深；默认值将为我们提供一个单层树。

#+begin_src sql
  create table airports_big as
  select * from airports_big;
  copy airports_big from
  '/home/student/internals/airports/extra_airports.copy';
  create index airports_gist_idx on airports_big
  using gist(coordinates) with (fillfactor=10);
#+end_src

在上层，所有的点都包含在几个（部分重叠的）边界框中：

[[./images/kKZ3ML.png]]

在下一层，大矩形被分割成小矩形：

[[./images/Poc8It.png]]


最后，在树的内层，每个边界框包含的点数与单页所能容纳的点数相同：

[[./images/zboFkn.png]]


该索引使用point_ops运算符类，这是唯一可用的点运算符类。

矩形和任何其他几何图形都可以用同样的方式进行索引，但索引必须存储对象的边界框，而不是对象本身。

页面布局

可以使用pageinspect扩展来研究GiST页面。

与B树索引不同，GiST没有元页，零页总是树的根。如果根页面被拆分，旧的根页面将被移至一个单独的页面，而新的根页面将
取而代之。

以下是根页面的内容：

#+begin_src sql
  select ctid, keys
  from gist_page_items(
   get_raw_page('airports_gist_idx', 0), 'airports_gist_idx'
   );
#+end_src


这四行对应于第一幅图中上层的四个矩形。遗憾的是，这里的键是以点的形式显示的（这对叶页来说是合理的），而不是以矩形的形
式显示的（这对内页来说更合理）。但我们可以随时获取原始数据并自行解释。

#+begin_comment
  要提取更详细的信息，可以使用gevel扩展，它不包含在标准的PostgreSQL发行版中。
#+end_comment

操作类

下面的查询返回实现树的搜索和插入操作逻辑的支持函数列表：

#+begin_src sql
  select amprocnum, amproc::regproc
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amproc amop on amprocfamily=opcfamily
  where amname='gist'
  and opcname='point_ops'
  order by amprocnum;
#+end_src


上面已经列出了必须具备的功能：

1. 在搜索过程中用于遍历树的一致性函数
2. union函数合并矩形
3. penalty函数，用于在插入条目时选择下行子树
4. picksplit函数，用于在页面分割后在新页面之间分配条目
5. same函数检查两个键是否相等

point_ops运算符类包括以下运算符：

#+begin_src sql
  select amopopr::regoperator, amopstrategy as st, oprcode::regproc,
  left(obj_description(opr.oid, 'pg_operator'), 19) descrioption
  from pg_am am
  join pg_opclass opc on opcmethod = am.oid
  join pg_amop amop on amopfamily = opcfaimly
  join pg_operator opr on opr.oid = amopopr
  where amname = 'gist'
  and opcname = 'point_ops'
  order by amopstrategy;
#+end_src

运算符名称通常不会告诉我们太多关于运算符的语义，因此该查询也会显示底层函数的名称及其描述。所有运算符都以这种或那种
方式处理几何图形的相对位置（左侧、右侧、上方、下方、包含、被包含）以及它们之间的距离。

与 B 树相比，GiST 提供了更多的策略。有些策略编号是几种索引1 的共用编号，而有些则是通过公式计算得出的（例如，28、
48和68实际上代表了同一种策略：矩形、多边形和圆形都包含这种策略）。此外，GiST还支持一些过时的运算符名称
（<<| 和 |>>）。

操作符类可能只实现部分可用策略。例如，点的运算器类不支持包含策略，但是在为具有可测量面积的几何体定义的类（box_ops、
poly_ops 和 circle_ops）中可以使用包含策略。

容器元素的搜索

一个典型的查询可以通过索引加快速度，返回指定区域内的所有点。

例如，我们可以找到所有距离莫斯科市中心1度以内的机场：

#+begin_src sql
  select airport_code, airport_name->>'en'
  from airports_big
  where coordinates <@ '<(37.622513, 55.753220), 1.0>'::circle;

  expalin (costs off) select airport_code
  from airports_big
  where coordinates <@ '<(37.622513, 55.753220), 1.0>'::circle;
#+end_src

我们可以通过下图中的一个微不足道的例子来详细了解这个运算符：

[[./images/h0GqE7.png]]


如果以这种方式选择边界框，索引结构将如下所示：

[[./images/anbOi7.png]]

包含运算符 <@ 确定特定点是否位于指定的矩形内。如果索引项的矩形与该矩形有公共点，则该操作符的一致性函数返回 "yes"。
这意味着，对于叶节点条目（存储简化为点的矩形），该函数确定点是否包含在指定的矩形中。

例如，让我们找出矩形(1,2)-(4,7)的内点，如下图所示：

[[./images/Hka1hm.png]]


[[./images/F4qXea.png]]


搜索从根节点开始。边界框与(0,0)-(3,4)重叠，但与(5,3)-(9,9)不重叠。这意味着我们不必进入第二个子树。

在下一层，边界框与 (0,3)-(3,4) 重叠，并触及 (0,0)-(3,2) ，因此我们必须检查这两个子树。

一旦我们到达叶节点，我们只需遍历其包含的所有点，并返回满足一致性函数的点。

B树搜索总是选择一个子节点。然而，GiST搜索可能需要扫描多个子树，特别是当它们的边界框重叠时。

最近邻搜索

索引支持的大多数操作符（如前面示例中的=或<@）通常被称为搜索操作符，因为它们定义了查询中的搜索条件。这些操作符是谓词，
也就是说，它们返回一个逻辑值。

但是还有一组排序操作符，它们返回参数之间的距离。此类操作符在ORDER BY子句中使用，通常由具有DISTANCE ORDERABLE
属性的索引支持，它能够快速查找指定数量的近邻。这种类型的搜索被称为k-NN或k-近邻搜索。

例如，我们可以找到离科斯特罗马最近的10个机场：

#+begin_src sql
  select airport_code, airport_name->>'en'
  from airports_big
  order by coordinates <-> '(40.926780, 57.767943)'::point
  limit 10;

  explain (costs off) select airport_code
  from airports_big
  order by coordinates <-> '(40.926780, 57.767943)'::point
  limit 5;
#+end_src

由于索引扫描会逐个返回结果，并且可以随时停止，因此可以很快找到几个首值。

#+begin_comment
 如果没有索引支持，很难实现高效搜索。我们必须找到特定区域内出现的所有点，然后逐步扩大该区域，直到返回所需的结果数。
 这将需要多次索引扫描，更不用说选择原始区域大小及其增量的问题了。
#+end_comment

您可以在系统目录中看到运算符类型（"s "表示搜索，"o "表示排序运算符）：

#+begin_src sql 
        select amopopr::regoperator, amoppurpose, amopstrategy 
      from pg_am am 
      join pg_opclass opc on opcmethod=am.oid 
      join pg_amop amop on amopfamily=opcfamily 
      where amname='gist' 
      and opcname='point_ops'  
  order by amopstrategy;
#+end_src

为了支持这种查询，操作符类必须定义一个额外的支持函数：它是距离函数，在索引条目上调用它来计算从存储在这个条目中的值
到其他值的距离。

对于表示索引值的叶元素，该函数必须返回与该值的距离。在点的情况下，它是一个常规的欧几里得距离，等于
#+begin_export latex
\sqrt((x_{2}-x_{1})^{2}-(y_{2}-y_{1})^{2}
#+end_export

对于一个内部元素，函数必须返回它与其子叶元素之间所有可能距离的最小值。由于扫描所有子元素的成本很高，函数可以乐观地
低估距离（牺牲效率），但绝不能返回更大的值--这会影响搜索的正确性。

因此，对于由边界框表示的内部元素，点到点的距离可以从常规数学意义上理解：要么是点到矩形之间的最小距离，要么如果点在
矩形内部则距离为零。这个值很容易计算，不需要遍历矩形的所有子点，并且保证不大于到这些点中任何一点的距离。

让我们考虑搜索点(6,8)的三个近邻的算法：

[[./images/AO2UAo.png]]


搜索从根节点开始，根节点包含两个边界框。从指定点到矩形 从指定点到矩形(0,0)-(3,4)的距离为到矩形角(3.4)的距离，等于
5.o。到(5,3)-(9,9)的距离为 0.0。这里所有的值都四舍五入到小数点后第一位；这样的精度在本例中就足够了。对于本例来说，
这样的精度已经足够了）。

我们再次选择右侧子树，进入包含三个点的叶节点：距离为 2.0 的 (6,6)，距离为 2.2 的 (8,9)，以及距离为 3.2 的
(9,7)。

[[./images/xXOaiY.png]]

因此，我们得到了前两个点：(6,6) 和 (8,9)。但是到这个节点的第三个点的距离大于到矩形(5,3)-(8,5)的距离。

因此，现在我们必须进入包含两个点的左侧子节点。到点 (8,5) 的距离是 3.6，而到点 (5,3) 的距离是 5.1。事实证明，前
一个子节点中的点(9,7)比左侧子树的任何一个节点都更靠近点(6,8)，因此我们可以将其作为第三个结果返回。

[[./images/UenfK8.png]]

本例说明了内部条目的距离函数必须满足的要求。由于矩形(5,3)-(8,5)的距离减小（从3.6减小到3.0），多扫描了一个节
点，因此搜索效率下降；但是算法本身仍然是正确的。

插入操作

当一个新的键插入到B树中时，该键所使用的节点由penalty函数决定：边界框的大小必须尽可能小。

例如，点(4,7)将被添加到矩形(5,3)-(9,9)中，因为其面积仅增加 6 个单位，而矩形(0,0)-(3,4)的面积将增加 12 个单位。
在下（叶）层，按照同样的逻辑，该点将添加到矩形(6,6)-(9,9)中。
[[./images/sdy7bb.png]]


假设一个页面最多包含三个元素，则必须将其一分为二，并在新的页面之间分配元素。在这个例子中，结果似乎是显而易见的，但在
一般情况下，数据分配任务并不那么简单。首先，picksplit函数试图最小化边界框之间的重叠，目的是获得更小的矩形和页面之
间点的均匀分布。

[[./images/QpjdZO.png]]


排他性约束

GiST索引也可用于排除约束中。

排除约束保证任意两个堆元组的指定字段在某些操作符的意义上不相互匹配。必须满足以下条件：

+ 排除约束必须由索引方法（CAN Exclude属性）支持。
+ 操作符必须属于该索引方法的操作符类。
+ 运算符必须是交换的，即 "a运算符b = b运算符a "的条件必须为真。

对于上面提到的哈希树和 btree 访问方法，唯一合适的操作符是 equal to。它实际上将一个排除约束变成了唯一约束，这并不
是特别有用。

GiST方法有两种更适用的策略：

+ 重叠：&&运算符
+ djacency: -|- 运算符 (为区间定义)

为了尝试一下，让我们创建一个约束条件，禁止机场之间距离太近。这个条件可以表述为：以机场坐标为圆心的特定半径的圆不能
重叠：

#+begin_src sql
  alter table aiports_data add exclude
  using gist (circle(coordinates, 0.2) with &&);
  insert into aiports_data(
  aiport_code, airport_name, city, coordinates, timezone
  ) values (
   'ZIA', '{}', '{"en":"Moscow"}', point(38.1517, 55.5533),
   'Europe/Moscow'
   );
#+end_src

当定义排除约束时，会自动添加一个用于执行该约束的索引。这里是在表达式上建立的GiST索引。

让我们来看一个更复杂的例子。假设我们需要允许机场之间的距离很近，但前提是它们必须属于同一个城市。一个可能的解决方案
是定义一个新的完整性约束，它可以表述如下：如果圆的中心位于机场坐标处，并且相应的城市名称不同，则禁止存在圆相交(&&)
的行对(!=)。

由于没有文本数据类型的操作符类，尝试创建这样的约束会导致错误：

#+begin_src sql
  alter table aiports_data
  drop constraint aiports_data_circle_excl;
  alter table aiports_data add exclude using gist(
  circle(coordinates, 0.2) with && ,
          (city->>'en') with !=
          );
#+end_src

然而，GiST 确实提供了诸如 strictly left of、 strictly right of 和 same 等策略，这些策略也可以应用于常规的
序数数据类型，例如数字或文本字符串。btree_gist扩展专门用于实现GiST对通常用于B树的操作的支持：

#+begin_src sql
  create extension btree_gist;
  alter table aiports_data add exclude using gist(
   circle(coordinates, 0.2) with &&,
       (city->>'en') with !=
       );
#+end_src

约束条件已创建。现在我们不能添加属于同名城镇的茹科夫斯基机场，因为莫斯科机场太近了：

#+begin_src sql
  insert into aiports_data(
  airport_code, aiport_name, city, coordinates, timezone
  )values (
  'ZIA', '{}', '{"en":"Zhukovskey"}', point(38.1517, 55.5533),
  'Europe/Moscow');
#+end_src

但是，如果我们指定莫斯科为该机场的城市，我们就可以做到这一点：

#+begin_src sql
  insert into aiports_data(
  aiport_code, aiport_name, city, coodrinates, timezone
  ) values (
  'ZIA', '{}', '{"en":"Moscow"}', point(38.1517, 55.5533),
  'Europe/Moscow');
#+end_src

需要记住的是，尽管 GiST 支持大于、小于和等于操作，但 B 树在这方面的效率要高得多，尤其是在访问数值范围时。因此，只
有当GiST索引确实是出于其他合理的原因时，使用上面的btree_gist扩展才是有意义的。

属性

访问方法属性，GiST方法有如下属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ]) p(name)
  where a.amname='gist';
#+end_src

不支持唯一约束和排序。

GiST索引可以创建额外的INCLUDE列

我们知道，我们可以在多个列上建立索引，也可以在完整性约束中使用索引。

索引级属性 这些属性在索引级别上定义：

#+begin_src sql
  select p.name, pg_index_has_property('airports_gist_idx', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backward_scan'
  ])p(name);
#+end_src

GiST索引可用于聚类。

在数据检索方法方面，支持常规（逐行）索引扫描和位图扫描。但是，不允许对GiST索引进行后向扫描。

列级属性

#+begin_src sql
  select p.name,
  pg_index_column_has_property('airports_gist_idx', 1, p.name)
  from unnest(array[
  'orderable', 'search_array', 'search_nulls'
  ])p(name);
#+end_src

禁用所有与排序相关的属性。

NULL值是允许的，但是GiST在处理NULL值时并不有效。我们假定NULL值不会增加边界框；这样的值会被插入到随机子
树中，因此必须在整棵树中进行搜索。

然而，有几个列级属性确实取决于特定的操作符类：

#+begin_src sql
  select p.name,
  pg_index_column_has_property('airports_gist_idx', 1, p.name)
  from unnest(array[
  'returnable', 'distance_orderable'
  ])p(name);
#+end_src

由于叶节点保留完整的索引键，因此允许只对索引进行扫描。

如上所述，该操作符类为近邻搜索提供了距离操作符。到NULL值的距离被认为是NULL；这样的值最后返回（类似于B树中的
NULLS LAST子句）。

但是，对于范围类型（表示线段，即线性几何图形，而不是等值几何图形），没有距离运算符，因此对于为此类类型建立的索引，
该属性是不同的：

#+begin_src sql
  create table reservations(during tsrange);
  create index on reservations using gist(during)

  select p.name,
  pg_index_column_has_property('reservations_during_idx', 1, p.name)
  from unnest(array[
  'returnable', 'distance_orderable'
  ]) p(name);
#+end_src

** 用于全文搜索的RD树

关于全文搜索

全文搜索的目的是从所提供的文档集中选择与搜索查询相匹配的文档。

要进行搜索，需要将文档转换为 tsvector 类型，其中包含词目及其在文档中的位置。词目是转换成适合搜索的格式的单词。默
认情况下，所有单词都被归一化为小写，并截去词尾：

#+begin_src sql
  set default_text_search_config = english;
  select to_tsvector(
   'No one can tell me, nobody knows, ' ||
   'Where the wind comes from, where the wind goes.'
   );
#+end_src

所谓的停顿词（如 "the "或 "from"）会被过滤掉：因为它们出现的频率太高，搜索无法返回任何有意义的结果。当然，所有这
些转换都是可配置的。

搜索查询用另一种类型来表示：tsquery。任何查询都包括一个或多个由逻辑连接词绑定的词素：& (AND)、| (OR)、! (NOT)。
您还可以使用括号定义运算符优先级。

#+begin_src sql
  select to_tsquery('wind & (comes | goes)');
#+end_src

用于全文搜索的唯一操作符是匹配操作符 @@：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gist'
  and opcname='tsvector_ops'
  order by amoostrategy;
#+end_src

该操作符决定文档是否满足查询要求。下面是一个示例：

#+begin_src sql
  select to_tsvector('Where the wind comes from, where the wind goes')
  @@ to_tsvector('wind & coming');
#+end_src

这绝不是对全文搜索的详尽描述，但这些信息应足以让我们了解索引编制的基本原理。

为了快速工作，全文搜索必须有索引支持。由于被索引的不是文档本身，而是 tsvector 值，因此你有两种选择：要么在表达式
上建立索引并执行类型转换，要么为 tsvector 类型添加一个单独的列并为该列建立索引。第一种方法的好处是不会浪费任何空间
来存储 tsvector 值，而实际上并不需要这些值。但它比第二种方法慢，因为索引引擎必须重新检查访问方法返回的所有堆元组。
这意味着，每重新检查一行，tsvector 值都要重新计算一次，而我们很快就会看到，GiST会重新检查所有的行。

让我们举一个简单的例子。我们要创建一个双列表：第一列存储文档，第二列存储 tsvector 值。我们可以使用触发器来更新第二
列 ，但更方便的做法是简单地将这一列声明为已生成：

#+begin_src sql
  create table ts(
   doc text,
   doc_tsv tsvecotr generated always as (
    to_tsvector('pg_catalog.english', doc)
    )stored
    );
    create index ts_gist_idx on ts
    using gist(doc_tsv);
#+end_src

#+begin_comment
 在上面的示例中，我使用了带有单参数的 to_tsvector 函数，并设置了 english default_text_search_config 参数
 来定义全文搜索配置。这个函数的波动类别是 STABLE，因为它隐式地依赖于参数值。但在这里，我应用了另一种明确定义配置
 的变量；这种变量是 IMMUTABLE 的，可以在生成表达式中使用。
#+end_comment

插入一些行
#+begin_src sql
  insert into ts(doc)
  values
  ('Old MacDonald had a farm'),
  ('And on his farm he had some cows'),
  ('Here a moo, there a moo'),
  ('Everywhere a moo moo'),
  ('Old Macdonald had a farm'),
  ('And on his farm he had some chicks'),
  ('Here a cluck, there a cluck'),
  ('Everywhere a cluck cluck'),
  ('Old Macdonald had a farm'),
  ('And on his farm he had some pigs'),
  ('here an oink, there an oink'),
  ('Everywhere an oink oink')
  return doc_tsv;
#+end_src

因此，R 树对于索引文档毫无用处，因为边界框的概念对它们毫无意义。因此，我们使用了 RD 树（俄罗斯娃娃）的改进版。这种
树使用边界集来代替边界框，即包含其子集所有元素的集合。在全文检索中，这种集合包含文档的词目，但在一般情况下，边界集合
可以是任意的。

在索引条目中表示边界集有几种方法。最简单的方法是枚举集合的所有元素。

它可能是这样的

[[./images/vzJXK6.png]]

要找到满足 DOC_TSV @@ TO_TSQUERY('cow')条件的文档，我们需要深入到已知子条目包含 "cow"词素的节点。

这种表示法的问题显而易见。文档中的词目数量可能非常庞大，而页面大小却有限。即使每份特定的文档单独来看没有太多不同的
词目，但在树的上层，它们的联合集仍然可能太大。

[[./images/juU0GL.png]]

全文搜索使用另一种解决方案，即更紧凑的签名树。使用过 Bloom 过滤器的人应该对这种方法不陌生。

每个词素都可以用它的签名来表示：一个特定长度的比特串，其中只有一个比特被置 1。

文档的签名是对该文档中所有词条的签名进行比特 OR 运算的结果。

| Suppose we have        | chick                              | 1000000 |
| assigned the following | cluck                              | 0001000 |
| signatures to our      | cow                                | 0000010 |
| lexemes:               | everywher                          | 0010000 |
|                        | farm                               | 0000100 |
|                        | macdonald                          | 0100000 |
|                        | moo                                | 0000100 |
|                        | oink                               | 0000010 |
|                        | old                                | 0000001 |
|                        | pig                                | 0010000 |
| Then the documents'    | Old MacDonald had a farm           | 0100101 |
| signatures will be as  | And on his farm he had some cows   | 0000110 |
| follows:               | Here a moo, there a moo            | 0000100 |
|                        | Everywhere a moo moo               | 0010100 |
|                        | And on his farm he had some chicks | 1000100 |
|                        | Here a cluck, there a cluck        | 0001000 |
|                        | Everywhere a cluck cluck           | 0011000 |
|                        | And on his farm he had some pigs   | 0010100 |
|                        | Here an oink, there an oink        | 0000010 |
|                        | Everywhere an oink oink            | 0010010 |

索引树可以这样表示

[[./images/5hTISQ.png]]

这种方法的优点显而易见：索引条目大小相同，而且相当小，因此索引相当紧凑。但也有一些缺点。首先，不可能只执行索引扫描，
因为索引不再存储索引键，每个返回的 TID 都必须由表重新检查。准确性也会受到影响：索引可能会返回许多误报，这些误报必
须在重新检查时过滤掉。

让我们再来看看 DIC_TSV @@ TO_TSQYERT(‘cows')条件。查询签名的计算方法与文档签名的计算方法相同；在本例中，查询
签名等于 0000010。一致性函数1必须找到所有在签名中设置了相同位的子节点：

[[./images/cj13sM.png]]

与前面的例子相比，由于存在假阳性命中，这里需要扫描更多的节点。由于签名的容量是有限的，所以在一个大的词集中必然会有
一些词具有相同的签名。在本例中，"cow "和 "oink "就是这样的词素。这意味着同一个签名可以匹配不同的文档；在这里，查
询的签名对应三个文档。

假阳性会降低索引的效率，但丝毫不会影响索引的正确性：因为假阴性是可以保证排除的，所以所需的值不会被漏掉。

显然，签名的大小实际上更大。默认情况下，签名大小为 124 字节（992bits），因此发生碰撞的概率远低于本例。如果需要，
可以使用操作符类参数将签名大小进一步增加到 2000 字节左右：

#+begin_src sql
  create index ... using gist(column tsvector_ops(siglen = size ));
#+end_src

此外，如果值足够小（比页面的十六分之一小一点，一个标准页面大约需要 500 字节），tsvector_ops 运算符类保存在索引叶
页中的是 tsvector 值本身，而不是它们的签名。

为了了解索引是如何在真实数据上运行的，我们可以使用 pgsql-hackers 邮件列表存档。它包含 356125 封电子邮件及其发
送日期、主题、作者姓名和正文。

让我们添加一个 tsvector 类型的列并建立一个索引。在这里，我将三个值（主题、作者和正文）合并为一个向量，以显示文件
可以动态生成，而不必存储在单列中。

#+begin_src sql
  alter table mail_messages add column tsv tsvector
  generated always as ( to_tsvector(
  'pg_catalog.english', subject || ' ' || author || ' ' || body_plain
  )) stored;
#+end_src

#+begin_src sql
  create index mail_gist_idx on mail_message using gist(tsv);
  select pg_size_pertty(pg_relation_size('mail_gist_idx'));
#+end_src

在填充列的过程中，由于词的大小，一定数量的大词被过滤掉了。但索引一旦准备就绪，就可以用于搜索查询：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select *
  from mail_messages
  where tsv @@ to_tsquery('magic & value');
#+end_src

除了满足条件的 898 条记录外，访问方法还返回了 7859 条记录，这些记录将在之后的重新检查中被过滤掉。如果我们增加签名
容量，准确性（以及索引效率）将会提高，但索引大小也会增加：

#+begin_src sql
  drop index mail_message_tsv_idx;
  create index on mail_messages
  using gist(tsv tsvector_ops(siglen=248));

  select pg_size_pretty(pg_relation_size('mail_message_tsv_idx'));

  explain (analyze, costs off, timing off, summary off)
  select *
  from mail_message
  where tsv @@ to_tsquery('magic & value');
#+end_src

属性

我已经介绍了访问方法属性，其中大部分属性对所有操作符类都是一样的。但以下两个列级属性值得一提：

#+begin_src sql
  select p.name
  pg_index_column_has_property('mail_messages_tsv_idx', 1, p.name)
  from unnest(array[
      'returnable', 'distance_orderable'
      ])p(name);
#+end_src

现在只扫描索引是不可能的，因为无法从其签名恢复原始值。在这种特殊情况下完全没问题：tsvector 值只用于搜索，而我们需
要检索文档本身。

tsvector_ops类的排序运算符也没有定义。

** 其他数据类型

我只考虑了两个最突出的例子。它们表明，尽管 GiST 方法是基于平衡树的，但由于不同运算符类中有不同的支持函数实现，它可
以用于各种数据类型。当我们谈论 GiST 索引时，我们必须始终指定操作符类，因为它对索引属性至关重要。

以下是 GiST 访问方法目前支持的其他几种数据类型。

1. 几何数据类型
   除了点之外，GiST 还可以索引其他几何对象：矩形、圆形、多边形。所有这些对象都可以用它们的边界框来表示。
   cube扩展添加了表示多维立方体的同名数据类型。它们使用带有相应维度边框的 R 树进行索引。
2. 范围类型
   PostgreSQL 提供了几种内置的数字和时间范围类型，如 int4range 和 tstzrange。自定义范围类型可使用 CREATE
   TYPE AS RANGE 命令来定义。
   GiST 通过 range_ops 运算符类支持任何范围类型，包括标准范围和自定义范围。对于索引，采用的是一维 R 树：在这种
   情况下，边界框会转换为边界段。
   也支持多范围类型；它们依赖于 multirange_ops 类。边界范围包括作为多范围值一部分的所有范围。
   seg 扩展为区间提供了同名数据类型，其边界定义特别精确。它不被视为区间类型，但实际上是，因此它的索引方式与区间类
   型完全相同。
3. 序数类型
   让我们再次回顾一下 btree_gist 扩展：它为 GiST 方法提供了操作符类，以支持各种序数数据类型，这些数据类型通常由
   B 树建立索引。当其中一列的数据类型不受 B 树支持时，此类操作符类可用于建立多列索引。
4. 网络地址类型
   inet 数据类型内置 GiST 支持，可通过 inet_ops 操作符类实现。
5. 整型数组
   intarray 扩展扩展了整数数组的功能，为其添加了 GiST 支持。有两类操作符。对于小数组，你可以使用 gist__int_ops
   它实现了 RD 树，在索引项中完整地表示了键。对于大型数组，可以使用基于 gist__bigint_ops 运算符类的 RD-tree
   来实现更紧凑但不太精确的签名。
   #+begin_comment
      运算符类名称中多余的下划线属于基本类型数组的名称。例如，除了更常用的 int4[] 符号外，整数数组还可以表示为
      _int4。但没有 _int 和 _bigint 类型。
   #+end_comment
6. Ltree
   ltree 扩展为带有标签的树状结构添加了同名数据类型。GiST 支持通过签名 RD-trees 提供，RD-trees 使用
   gist_ltree_ops 运算符类处理 ltree 值，使用 gist__ltree_ops 运算符类处理 ltree 类型的数组。
7. 键值对存储
   hstore 扩展提供了用于存储键值对的 hstore 数据类型。gist_hstore_ops 运算符类基于签名 RD 树实现了索引支持。
8. Trigrams
   pg_trgm 扩展添加了 gist_trgm_ops 类，该类实现了对比较文本字符串和通配符搜索的索引支持。

* GIN

** 简介
根据其作者的解释，GIN 代表的是一种烈性和不畏艰险的精神，而不是一种酒精饮料。但也有一种正式的解释：这个缩写被扩展为
"Generalized Inverted Index"。

GIN 访问方法专为表示由独立元素组成的非原子值的数据类型而设计（例如，在全文检索中，文档由词条组成）。GiST 将值作为
一个整体进行索引，而 GIN 则不同，它只对其元素进行索引；每个元素都会映射到包含它的所有值。

我们可以把这种方法比作一本书的索引，它包括所有重要的术语，并列出所有提到这些术语的页面。为了方便使用，索引必须按字
母顺序排列，否则就无法快速浏览。类似地，GIN 依靠的是复合值的所有元素都可以排序这一事实；它的主要数据结构是 B 树。

GIN 元素树的实现没有普通 B 树那么复杂：它被设计为包含多次重复的小元素集。

这一假设得出了两个重要结论：
+ 一个元素只能在索引中存储一次。
  每个元素都被映射到一个 TID 列表中，该列表被称为 "posting list"。如果列表较短，则会与元素一起存储；较长的列表
  会被移到单独的过posting tree中，posting tree实际上是一棵 B 树。就像元素树一样，发布列表也是排序的；从用
  户的角度来看，这并不重要，但有助于加快数据访问速度和减少索引大小。

+ 删除树上的元素毫无意义。
  即使某个元素的 TID 列表是空的，同一元素也有可能作为其他值的一部分再次出现。

因此，索引是一棵元素树，其叶条目与平面列表或 TID 树绑定。

与 GiST 和 SP-GiST 访问方法一样，GIN 也可以通过操作符类的简化接口来索引各种数据类型。此类操作符通常会检查索引的
复合值是否与特定元素集相匹配（就像 @@ 操作符会检查文档是否满足全文搜索查询一样）。

要为特定数据类型建立索引，GIN 方法必须能够将复合值分割成元素，对这些元素进行排序，并检查找到的值是否满足查询要求。
这些操作由操作符类的支持函数实现。

** 全文搜索索引

GIN 主要用于加速全文检索，因此我将继续举例说明 GiST 索引。 正如你所猜测的，这里的复合值就是文档，而这些值的元素就
是词条。

让我们在 "Old MacDonald "表上建立一个 GIN 索引：

#+begin_src sql
  create index ts_gin_dx on ts using gin(doc_tsv);
#+end_src

该指数的可能结构如下所示。与前面的插图不同，这里我提供了实际的 TID 值（灰色背景显示），因为它们对于理解算法非常重
要。这些值表明堆元组具有以下 ID：

#+begin_src sql
  select ctid, * from ts;
#+end_src

[[./images/tLm8IB.png]]

请注意这里与普通 B 树索引的一些不同之处。B 树内部节点最左边的键是空的，因为它们实际上是多余的；而在 GIN 索引中，
它们根本不会被存储。因此，对子节点的引用也会被转移。两种索引都使用高键，但在 GIN 索引中，高键位于其合法的最右侧位
置。B 树中的同级节点被绑定到一个双向列表中；而 GIN 使用的是单向列表，因为树的遍历始终只有一个方向。

在这个理论性的例子中，除了 "farm "这个词素外，所有的posting list都适合常规页面。这个词素在多达六个文档中出现，
因此其 ID 被移到了一个单独的树中。

页面布局

GIN 页面布局与 B 树非常相似。我们可以使用 pageinspect 扩展来窥探索引。让我们在存储 pgsql-hackers 邮件列表电
子邮件的表上创建一个 GIN 索引：

#+begin_src sql
  create index mail_gin_idx on mail_messages using gin(tsv);
#+end_src

零页（元页）包含基本统计数据，如元素和其他类型页面的数量：

#+begin_src sql
  select * from gin_metapage_info(get_raw_page('mail_gin_idx', 0));
#+end_src

GIN 使用索引页的特殊空间；例如，该空间存储定义页类型的位：

#+begin_src sql
  select flags, count(*)
  from generate_series(0, 22956) as p,
  gin_page_opaque_info(get_raw_page('mail_gin_idx', p))
  group by flags
  order by 2;
#+end_src

带有元属性的页面当然是元页面。带 data 属性的页面属于posting list，而不带 data 属性的页面则与元素树有关。叶子
页面带有 leaf 属性。

在下一个示例中，另一个 pageinspect 函数会返回存储在树的叶子页中的 TID 信息。这样一棵树的每个条目实际上都是一个
小的 TID 列表，而不是单个 TID：

#+begin_src sql
  select left(tids::text, 60) || '...' tids
  from gin_leafpage_items(get_raw_page('mail_gin_idx', 24));
#+end_src

posting list是有序的，因此可以对其进行压缩（这也是同名属性的由来）。它们存储的不是 6 字节的 TID，而是与前一个
值的差值，差值用可变的字节数表示：1 差值越小，数据占用的空间就越小。

操作类

下面是 GIN 运算符类的支持函数列表：

#+begin_src sql
  select amprocnum, amproc::regproc
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amproc amop on amprocfamily=opfamily
  where amname='gin'
  and opcname='tsvector_ops'
  order by amprocnum;
#+end_src

第一个支持函数比较两个元素（本例中为两个词素）。如果词条是由 B-tree 支持的常规 SQL 类型表示的，那么 GIN 会自动
使用 B-tree 运算符类中定义的比较运算符。

第五个（可选）函数用于部分搜索，检查索引元素是否与搜索关键字部分匹配。在这种特殊情况下，部分搜索包括通过前缀搜索词
目。例如，查询 "c: *"对应于所有以字母 "c "开头的词目。

第二个函数从文档中提取词条，而第三个函数则从搜索查询中提取词条。使用不同的函数是合理的，因为至少文档和查询是由不同
的数据类型表示的，即 tsvector 和 tsquery。此外，搜索查询的函数决定了搜索的执行方式。如果查询要求文档包含特定词
素，那么搜索将仅限于至少包含查询中指定的一个词素的文档。如果没有这样的条件（例如，如果您需要不包含特定词素的文档），
则必须扫描所有文档--当然，这样做的成本要高得多。

#+begin_comment
 如果查询包含任何其他搜索关键字，则首先按这些关键字扫描索引，然后重新检查这些中间结果。因此，无需全面扫描索引。
#+end_comment

第四和第六个函数是一致性函数，用于确定找到的文档是否满足搜索查询。作为输入，第四个函数获取查询中指定的词目在文档中
出现的确切信息。第六个函数是在不确定的情况下运行的，可以在尚不清楚某些词目是否出现在文档中时调用。操作符类不必同时
实现这两个功能：只需提供其中一个即可，但在这种情况下搜索效率可能会受到影响。

tsvector_ops 运算符类只支持一种与搜索查询匹配文档的运算符： @@，它也包含在 GiST 运算符类中。

搜索

让我们来看看 "everywhere | oink "查询的搜索算法，其中两个词项由 OR 运算符连接。首先，支持函数从 tsquery 类型
的搜索字符串中提取词条 "everywher "和 "oink"（搜索键）。

由于查询要求包含特定的词目，因此至少包含一个查询关键字的文档的 TID 会被绑定到一个列表中。为此，与每个搜索关键字相
对应的 TID 会在词条树中被搜索，并被添加到一个公共列表中。索引中存储的所有 TID 都是有序的，因此可以将多个有序的
TID 流合并为一个索引。

请注意，此时键是否通过 AND、OR 或任何其他运算符组合并不重要：搜索引擎处理的是键列表，对搜索查询语义一无所知。

[[./images/T7HZte.png]]

找到的每个与文档相对应的 TID 都要经过一致性函数的检查。正是该功能解释了搜索查询，并只留下满足查询的 TID（或至少可
能满足查询的 TID，且必须由表格重新检查）。

在这种特殊情况下，一致性函数会保留所有 TID：

| TID   | "everywher" | "oink" | consistency function |
|-------+-------------+--------+----------------------|
| (0,4) | ✓           | -      | ✓                    |
| (1,4) | ✓           | -      | ✓                    |
| (2,3) | -           | ✓      | ✓                    |
| (2,4) | ✓           | ✓      | ✓                    |
|-------+-------------+--------+----------------------|

搜索查询可以包含前缀，而不是普通词素。如果应用程序用户在搜索字段中输入单词的首字母，并希望立即得到搜索结果，那么前
缀就非常有用。例如，"pig： *查询将匹配所有包含以 "pig "开头的词素的文档：在这里，我们得到了 "pigs"，如果老麦克
唐纳在他的农场里饲养了鸽子，我们也会得到 "pigeons"。

这种部分搜索使用一个特殊的支持函数将索引词目与搜索关键字进行匹配；除了前缀匹配外，该函数还可以实现其他部分搜索逻辑。

常用词和罕见词

如果搜索的词条在文档中多次出现，创建的 TID 列表就会变得很长，这当然是低效的。幸运的是，如果查询中也包含一些罕见词
目，这种情况通常可以避免。

让我们来看看 "farm & cluck "查询。cluck "词素出现了两次，而 "farm "词素则出现了六次。我们没有将这两个词素同等
对待，也没有根据它们建立完整的 TID 列表，而是将罕见的 "cluck "词素视为必选词素，而将出现频率较高的 "farm "词素
视为可选词素，因为很明显（考虑到查询语义），带有 "farm "词素的文档只有同时包含 "cluck "词素才能满足查询。

因此，我们通过索引扫描确定了第一个包含 "cluck "的文档，其 TID 为 (1,3)。然后，我们必须找出该文档是否也包含
"farm "词素，但可以跳过所有 TID 小于 (1,3) 的文档。由于频繁出现的词素很可能与许多 TID 相对应，它们很有可能被存
储在单独的树中，因此有些页面也可以跳过。在本例中，在 "farm "词条树中的搜索从 (1,3) 开始。

随后的强制词素值将重复这一过程。

显然，这种优化也可以应用于涉及两个以上词性的更复杂搜索场景。该算法按词目出现频率的顺序排列词目，并将其逐一添加到必
选词目列表中，当剩余词目无法保证文档满足查询要求时，算法就会停止。

例如，我们来看看查询 "farm & ( cluck | chick )"。出现频率最低的词素是 "chick"；它被立即添加到必选词素列表中。
为了检查其他词素是否可以被视为可选词素，一致性函数对必选词素取 false，对所有其他词素取 true。函数返回 true AND
(true OR false) = true，这意味着其余词素是 "自给自足 "的，它们中至少有一个必须成为必选词素。

下一个出现频率最低的词素（"cluck"）被添加到列表中，现在一致性函数返回 true AND (false OR false) = false。
因此，"chick "和 "cluck "词素成为必选词素，而 "farm "仍然是可选词素。

[[./images/rc63ga.png]]


posting list 的长度为三，因为必填词目出现了三次：

| TID   | "chick" | "cluck" | "farm" | consistency function |
|-------+---------+---------+--------+----------------------|
| (1,2) | ✓       | -       | ✓      | ✓                    |
| (1,3) | -       | ✓       | -      | -                    |
| (1,4) | -       | ✓       | -      | -                    |
|-------+---------+---------+--------+----------------------|

因此，如果知道词素频率，就可以用最有效的方式合并词素树，从罕见词素开始，跳过那些肯定是多余的频繁词素的页面范围。这
样可以减少调用一致性函数的次数。

为了确保这种优化确实有效，让我们查询一下 pgsql-hackers 档案。我们需要指定两个词目，一个常见词目和一个罕见词目：

#+begin_src sql
  select word, ndoc
  from ts_stat('select tsv frm mail_messages')
  where word in ('wrote', 'tattoo');
#+end_src

事实证明，确实存在一份同时包含这两份内容的文件：

#+begin_src sql
  \timing on
  select count(*) from mail_messages
  where tsv @@ to_tsquery('wrote & tattoo');
#+end_src

该查询的执行速度几乎与搜索单词 "tattoo "一样快：

#+begin_src sql
  select count(*) from mail_messages
  where tsv @@ to_tsquery('tatoo')'
#+end_src

但是，如果我们要找的是 "wrote "这个单词，搜索时间会更长：

#+begin_src sql
  select count(*) from mail_messages
  where tsv @@ to_tsquery('wrote');
#+end_src

插入

GIN 索引不能包含重复内容；如果要添加的元素已经存在于索引中，其 TID 只需添加到已存在元素的posting list或树状
结构中即可。posting list是索引条目中的一部分，它不能占用页面中过多的空间，因此如果超出了分配的空间，列表就会变
成树状。

当一个新元素（或新 TID）被添加到树中时，可能会出现页面溢出；在这种情况下，页面会被一分为二，元素会在它们之间重新
分配。

但是，每个文档通常都包含许多需要索引的词目。因此，即使我们只创建或修改了一个文档，索引树仍然会经历大量的修改。这
就是 GIN 更新相当缓慢的原因。

下图显示了在表中插入 TID 为 (4,1) 的 "Everywhere clucks, moos, and oinks "行后树的状态。扩展了 "cluk"、
"moo "和 "oink "的词条列表；"everywher "的词条列表超过了最大值，被分割成一棵独立的树。

不过，如果一次更新索引以纳入与多个文档相关的更改，那么与连续更改相比，总工作量可能会减少，因为这些文档可能包含一些
共同词目。

这一优化由 fastupdate 存储参数控制。延迟的索引更新会累积到一个无序的待定列表中，该列表实际存储在元素树之外的单独
列表页中。该列表的最大大小由 4MB gin_pending_list_limit 参数或同名索引存储参数确定。

[[./images/vqGXad.png]]

默认情况下，这种延迟更新是启用的，但你应该记住，它们会减慢搜索速度：除了树本身，还必须扫描整个无序词条列表。此外，
插入时间的可预测性也会降低，因为任何变化都可能导致溢出，从而引发昂贵的合并过程。在索引抽真空过程中，合并也可以异步
进行，这在一定程度上缩短了合并时间。

创建新索引 时，元素也是分批添加的，而不是逐个添加，因为这样速度太慢。所有更改不会被保存到磁盘上的无序列表中，而是累
积到一个 64MB 的 maintenance_work_mem 内存块中，一旦该内存块没有可用空间，就会被转移到索引中。为这一操作分配的
内存越多，建立索引的速度就越快。

本章提供的示例证明，就搜索精度而言，GIN 优于 GiST 签名树。因此，GIN 通常被用于全文检索。不过，如果数据更新频繁，
GIN 更新速度慢的问题可能会使 GiST 更受青睐。

限制结果集大小

GIN 访问方法总是以位图的形式返回结果，不可能逐个获取 TID。换句话说，支持 BITMAP SCAN 属性，但不支持 INDEX SCAN
属性。

造成这种限制的原因是延迟更新的无序列表。在索引访问的情况下，该列表会被扫描以建立一个位图，然后用树的数据更新该位图。
如果在搜索过程中无序列表与树合并（作为索引更新的结果或在抽真空过程中），一个相同的值可能会返回两次，这是不可接受的。
但对于位图来说，这不会造成任何问题：相同的位只会被设置两次。

因此，使用 LIMIT 子句和 GIN 索引的效率并不高，因为位图仍需全部建立，这在总成本中占了相当大的比例：

#+begin_src sql
  expalin select * from mail_messages
  where tsv @@ to_tsquery('hacker')
  limit 1000;
#+end_src

因此，GIN 方法提供了一个特殊功能，可以限制索引扫描所返回结果的数量。该限制由 gin_fuzzy_search_limit 参数施加，
默认情况下该参数处于关闭状态。如果启用该参数，索引访问方法将随机跳过某些值，以获得大致指定的行数（因此被称为 "模
糊"）：

#+begin_src sql
  set gin_fuzzy_search_limit=1000;
  select count(*)
  from mail_messages
  where tsv @@ to_tsquery('hacker');
#+end_src

#+begin_src sql
  select count(*)
  from mail_messages
  where tsv @@ to_tsquery('hacker');
#+end_src


#+begin_src sql
  reset gin_fuzzy_search_limig;
#+end_src

请注意，这些查询中没有 LIMIT 子句。这是使用索引扫描和堆扫描获取不同数据的唯一合法方式。规划器对 GIN 索引的这种行
为一无所知，因此在估算成本时不会考虑该参数值。

属性

gin 访问方法的所有属性在所有级别上都是相同的，它们并不依赖于特定的操作符类别。

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ])p(name)
  where a.amname='gin';
#+end_src

GIN 既不支持排序，也不支持唯一约束。

支持多列索引，但值得一提的是，其列的顺序并不重要。与普通的 B 树不同，多列 GIN 索引不存储复合键，而是用相应的列编
号扩展独立的元素。

由于 INDEX SCAN 属性不可用，因此无法支持排除限制。

GIN 不支持额外的 INCLUDE 列。这类列在这里没有太大意义，因为几乎不可能使用 GIN 索引作为覆盖：它只包含索引值的单独
元素，而索引值本身存储在表中。

索引级属性

#+begin_src sql
  select p.name, pg_index_has_property('mail_gin_idx', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backwoard_scan'
  ])p(name);
#+end_src

不支持逐个获取结果：索引访问总是返回一个位图。

出于同样的原因，使用 GIN 索引对表重新排序也是没有意义的：位图总是与表中数据的物理布局相对应，不管它是什么。

不支持后向扫描：该功能适用于常规索引扫描，不适用于位图扫描。

列级属性

#+begin_src sql
  select p.name,
  pg_index_column_has_property('mail_gin_idx', 1, p.name)
  from unnest(array[
  'orderable', 'search_array', 'search_nulls',
  'returnable', 'distance_orderable'
  ])p(name);
#+end_src

列级属性都不可用：既不能排序（原因显而易见），也不能使用索引作为覆盖（因为文档本身并不存储在索引中）。也不支持 NULL
（对于非原子类型的元素没有意义）。

GIN的限制和RUM指数

尽管 GIN 功能强大，但它仍无法解决全文检索的所有难题。尽管tsvector 类型确实能指示词目位置，但这些信息并不能进入
索引。因此，GIN 无法用于加快短语搜索，因为短语搜索需要考虑词素的邻近性。此外，搜索引擎通常按照相关性（不管这个词是
什么意思）来返回结果，由于 GIN 不支持排序运算符，因此唯一的解决方案就是为每一行结果计算排序函数，这当然会非常慢。

RUM 访问方法（它的名字让我们怀疑开发人员对 GIN 真正含义的诚意）解决了这些缺点。

这种访问方法是作为扩展提供的；您可以从 PGDG 软件库中下载相应的软件包，或者获取源代码本身。

RUM 基于 GIN，但两者有两个主要区别。首先，RUM 不提供延迟更新，因此除了位图扫描外，它还支持常规的索引扫描，并实现
了排序操作符。其次，RUM 索引键可以扩展附加信息。这一功能在某种程度上类似于 INCLUDE 列，但在这里，附加信息被绑定
到特定的键上。在全文搜索中，RUM 运算符类可将词素出现映射到其在文档中的位置，从而加快短语搜索和结果排序。

这种方法的缺点是更新速度较慢，索引规模较大。此外，由于RUM访问方法是作为扩展提供的，它依赖于通用 WAL 机制，这比
内置日志更慢，而且会产生更大的 WAL。

** Trigrams

pg_trgm 扩展可以通过比较重合的三个字母序列（trigrams）的数量来评估词语的相似性。单词相似性可与全文搜索一起使用，
即使要搜索的单词在输入时有错别字，也能返回一些结果。

gin_trgm_ops 运算符类实现了文本字符串索引。为了找出文本值中的元素，它提取各种三字母子串，而不是单词或词目（只考
虑字母和数字，其他字符忽略不计）。在索引中，三字符串表示为整数。需要注意的是，对于UTF-8 编码中需要 2 至 4 个字节
的非拉丁字符，这种表示法无法解码原始符号。

#+begin_src sql
  create extension pg_trgm;
  select unnest(show_trgm('macdonald')),
         unnest(show_trgm('McDonald'));
#+end_src

该类支持精确和模糊比较字符串和单词的操作符。

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='gin_trgm_ops'
  order by amopstrategy;
#+end_src

为了进行模糊比较，我们可以将字符串之间的距离定义为共同卦数与查询字符串中卦数之比。但如前所述，GIN 不支持排序操作
符，因此该类中的所有操作符都必须是布尔型的。因此，对于执行模糊比较策略的 %、%> 和 %>> 操作符，如果计算出的距离不
超过定义的阈值，一致性函数就会返回 true。

对于 = 和 LIKE 操作符，一致性函数要求值包含查询字符串中的所有三元组。根据正则表达式匹配文档需要进行更复杂的检查。

无论如何，trigram搜索总是模糊的，搜索结果必须重新检查。

**  索引数组

GIN 还支持数组数据类型。通过在数组元素上建立 GIN 索引，可以快速确定一个数组是否与另一个数组重叠或包含在另一个数组
中：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='array_ops'
  order by amopstrategy;
#+end_src

以演示数据库中显示航班信息的路线视图为例。Days_of_week 列是一个数组，包含一周中执行航班的天数。要建立索引，我们首
先要将视图实体化：

#+begin_src sql
  create table routes_tbl as select * from routes;
  create index on routes_tbl using gin(days_of_week);
#+end_src

让我们使用创建的索引来选择在周二、周四和周日起飞的航班。我关闭了顺序扫描；否则，计划器不会为这样一个小表使用索引：

#+begin_src sql
  set enable_seqscan=off;
  explain (costs off) select * from routes_tbl
  where days_of_week=array[2,4,7];
#+end_src

原来，这样的航班共有 11 次：

#+begin_src sql
  select flight_no, departure_airport, arrival_aiport,
  days_of_week
  from routes_tbl
  where days_of_week = array[2,4,7];
#+end_src

建立的索引只包含七个元素：从 1 到 7 的整数，代表一周的天数。

查询的执行与之前展示的全文检索非常相似。在这种特殊情况下，搜索查询由普通数组而非特殊数据类型表示；我们假定索引数组
必须包含所有指定元素。这里的一个重要区别是，相等条件还要求索引数组不包含其他元素。一致性函数通过策略编号知道了这一
要求，但它无法验证是否存在不需要的元素，因此它要求索引引擎通过表格重新检查结果：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from routes_tbl
  where days_of_week=array[2,4,7];
#+end_src

使用附加列扩展 GIN 索引可能很有用。例如，为了搜索每周二、周四和周日从莫斯科起飞的航班，索引缺少 departure_city
列。但常规标量数据类型没有操作符类：

#+begin_src sql
  create index on routes_tbl using gin(days_of_week, departure_city);
#+end_src

这种情况可以通过 btree_gin 扩展来解决。它添加了 GIN 运算符类，通过将标量值表示为包含单个元素的复合值来模拟常规的
B 树处理。

#+begin_src sql
  create extension btree_gin;
  create index on routes_tbl using gin(days_of_week, departure_city);
  explain (costs off)
  select * from routes_tbl
  where days_of_week = array[2,4,7]
  and departure_city='Moscow';
  reset enable_seqscan;
#+end_src

关于 btree_gist 的评论也适用于 btree_gin：在进行比较操作时，B 树的效率要高得多，因此只有在真正需要 GIN 索引时，
才有必要使用 btree_gin 扩展。例如，通过小于或小于等于条件进行的搜索可以在 B 树中通过后向扫描执行，但在 GIN 中则
不行。


** 索引JSON

jsonb_ops 操作符类是默认的操作符类。原始 JSON 文档中的所有键、值和数组元素都会转换成索引项。它能加快检查是否包含
JSON 值 (@>)、是否存在键 (?、?| 和 ?&) 或是否与 JSON 路径匹配 (@? 和 @@) 的查询速度：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='jsonb_ops'
  order by amopstrategy;
#+end_src

让我们把路由视图中的几行转换成 JSON 格式：

#+begin_src sql
  create table routes_jsonb as
  select to_jsonb(t) route
  from (
  select departure_aiport_name, arrival_airport_name, days_of_week
  from routes
  order by flight_no
  limit 4
  );
  select ctid, jsonb_pretty(route) from routes_jsonb;
#+end_src

#+begin_src sql
  create index on routes_jsonb using gin(route);
#+end_src

创建的索引如下所示：

[[./images/AWQKPK.png]]

让我们考虑一个带条件路由 @> '{"days_of_week"： [6]}'，它会选择包含指定路径（即周六执行的航班）的 JSON 文档。

支持函数从搜索查询的 JSON 值中提取搜索键： 支持函数从搜索查询的值中提取搜索关键字："days_of_week "和 "6"。
对于包含策略，该函数要求所有搜索键都可用，但结果仍需由表格重新检查：从索引的角度来看，指定路径也可以对应于类似
{"days_of_week"： [2], "foo"： [6]}.

jsonb_path_ops操作类

第二个类名为 jsonb_path_ops，包含的操作符较少：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='jsonb_path_ops'
  order by amopstrategy;
#+end_src

如果使用该类，索引将包含从文档根指向所有值和所有数组元素的路径，而不是孤立的 JSON 片段。这将使搜索更精确、更高效，
但对于使用独立键而非路径表示的参数的操作，速度不会提高。

由于路径可能相当长，因此真正被索引的不是路径本身，而是其哈希值。

让我们使用该操作符类为同一个表创建一个索引：

#+begin_src sql
  create index on routes_jsonb using gin(route jsonb_path_ops);
#+end_src

创建的索引可以用以下树形结构表示：

[[./images/iE6aBN.png]]


当执行具有相同条件路由 @> '{"days_of_week"： [6]}"时，支持函数提取的是整个路径 "days_of_week, 6"，而不是其
单独的组成部分。这样就能立即在元素树中找到两个匹配文档的 TID。

显然，这些条目将由一致性函数进行检查，然后由索引引擎重新检查（例如，排除哈希碰撞）。但是，通过树进行搜索的效率要高
得多，因此，如果 jsonb_path_ops 类的运算符提供的索引支持足以满足查询的需要，那么选择 jsonb_path_ops 类是有道
理的。


** 索引其他数据类型

还通过扩展为以下数据类型提供 GIN 支持：

+ 整型数组intarray 扩展为整数数组添加了 gin__int_ops 操作符类。它与标准的 array_ops 运算符类非常相似，但它支持
  匹配运算符 @@，可将文档与搜索查询进行匹配。
+ 键值存储 hstore 扩展实现了键值对的存储，并提供了 gin_hstore_ops 运算符类。键和值都有索引。
+ JSON查询语言 外部 jsquery 扩展为 JSON 提供了自己的查询语言和 GIN 索引支持。

#+begin_comment
 在采用 SQL:2016 标准并在 PostgreSQL 中实现 SQL/JSON 查询语言后，标准内置功能似乎是更好的选择。
#+end_comment





