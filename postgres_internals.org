#+name: postgres_internals
#+header: :engine postgres

* 隔离

** 一致性

关系数据库的主要特点是能够确保数据的一致性，即数据的正确性。

众所周知，在数据库级别可以创建完整性约束，如 NOT NULL 或 UNIQUE。数据库系统可确保这些约束永远不会被破坏，因此数
据完整性永远不会受到影响。

如果所有需要的约束条件都能在数据库一级制定，一致性就能得到保证。但有些条件过于复杂，例如同时涉及多个表。即使在数据
库中可以定义一个约束，但由于某些原因没有定义，也并不意味着这个约束可能会被违反。

因此，数据一致性比完整性更严格，但数据库系统并不知道 "一致性 "的实际含义。如果应用程序在不破坏完整性的情况下破坏了
一致性，数据库系统根本无法发现。因此，必须由应用程序来制定数据一致性的标准，而且我们必须相信它是正确编写的，绝不会
出现任何错误。

但是，如果应用程序始终只执行正确的运算符序列，那么数据库系统的作用又在哪里呢？

首先，一个正确的操作符序列可能会暂时破坏数据的一致性，虽然看起来很奇怪，但这是完全正常的。

从一个账户向另一个账户转移资金就是一个老生常谈但却清晰明了的例子。一致性规则听起来可能是这样的：资金转移绝不能改变
受影响账户的总余额。要在 SQL 中将这条规则表述为完整性约束是相当困难的（尽管有可能），因此我们假设它是在应用程序级
别定义的，对数据库系统来说是不透明的。转账由两个操作组成：第一个操作是从一个账户中提取资金，而第二个操作则是将这笔
资金添加到另一个账户中。第一个操作会破坏数据的一致性，而第二个操作则会恢复数据的一致性。

如果第一个操作成功了，但第二个操作没有成功（由于某些故障），数据一致性就会被破坏。这种情况是不可接受的，但要在应用
程序层面发现并解决这些问题却需要花费大量精力。幸运的是，这并不是必需的--如果数据库系统知道这两个操作构成了一个不可
分割的整体，即一个事务，那么这个问题完全可以由数据库系统自己解决。

但这里还有一个更微妙的方面。事务本身是绝对正确的，但并行运行时可能会开始运行错误。这是因为属于不同事务的操作经常会
混合在一起。如果数据库系统先完成一个事务的所有操作，然后再进入下一个事务，就不会出现这种问题，但顺序执行的性能会低
得离谱。

#+begin_comment
  只有在拥有合适硬件（多核处理器、磁盘阵列等）的系统上，才能真正实现事务的同步执行。但同样的道理也适用于在分时模式
  下顺序执行命令的服务器。出于概括的目的，这两种情况有时都被称为并发执行。
#+end_comment

正确的事务在一起运行时行为不正确，会导致并发异常或并发现象。

下面是一个简单的例子。要从数据库中获取一致的数据，应用程序至少不能看到其他未提交事务所做的任何更改。否则（如果某些
事务回滚），应用程序就会看到从未存在过的数据库状态。这种异常情况被称为 "脏读"。还有许多其他异常情况，它们更为复杂。

在并发运行事务时，数据库必须保证事务的执行结果与可能的顺序执行结果相同。换句话说，数据库必须将事务相互隔离，从而避免
可能出现的异常情况。

总而言之，事务是将数据库从一个正确状态带到另一个正确状态（一致性）的一组操作，条件是事务必须完整执行（原子性），并
且不受其他事务的影响（隔离性）。这一定义结合了 ACID 首字母缩写前三个字母所隐含的要求。它们相互交织在一起，因此将
它们放在一起讨论是合理的。事实上，耐久性要求也很难分割开来：在系统崩溃后，系统可能仍包含一些未提交事务所做的更改，
因此必须采取一些措施来恢复数据的一致性。

因此，尽管数据库系统不知道隐含的一致性规则，但它可以通过考虑事务边界来帮助应用程序保持数据一致性。

遗憾的是，完全隔离很难实现，而且会对性能产生负面影响。现实生活中的大多数系统都使用较弱的隔离级别，这可以防止一些异
常情况，但不能防止所有异常情况。这意味着维护数据一致性的工作部分落在了应用程序身上。正因如此，了解系统中使用的隔离
级别、该级别能保证什么、不能保证什么，以及如何确保代码在这种情况下的正确性就显得非常重要。

** SQL 标准中的隔离级别和异常情况

SQL 标准规定了四种隔离级别。这些级别由并发事务执行期间可能发生或不发生的异常情况列表定义。因此，在谈论隔离级别时，
我们必须从异常情况入手。

我们应该牢记，标准是一种理论建构：它影响着实践，但实践仍在很多方面与它相背离。这就是为什么这里的所有例子都是假设性
的。关于银行账户上的交易，这些例子不言自明，但我必须承认，它们与真实的银行业务毫无关系。

有趣的是，实际的数据库理论也与标准相左：它是在标准通过后才制定的，而实践已经远远领先于标准

丢失更新

当两个事务读取同一个表行，然后其中一个事务更新该行，最后另一个事务在不考虑第一个事务所做更改的情况下更新同一行时，
就会出现更新丢失异常。

假设有两笔交易将使同一个账户的余额增加 100 美元。第一个事务读取当前值（1000 美元），然后第二个事务读取相同的值。
第一个事务增加余额（使其达到 1,100 美元），并将新值写入数据库。第二个事务做了同样的操作：增加余额后获得 1,100
美元，并写入该值。结果，客户损失了 100 美元。   

所有隔离级别的标准都禁止丢失更新。

脏读和读未提交

当一个事务读取另一个事务做出的未提交更改时，就会出现脏读异常。

例如，第一个事务将 100 美元转入一个空账户，但没有提交这一变更。另一个事务读取了账户状态（已更新但未提交），并允许
客户取款，尽管第一个事务被中断，其更改被回滚，因此账户是空的。

该标准允许在 "读取未提交 "级别进行脏读。

不可重复读和读提交

当一个事务两次读取同一条记录，而另一个事务在两次读取之间更新（或删除）该记录并提交更改时，就会出现不可重复读取异常。
因此，第一个事务会得到不同的结果。

例如，假设有一条一致性规则禁止银行账户余额为负。第一笔交易将使账户余额减少 100 美元。它检查了当前值，得到了 1,000
美元，并决定这个操作是可行的。与此同时，另一个交易从该账户中提取所有资金，并提交更改。如果此时第一笔交易再次检查余
额，则会得到 0 美元（但取款的决定已经做出，该操作会导致透支）。

该标准允许在 "未提交读取 "和 "已提交读取 "级别进行不可重复读取。

幻读和重复读

当同一个事务执行两个相同的查询，返回一组满足特定条件的记录，而另一个事务添加了一些满足该条件的其他记录，并在这两个
查询之间的时间间隔内提交更改时，就会出现幻读异常。因此，第一个事务会得到两组不同的记录。

例如，假设有一条一致性规则禁止客户拥有超过三个账户。第一个事务要开设一个新账户，因此它要检查当前有多少个账户（假设
有两个），并决定可以进行此操作。此时，第二个事务也会为该客户开设一个新账户，并提交更改。如果第一个事务重复检查了开
放账户的数量，就会得到三个账户（但它已经在开设另一个账户，客户最终拥有四个账户）。

该标准允许在 "未提交读取"、"已提交读取 "和 "可重复读取 "隔离级别进行幻读。

无异常和可序列化

该标准还定义了不允许任何异常的可序列化级别。这与禁止丢失更新、脏读、不可重复读和幻读不同。事实上，已知异常情况的数
量比标准规定的要多得多，而未知异常情况的数量仍然未知。

可序列化级别必须防止任何异常情况。这意味着应用程序开发人员不必考虑隔离问题。如果事务在单独运行时执行正确的操作符序
列，并发执行也不会破坏数据一致性。

可序列化级别必须防止任何异常情况。这意味着应用程序开发人员不必考虑隔离问题。如果事务在单独运行时执行正确的操作符序
列，并发执行也不会破坏数据一致性。

为了说明这一观点，我将使用标准中提供的一个众所周知的表格；为清楚起见，在此 增加了最后一列：

|                 | lost update | dirty read | non-repeatable | phantom read | other anomalies |
| Read Uncommited | -           | yes        | yes            | yes          | yes             |
| Read Committed  | -           | -          | yes            | yes          | yes             |
| Repeatable Read | -           | -          | -              | yes          | yes             |
| Serializable    | -           | -          | -              | -            | -               |

为什么会出现这些异常现象？

在所有可能出现的异常情况中，为什么标准只提到了一些，而且恰恰是这些异常情况？

似乎没有人确切知道这一点。不过，由于当时的理论远远落后于实践，在通过第一版标准时根本没有考虑到其他异常情况，这也并
非不可能。

此外，隔离必须基于锁。广泛使用的两阶段锁协议（2PL）要求事务在执行过程中锁定受影响的行，并在完成后释放锁。简单来说，
一个事务获得的锁越多，它与其他事务的隔离就越好。因此，系统性能就越差，因为事务会开始排队访问相同的行，而不是并发运
行。

我认为，在很大程度上，标准隔离级别之间的差异是由实现这些级别所需的锁的数量决定的。

如果要更新的行对写入锁定但对读取不锁定，我们就会得到 "未提交读取 "隔离级别，它允许在提交前读取数据。

如果要更新的行在读取和写入时都被锁定，我们就会得到 "已提交读取 "级别：禁止读取未提交的数据，但如果查询被运行多次
（不可重复读取），它可能会返回不同的值。

锁定要读取和要更新的记录的所有操作后，我们就获得了可重复读取级别：重复查询将返回相同的结果。

然而，可序列化级别带来了一个问题：不可能锁定一条尚未存在的记录。这就给幻读取留下了可乘之机：事务可以添加一条满足上
一次查询条件的记录，而这条记录将出现在下一次查询结果中。

因此，常规锁无法提供完全隔离：要实现完全隔离，我们必须锁定条件（谓词）而不是行。早在 1976 年开发 R 系统时，就已经
引入了这种谓词锁；然而，它们的实际应用仅限于简单的条件，对于这些条件，两个不同的谓词是否会发生冲突是显而易见的。据
我所知，谓词锁从未在任何系统中实现过。

** PostgreSQL 中的隔离级别

随着时间的推移，基于锁的事务管理协议被快照隔离（SI）协议所取代。这种方法背后的理念是，每个事务都会访问特定时间点出
现的一致数据快照。快照中包括快照拍摄前提交的所有当前更改。

快照隔离可最大限度地减少所需锁的数量。 事实上，只有并发更新尝试才会锁定记录。在所有其他情况下，操作都可以并发执行：
写操作永远不会锁定读操作，而读操作永远不会锁定任何内容。

PostgreSQL 使用一种多版本的 SI 协议。多版本并发控制意味着数据库系统在任何时刻都可能包含同一行的多个版本，因此
PostgreSQL 可以在快照中包含适当的版本，而不是中止试图读取过时数据的事务。

基于快照，PostgreSQL 的隔离与标准中规定的要求不同--事实上，它甚至更加严格。设计上禁止脏读。从技术上讲，你可以指定
"未提交读取"（Read Uncommitted）级别，但其行为与 "已提交读取"（Read Committed）相同，因此我不再提及这一级别。
可重复读取既不允许不可重复读取，也不允许幻读（尽管它不能保证完全隔离）。但在某些情况下，有可能丢失已提交读取级别的
更改。

|                 | lost updates | dirty reads | non-repeatable reads | phantom reads | other anomalies |
| Read Committed  | yes          | -           | yes                  | yes           | yes             |
| Repeatable Read | -            | -           | -                    | -             | yes             |
| Serializable    | -            | -           | -                    | -             | -               |

在探讨内部隔离机制之前，我们先从用户的角度来讨论一下这三种隔离级别。

为此，我们将创建账户表；Alice 和 Bob 将各有 1,000 美元，但 Bob 将有两个账户：

#+begin_src sql
  create table accounts(
    id integer primary key generated by default as identity,
    client text,
    amount numeric
  );
  insert into accounts values(1, 'alice', 1000.00),
                             (2, 'bob', 100.00),
                             (3, 'bob', 900.00)
#+end_src

读已提交

*不读脏页* 要检查不允许读取脏数据很容易。让我们启动一个事务。默认情况下，它使用 "读已提交"隔离级别：

#+begin_src sql
  begin;
  show transaction_isolation;
#+end_src

更确切地说，默认级别由以下参数设置，可根据需要进行更改：

#+begin_src sql
  show default_transaction_isolation;
#+end_src

打开的交易从客户账户中提取了一些资金，但尚未提交这些更改。但它会看到自己的变化，因为它总是被允许的：

#+begin_src sql
  update accounts set amount=amount-200 where id=1;
  select * from accounts where client='alice';
#+end_src

在第二个会话中，我们启动另一个事务，该事务也将在 "读已提交 "级别运行：

#+begin_src sql
  begin;
  select * from accounts where client='alice';
#+end_src

可以预见的是，第二个事务不会看到任何未提交的更改--禁止脏读。

*不可重复读* 现在让第一个事务提交更改。然后第二个事务将重复同样的查询：

#+begin_src sql
  commit;
#+end_src

#+begin_src sql
  select * from accounts where client='alice';
  commit;
#+end_src

查询会收到数据的更新版本，而这正是不可重复读取异常所能理解的，在 "已提交读取 "级别上是允许的。

一个实用的启示：在事务中，不能根据前一个操作员读取的数据做出任何决定，因为中间的一切都可能发生变化。下面是一个例子，
它在应用程序代码中的变化非常频繁，可以说是一种典型的反模式：

#+begin_src sql
  if (select amount from accounts where id=1)>=1000 then
    update accounts set amount=amount-1000 where id=1;
  end if;
#+end_src

在检查和更新之间的时间里，其他交易可以随意改变账户的状态，因此这样的 "检查 "是完全无用的。为了更好地理解，可以想象
其他事务的随机操作符 "楔入 "当前事务的操作符之间。例如，像这样

#+begin_src sql
  if (select amount from accounts where id=1)>=1000 then
   |  update accounts set amount=amount-200 where id=1;
   |  commit;
    update accounts set amount=amount-1000 where id=1;
  end if;
#+end_src

如果一重新排列运算符就会出错，那么代码就是不正确的。不要自欺欺人，以为自己永远不会遇到这种麻烦：任何可能出错的事情
都会出错。这种错误很难重现，因此，修复它们是一项真正的挑战。

如何更正此代码？有几种选择：

+ 用声明式代码取代程序式代码。

  例如，在这种特殊情况下，很容易将 IF 语句转化为 CHECK 约束：

  #+begin_src sql
    alter table accounts
      add check amount>=0;
  #+end_src

  现在不需要在代码中进行任何检查：只需运行命令，并处理违反完整性约束时产生的异常即可。

  现在不需要在代码中进行任何检查：只需运行命令，并处理违反完整性约束时产生的异常即可。

+ 使用单个SQL操作符

  如果一个事务在另一个事务的操作员之间的时间间隙内提交，从而改变了数据的可见性，那么数据的一致性就会受到影响。如果
  只有一个操作员，就不会出现这种时间差。

  PostgreSQL 拥有足够的能力，只需一条 SQL 语句就能解决复杂的任务。特别是，它提供的通用表表达式（CTE）可以包含
  INSERT、DELETE、UPDATE 等操作符，以及 INSERT ON CONFLICT 操作符，该操作符实现了以下逻辑：如果行不存在，
  则插入该行，否则执行更新。

+ 应用明确的锁。

  最后的办法是对所有需要的记录（SELECT FOR UPDATE）甚至整个表（LOCK TABLE）手动设置排他性锁。这种方法总能奏
  效，但却抵消了 MVCC 的所有优点：一些可以并发执行的操作将按顺序运行。
  
*读取偏差* 然而，事情并非如此简单。PostgreSQL 的实现允许其他一些不太为人所知的异常情况，而这些情况并不受标准的约
束。

假设第一笔交易启动了 Bob 账户之间的转账：

#+begin_src sql
  begin;
  update accounts set amount=amount-100 where id=2;
#+end_src

与此同时，另一个事务开始循环处理Bob的所有账户，计算它们的总余额。它从第一个账户开始（当然是看到它之前的状态）：

#+begin_src sql
  begin;
  select amount from accounts where id=2;
#+end_src

此时，第一笔事务成功完成：

#+begin_src sql
  update accounts set amount=amount+100 where id=3;
  commit;
#+end_src

第二个事务读取第二个账户的状态（并看到已更新的值）：

#+begin_src sql
  select amount from accounts where id=3;
  commit;
#+end_src

结果，第二笔交易因为读取了错误的数据而获得了 1100 美元。这种异常情况被称为读偏移。

如何避免在 "读已提交 "级别出现这种异常？答案显而易见：使用单一操作符。例如，像这样

#+begin_src sql
  select sum(amount) from accounts where client='bob';
#+end_src

我一直在说，数据可见性只能在操作符之间发生变化，但真的是这样吗？如果查询运行了很长时间呢？在这种情况下，它能看到处
于不同状态的数据的不同部分吗？

让我们来看看。一种方便的方法是通过调用 pg_sleep 函数为操作符添加延迟。这样，第一行将被立即读取，但第二行则需要等
待两秒钟：

#+begin_src sql
  select amount, pg_sleep(2) -- two seconds
  from accounts where client='bob';
#+end_src

在执行这条语句的同时，让我们开始另一个事务，把钱转回去：

#+begin_src sql
  begin;
  update accounts set amount=amount+100 where id=2;
  update accounts set amount=amount-100 where id=3;
  commit;
#+end_src

结果显示，运算符在开始执行时看到了对应状态下的所有数据，这当然是正确的：

但也不是那么简单。如果查询包含一个声明为 VOLATILE 的函数，而这个函数又执行了另一个查询，那么这个嵌套查询所看到的
数据将与主查询的结果不一致。
  
让我们用下面的函数来检查一下Bob的账户余额：

#+begin_src sql
  create function get_amount(id integer) returns numeric
  as $$
    select amount from accounts a where a.id=get_amount.id;
  $$ volatile language sql;

  select get_amount(id), pg_sleep(2)
  from accounts where client='bob';
#+end_src

在执行延迟查询的同时，我们将再次在账户间转账：

#+begin_src sql
  begin;
  update accounts set amount=amount+100 where id=2;
  update accounts set amount=amount-100 where id=3;
  commit;
#+end_src

在这种情况下，我们将得到不一致的数据--100 美元已经丢失：

我想强调的是，只有在读取已提交（Read Committed）的隔离级别下，并且只有当函数是 VOLATILE 时，才有可能产生这种
效果。问题是，PostgreSQL 默认使用的正是这种隔离级别和这种不稳定性类别。因此我们不得不承认，这个陷阱设置得非常狡
猾。

*读取偏差，而不是更新丢失。* 在更新过程中，读取偏移异常也可能发生在单个运算符中，尽管发生的方式有些出人意料。

让我们看看如果两个交易试图修改同一行会发生什么。Bob目前在两个账户中共有 1000 美元：

#+begin_src sql
  select * from accounts where client='bob';
#+end_src

开始事务，减少鲍勃的余额：

#+begin_src sql
  begin;
  update accounts set amount=amount-100 where id=3;
#+end_src

与此同时，另一项交易将计算总余额在 1 000 美元或以上的所有客户账户的利息：

#+begin_src sql
  update accounts set amount=amount*1.01
  where client in (
    select client
    from accounts
    group by client
    having sum(amount)>=1000
  );
#+end_src

UPDATE 操作符的执行实际上包括两个阶段。首先，根据提供的条件选择要更新的行。由于第一个事务尚未提交，第二个事务无法
看到其结果，因此选择应计利息的行不会受到影响。因此，bob的账户满足条件，一旦更新操作完成，他的余额必须增加 10 美
元。

在第二阶段，被选中的记录会被逐一更新。第二个事务需要等待，因为 id = 3 的记录被锁定：它正在被第一个事务更新。

同时，第一个事务提交其更改：

#+begin_src sql
  commit;
  select * from accounts where client='bob';
#+end_src

一方面，UPDATE 命令不能看到第一个事务所做的任何更改。但另一方面，它也不能丢失任何已提交的更改。

一旦锁被释放，UPDATE 操作符就会重新读取要更新的记录（但仅限于这一行！）。结果，Bob 从 900 美元的总额中获得了 9
美元的利息。但如果他有 900 美元，他的账户就不应该包含在查询结果中。

因此，我们的事务返回了错误的数据：从不同的快照中读取了不同的行。我们再次观察到读取倾斜异常，而不是更新丢失。

*丢失更新* 但是，如果数据被不同的 SQL 操作员修改，重新读取锁定行的技巧将无助于防止更新丢失。

下面是我们已经看过的一个例子。 应用程序（在数据库外）读取并注册 Alice 账户的当前余额：

#+begin_src sql
  begin;
  select amount from accounts where id=1;
#+end_src

与此同时，另一笔交易也是如此：

#+begin_src sql
  begin;
  select amount from accounts where id=1;
#+end_src

第一笔交易将先前登记的值增加 100 美元，并提交这一更改：

#+begin_src sql
  update accounts set amount=800.00+100 where id=1
  returning amount;
  commit;
#+end_src

第二次交易也是如此：

#+begin_src sql
  update accounts set amount=800.00+100 where id=1
  returning amount;
  commit;
#+end_src

不幸的是，Alice 损失了 100 美元。数据库系统不知道 800 美元的注册值与 accounts.amount 有某种关联，因此无法防
止丢失更新异常。在 "读已提交"（Read Committed）隔离级别，这段代码是不正确的。

重复读

*不可重复读和幻读* 顾名思义，可重复读取隔离级别必须保证可重复读取。让我们来检查一下，确保幻读也不会发生。为此，我
们将启动一个事务，将 Bob 的账户恢复到之前的状态，并为 Charlie 创建一个新账户：

#+begin_src sql
  begin;

  update accounts set amount=200.00 where id=2;
  update accounts set amount=800.00 where id=3;
  insert into accounts values
  (4, 'charlie', 100.00);
  select * from acounts order by id;
#+end_src

在第二个会话中，让我们启动另一个事务，在 BEGIN 命令中明确指定可重复读取级别（第一个事务的级别并不重要）：

#+begin_src sql
  begin isolation level repeatable read;
  select * from accounts order by id;
#+end_src

现在，第一个事务提交其更改，第二个事务重复相同的查询：

#+begin_src sql
  commit;
  |  select * from accounts order by id;
  |  commit;
#+end_src

第二个事务看到的数据仍与之前相同：既看不到新行，也看不到行更新。在这种隔离级别下，您不必担心操作员之间会发生变化。

*序列化失败，而不是更新丢失。* 正如我们已经看到的，如果两个事务在 "读已提交 "级别更新同一行，就会导致读取偏移异常：
等待的事务必须重新读取锁定的行，因此与其他行相比，它在不同的时间点看到该行的状态。

可重复读取 "隔离级别不允许出现这种异常情况，如果出现这种情况，只能通过序列化失败中止事务。让我们通过重复应计利息的
情况来验证一下：

#+begin_src sql
  select * from accounts where client='bob';
  begin;
  update accounts set amount=amount-100.00 where id=3;
  | begin isolation level repeatable read;
  | update accounts set amount=amount*1.01
  | where client in (
  |   select client
  |   from accounts
  |   group by client
  |   having sum(amount)>=1000
  |  );
  commit;
#+end_src

#+begin_src sql
  rollback;
#+end_src

数据保持一致：

#+begin_src sql
  select * from accounts where client='bob';
#+end_src

任何并发的行更新都会引发相同的错误，即使它们影响的是不同的列。

如果我们试图根据先前存储的值更新余额，也会出现此错误：

#+begin_src sql
  begin isolation level repeatable read;
  select amount from accounts where id=1;
  |  begin isolation level repeatable read ;
  |  select amount from accounts where id=1;
  update accounts set amount=900.00+100.00 where id=1 returning amount;
  commit;
  | update accounts set amount=900.00+100.00 where id=1 returning amount;
  | rollback;
#+end_src

实践启示：如果您的应用程序对写事务使用可重复读取隔离级别，就必须准备好重试已完成但序列化失败的事务。对于只读事务，
这种结果是不可能发生的。

*写偏差* 正如我们所看到的，PostgreSQL 实现的可重复读取隔离级别可以防止标准中描述的所有异常情况。但并非所有可能
的异常情况：没有人知道有多少异常情况存在。然而，一个重要的事实已被证实：快照隔离并不能只防止两种异常情况，无论还有
多少其他异常情况存在。

第一个是写偏差。

让我们定义以下一致性规则：只要总余额不是负数，就允许客户的某些账户余额为负数。

第一笔交易得到Bob账户的总余额：

#+begin_src sql
  begin isolation level repeatable read;
  select sum(amount) from accounts where client='bob';
#+end_src

第二个事务获取到的相关的和

#+begin_src sql
  |  begin isolation level repeatable read;
  |  select sum(amount) from accounts where client='bob';
#+end_src

第一笔交易假定可以从其中一个账户中扣除 600 美元：

#+begin_src sql
  update accounts set amount=amount-600.00 where id=2;
#+end_src

第二笔交易的结论相同，但借记另一个账户：

#+begin_src sql
  | update accounts set amount=amount-600.00 where id=3;
  | commit;
  select * from accounts where client='bob';
#+end_src

Bob的总余额现在是负数，尽管如果分开运行，这两笔交易都是正确的。

*只读事务异常。* 只读事务异常是可重复读取隔离级别允许的第二种异常，也是最后一种异常。要观察这种异常情况，我们必须
运行三个事务：其中两个事务将更新数据，而第三个事务将只读。

但首先让我们恢复Bob的帐户：

#+begin_src sql
  update accounts set amount=900.00 where id=2;
  select * from accounts where client='bob';
#+end_src

第一笔交易计算的是Bob总余额的应计利息，并将这笔钱存入他的一个账户：

#+begin_src sql
  begin isolation level repeatable read; -- 1
  update accounts set amount=amount+(
    select sum(amount) from accounts where client='bob'
  )*0.01
  where id=2;
#+end_src

然后，第二笔交易从Bob的另一个账户中取出一些钱，并提交这一更改：

#+begin_src sql
  | begin isolation level repeatable read; -- 2
  | update accounts set amount=amount-100.00 where id=3;
  | commit;
#+end_src

如果第一个事务在此时提交，就不会出现异常：我们可以假设第一个事务在第二个事务之前提交（但反之亦然--第一个事务在第二
个事务进行任何更新之前已经看到 id = 3 的账户状态）。

#+begin_src sql
  begin isolation level repeatable read; -- 3
  select * from accounts where client='alice';
#+end_src

只有现在，第一笔交易才会被提交：

#+begin_src sql
  commit;
#+end_src

此时，第三个事务应该看到哪种状态呢？启动后，它可以看到第二个事务（已提交）所做的更改，但看不到第一个事务（尚未提交）
所做的更改。但正如我们已经确定的，第二个事务应被视为在第一个事务之后启动的。第三个事务看到的任何状态都是不一致的，
这正是只读事务异常的含义：

#+begin_src sql
  | select * from accounts where client='bob';
  | commit;
#+end_src

可序列化

可序列化隔离级别可防止所有可能的异常情况。该级别实际上建立在快照隔离之上。在可重复读取隔离级别不会出现的异常情况（
如脏读、不可重复读或幻读），在可串行化级别也不会出现。而出现的两种异常情况（写偏斜和只读事务异常）会以一种特殊的方
式被检测到，从而中止事务，导致我们已经熟悉的序列化失败。

*无异常* 让我们确保我们的写偏移方案最终会以序列化失败告终：

#+begin_src sql
  begin isolation level serializable;
  select sum(amount) from accounts where client='bob';
#+end_src

#+begin_src sql
  | begin isolation level serializable;
  | select sum(amount) from accounts where client='bob';
#+end_src

#+begin_src sql
  update accounts set amount=amount-600.00 where id=2;
#+end_src

#+begin_src sql
  | update accounts set amount=amount-600.00 where id=3;
  | commit;
#+end_src

#+begin_src sql
  commit;
#+end_src

只读事务异常的情况也会导致同样的错误。

*推迟只读事务。* 为了避免只读事务导致异常，从而影响数据一致性，PostgreSQL 提供了一种有趣的解决方案：可以推迟该
事务，直到其执行变得安全为止。这是 SELECT 语句被行更新阻塞的唯一情况。

我们将通过重复演示只读事务异常的场景来检查它：

#+begin_src sql
  update accounts set amount=900.00 where id=2;
  update accounts set amount=100.00 where id=3;
  select * from accounts where client='bob' order by id;
#+end_src

#+begin_src sql
  begin isolation level serializable; -- 1
  update accounts set amount=amount+(
    select sum(amount) from accounts where client='bob';
  )*0.01
  where id=2;

  | begin isolation level serializable; -- 2
  | update accounts set amount=amount-100.00 where id=3;
  | commit;
#+end_src

让我们明确地将第三个事务声明为只读和延迟：

#+begin_src sql
  | begin isolation level serializable read only deferrable;
  | select * from accounts where client='alice';
#+end_src

尝试运行查询会阻塞事务，否则就会导致异常。

只有当第一个事务提交后，第三个事务才能继续执行：

#+begin_src sql
  commit;
  | select * from accounts where client='bob';
  | commit;
#+end_src

因此，如果应用程序使用可序列化隔离级别，就必须准备好重试因序列化失败而结束的事务。(可重复读取 "级别也需要同样的方
法，除非应用程序仅限于只读事务）。

可串行化隔离级别带来了编程的简便，但付出的代价是异常检测和强制终止部分事务所产生的开销。如果在声明只读事务时明确使
用 READ ONLY 子句，就可以降低这种影响。但主要的问题当然是终止的事务数量有多大，因为这些事务必须重试。如果
PostgreSQL 只中止那些导致数据冲突和真正不兼容的事务，情况也不会太糟糕。但这种方法不可避免地会耗费大量资源，因为
它需要跟踪每一行的操作。

如果使用 Serializable 级别，应用程序的所有事务都必须遵守。当与其他级别结合使用时，Serializable 的行为与可重复
读取一样，无需任何通知。因此，如果决定使用 Serializable 级别，那么相应地修改 default_transaction_isolation
参数值是有意义的，即使有人仍然可以通过显式设置不同的级别来覆盖它。

此外，还有其他限制；例如，在可序列化级别运行的查询不能在副本上执行。虽然这个层级的功能在不断改进，但目前的限制和开
销使其吸引力大打折扣。

** 使用哪种隔离级别？

读已提交（Read Committed）是 PostgreSQL 的默认隔离级别，显然绝大多数应用程序都使用这个级别。这个级别很方便，
因为它只允许在出现故障时中止事务，而不会中止任何事务以保持数据一致性。换句话说，序列化失败不会发生，因此你不必担心
事务重试。

这一级别的缺点是可能出现大量异常情况，上文已对此进行了详细讨论。开发人员必须时刻牢记这些异常情况，并在编写代码时防
止其发生。如果不可能在一条 SQL 语句中定义所有需要的操作，那么就必须使用显式锁定。最困难的是，代码很难测试与数据不
一致相关的错误；这些错误可能以不可预测、几乎不可重现的方式出现，因此也很难修复。

可重复读取隔离级别消除了部分不一致问题，但并非全部。因此，你不仅要记住剩余的异常情况，还要修改应用程序以正确处理序
列化失败，这当然很不方便。不过，对于只读事务来说，该级别是对已提交读取级别的完美补充；它在构建涉及多个 SQL 查询的
报告等情况下非常有用。

最后，可序列化隔离级别让你完全不用担心数据一致性问题，这在很大程度上简化了代码的编写。应用程序唯一需要做的就是能够
重试任何因序列化失败而中止的事务。不过，中止的事务数量和相关开销会大大降低系统吞吐量。您还应该记住，可序列化级别不
支持副本，也不能与其他隔离级别结合使用。


















* 缓冲缓存

** 缓存

在现代计算系统中，高速缓存无处不在--无论是在硬件层面还是在软件层面。仅处理器就有多达三到四级缓存。RAID 控制器和磁
盘也增加了自己的缓存。

缓存用于均衡快慢类型内存之间的性能差异。快速内存价格昂贵，容量较小，而慢速内存容量大，价格便宜。因此，快速内存无法
容纳慢速内存中存储的所有数据。但在大多数情况下，只有一小部分数据在每个特定时刻被积极使用，因此分配一些快速内存作为
缓存来保存热数据，可以大大减少慢速内存访问所产生的开销。

在 PostgreSQL 中，缓冲存储器保存关系页，从而平衡磁盘（毫秒）和内存（纳秒）的访问时间。

操作系统也有自己的缓存，起到同样的作用。因此，数据库系统的设计通常会避免双重缓存：通常会绕过操作系统缓存，直接查询
存储在磁盘上的数据。但 PostgreSQL 使用的是另一种方法：它通过缓冲文件操作读写所有数据。

#+begin_comment
  如果使用直接 I/O，就可以避免双重缓存。这将减少开销，因为 PostgreSQL 将使用直接内存访问（DMA），而不是将缓冲页
  复制到 os 地址空间；此外，你还能立即控制磁盘上的物理写入。不过，直接I/O不支持缓冲区化带来的数据预取功能，因此
  必须通过异步I/O单独实现，这需要对PostgreSQL核心代码进行大量修改，还要处理操作系统在支持直接I/O和异步
  I/O时的不兼容性问题。但是，一旦异步通信设置完成，你就可以享受无等待磁盘访问的额外优势。

  PostgreSQL 社区已经开始了这一重大努力，但实际成果还需要很长时间才能显现。
#+end_comment

** 缓冲缓存设计

缓冲缓存位于服务器的共享内存中，所有进程都可以访问。它占据了共享内存的大部分，无疑是 PostgreSQL 中最重要、最复杂
的数据结构之一。了解缓存的工作原理本身就很重要，但由于许多其他结构（如子事务、CLOG 事务状态和 WAL 条目）都使用类
似的缓存机制（尽管比较简单），因此了解缓存的工作原理就更加重要了。

这种高速缓存的名称是受其内部结构的启发，因为它由一系列缓冲区组成。每个缓冲区都预留了一个内存卡盘，可容纳单个数据页
及其页头。

[[./images/xicEDi.png]]

页头包含缓冲区和其中页面的一些信息，例如

+ 页面的实际位置（文件 ID、分叉和分叉中的区块编号）
+ 该属性表明页面中的数据已被修改，迟早要写回磁盘（这样的页面称为 dirty 页面）。
+ 缓冲区使用计数
+ 钉住数或引用数

要访问某个关系的数据页，进程会向缓冲区管理器提出请求，并接收包含该页的缓冲区 ID。然后，它会读取缓存数据，并在需要
时直接在缓存中修改。当页面被使用时，其缓冲区会被钉住。插销禁止驱逐缓存页面，可以与其他锁一起使用。每个插值也会增加
使用次数。

只要页面处于缓存状态，使用时就不会产生任何文件操作。

我们可以使用 pg_buffercache 扩展来探索缓冲区缓存：

#+begin_src sql
  create extension pg_buffercache;
#+end_src

#+begin_src sql
  create table cacheme(
    id integer
  )with (autovaccum_enabled=off);
  insert into cacheme values(1);
#+end_src

现在，缓冲区缓存中的堆页面包含了新插入的记录。你可以通过选择与某个表相关的所有缓冲区来查看。我们将再次需要这样的查
询，因此让我们把它封装到一个函数中：

#+begin_src sql
  create function buffercache(rel regclass)
  returns table(
    bufferid integer, relfork text, relblk bigint,
    isdirty boolean, usagecount smallint, pins integer 
  ) as $$
  select bufferid,
    case relforknumber
      when 0 then 'main'
      when 1 then 'fsm'
      when 2 then 'vm'
    end,
    relblocknumber,
    isdirty,
    usagecount,
    pinning_backends
  from pg_buffercache
  where relfilenode = pg_relation_filenode(rel)
  order by relforknumber, relblocknumber
  $$ language sql;
#+end_src

#+begin_src sql
  select * from buffercache('cacheme');
#+end_src

页面为脏页面：已被修改，但尚未写入磁盘。其使用计数设置为 1。

** 缓冲命中

当缓冲区管理器需要读取一个页面时，它会首先检查缓冲区缓存。所有缓冲区 ID 都存储在一个哈希表中，用来加快搜索速度。

#+begin_comment
  许多现代编程语言都将哈希表作为基本数据类型之一。哈希表通常被称为关联数组，事实上，从用户的角度来看，哈希表看起来
  就像一个数组；但是，其索引（哈希键）可以是任何数据类型，例如，文本字符串而不是整数。

  虽然可能的键值范围可能相当大，但散列表一次绝不会包含那么多不同的值。散列的原理是使用散列函数将键值转换成整数。这
  个数字（或其部分比特）被用作一个常规数组的索引。该数组的元素称为哈希表桶。

  一个好的散列函数或多或少会将散列键均匀地分配到不同的散列桶中，但它仍有可能将相同的数字分配给不同的键，从而将它们
  放到同一个桶中；这就是所谓的碰撞。因此，值与散列键一起存储在桶中；要通过键访问散列值，PostgreSQL 必须检查桶中的
  所有键。
#+end_comment

哈希表有多种实现方式；在所有可能的选项中，缓冲存储器缓存使用的是可扩展表，它通过链式方式解决哈希碰撞问题。

哈希键由关系文件的 ID、分叉类型和分叉文件中页面的 ID 组成。这样，PostgreSQL 在知道页面后，就能快速找到包含该页
面的缓冲区，或确保该页面当前未被缓存。

[[./images/0soFQP.png]]

#+begin_comment
  缓冲区缓存的实现依赖于哈希表，这一点长期以来一直饱受诟病：当需要查找特定关系页占用的所有缓冲区时，这种结构毫无用
  处，而在运行 DROP 和 TRUNCATE 命令或在自动回收元组过程中截断表时，需要从缓存中移除页面。然而，迄今为止还没有人
  提出合适的替代方案。
#+end_comment

如果哈希表中包含所需的缓冲区 ID，缓冲区管理器就会将该缓冲区固定下来，并将其 ID 返回给进程。然后，该进程就可以开始
使用缓存页面，而不会产生任何 I/O 流量。

要固定一个缓冲区，PostgreSQL 必须递增其头部的固定计数器；一个缓冲区可以同时被多个进程固定。当缓冲区的引脚计数器
大于零时，缓冲区就被认为正在使用中，其内容不允许有任何重大改变。例如，可以出现一个新的元组（根据可见性规则，它将是
不可见的），但页面本身不能被替换。

当使用 analyze 和 buffers 选项运行时，EXPLAIN 命令会执行显示的查询计划，并显示已使用的缓冲区数量：

#+begin_src sql
  explain (analyze, buffers, costs off, timing off, summary off)
  select * from cacheme;
#+end_src

hit=1 表示在缓存中找到了唯一需要读取的页面。

缓冲区针脚会将使用次数增加一个：

#+begin_src sql
  begin;
  declare c cursor for select * from cacheme;
  fetch c;
#+end_src

#+begin_src sql
  select * from buffercache('cacheme');
#+end_src

如果一个进程无法使用一个固定的缓冲区，它通常会跳过该缓冲区，直接选择另一个缓冲区。我们可以在回收元组时看到这种情况：
#+begin_src sql
  vacuum verbose cacheme;
#+end_src

该页被跳过是因为其元组无法从被钉住缓冲区中物理移除。

但如果需要的正是这个缓冲区，进程就会加入队列，等待对该缓冲区的独占访问。这种操作的一个例子就是自动回收和冻结。

一旦光标关闭或移动到其他页面，缓冲区就会被解钉。在本例中，它发生在事务结束时：

#+begin_src sql
  commit;
  select * from buffercache('cacheme');
#+end_src

页面修改也受同样的固定机制保护。例如，让我们在表格中插入另一行（它将进入同一页面）：

#+begin_src sql
  insert into cacheme values(2);
  select * from buffercache('cacheme');
#+end_src

PostgreSQL 不会立即向磁盘写入任何内容：页面会在缓冲缓存中保持一段时间，为读取和写入提供一些性能提升。

** 缓存丢失

如果哈希表中没有与所查询页面相关的条目，则表示该页面未被缓存。在这种情况下，会分配一个新的缓冲区（并立即固定），将
页面读入该缓冲区，并相应修改哈希表引用。

让我们重启实例，清除其缓冲区缓存：

#+begin_src sh
  pg_ctl restart -l /home/postgres/logfile 
#+end_src

尝试读取页面将导致缓存缺失，页面将被加载到一个新的缓冲区：

#+begin_src sql
  explain (analyze, buffers, costs off, timing off, summary off)
  select * from cacheme;
#+end_src

计划现在显示的是读取状态，而不是命中，这表示缓存未命中。此外，该页面已经变脏，因为查询修改了一些提示位

缓冲区缓存查询显示，新添加页面的使用计数设置为 1：

#+begin_src sql
  select * from buffercache('cacheme');
#+end_src

pg_statio_all_tables 视图包含各表缓冲区缓存使用情况的完整统计数据：

#+begin_src sql
  select heap_blks_read, heap_blks_hit
  from pg_statio_all_tables
  where relname='cacheme';
#+end_src

PostgreSQL 为索引和序列提供了类似的视图。它们还可以显示 I/O 操作的统计信息，但前提是关闭 track_io_timing 功能。

缓冲区搜索和替换

为页面选择缓冲区并非易事。有两种可能的情况：

1. 服务器启动后，所有缓冲区都会清空，并绑定到一个列表中。
   
   当一些缓冲区仍然空闲时，下一个从磁盘读取的页面将占用第一个缓冲区，并将其从列表中移除。

   缓冲区只有在其页面消失而没有被其他页面取代时，才能返回列表。如果调用 DROP 或 TRUNCATE 命令，或者在自动回收
   过程中表被截断，就会出现这种情况。

2. 迟早会没有空闲的缓冲区（因为数据库的大小通常大于为缓存分配的内存块）。这时，缓冲区管理器必须选择一个已在使用的
   缓冲区，并从该缓冲区中驱逐缓存页面。这需要使用时钟扫描算法，时钟隐喻很好地说明了这一点。时钟指针指向其中一个缓
   冲区，开始绕缓冲区缓存一周，并在经过时将每个缓存页面的使用计数减少一个。时钟指针发现的第一个计数为零的未固定缓
   冲区将被清除。


因此，每次访问缓冲区（即钉住）时，使用计数都会递增，而当缓冲区管理器搜索要驱逐的页面时，使用计数就会减少。因此，最
近使用次数最少的页面会首先被驱逐，而访问次数较多的页面则会在缓存中保留更长时间。

正如你所猜测的那样，如果所有缓冲区的使用次数都不为零，那么时钟指针必须走完一圈以上的路程才能最终到达零值。为了避免
跑多圈，PostgreSQL 将使用计数限制为 5。

一旦找到要驱逐的缓冲区，就必须从哈希表中删除仍在该缓冲区中的页面引用。

但如果该缓冲区很脏，即包含一些修改过的数据，就不能简单地扔掉旧页面--缓冲区管理器必须先将其写入磁盘。

[[./images/jZ4DpS.png]]

然后，缓冲区管理器会将新页面读入找到的缓冲区--无论该缓冲区是否已被清空或仍处于空闲状态。为此，缓冲管理器使用缓冲
I/O，因此只有当操作系统无法在自己的缓存中找到页面时，才会从磁盘读取页面。

#+begin_comment
  然后，缓冲区管理器会将新页面读入找到的缓冲区--无论该缓冲区是否已被清空或仍处于空闲状态。为此，缓冲管理器使用缓冲
  I/O，因此只有当操作系统无法在自己的缓存中找到页面时，才会从磁盘读取页面。
#+end_comment

哈希表更新为引用新页面，缓冲区被钉住。缓冲区的使用计数会递增，现在设置为 1，这样在时钟指针遍历缓冲区缓存时，缓冲区
就有时间增加使用计数。

** 批量驱逐

如果进行批量读取或写入，一次性数据有可能很快将有用的页面从缓冲缓存中删除。

为谨慎起见，批量操作会使用相当小的缓冲区环，并在其边界内执行驱逐，而不会影响其他缓冲区。

#+begin_comment
  除了 "缓冲区环"，代码还使用了 "环形缓冲区 "一词。不过，这个同义词比较含糊，因为环形缓冲区本身由多个缓冲区（属
  于缓冲区缓存）组成。在这方面，"缓冲区环 "一词更为准确。
#+end_comment

一个特定大小的缓冲区环由一个接一个使用的缓冲区阵列组成。起初，缓冲区环是空的，各个缓冲区按照通常的方式从缓冲区缓存
中选择后，一个接一个地加入缓冲区环。然后，驱逐开始发挥作用，但只能在缓冲区环的范围内进行。

添加到环中的缓冲区不会被排除在缓冲区缓存之外，仍可被其他操作使用。因此，如果要重复使用的缓冲区被钉住，或其使用次数
大于 1，它就会被从环中分离出来，由另一个缓冲区取代。

PostgreSQL 支持三种驱逐策略。

*批量读取策略* 如果大型表的大小超过缓冲区缓存的 $ \frac{1}{4} $ 倍，则使用环形缓冲区对其进行顺序扫描。环形缓冲
区容量为 256kB（32 个标准页）。

这种策略不允许将脏页写入磁盘来释放缓冲区；相反，缓冲区会被从环中删除，并由另一个缓冲区取代。因此，读取无需等待写入
完成，因此读取速度更快。

如果发现表已被扫描，启动另一次扫描的进程会加入现有的缓冲区环，并访问当前可用的数据，而不会产生额外的 I/O 操作。 当
第一个进程完成扫描后，第二个进程将返回到表的跳过部分。

*批量写入策略* COPY FROM、CREATE TABLE AS SELECT 和 CREATE MATERIALIZED VIEW 命令，以及那些会导致表重写
的 ALTER TABLE 命令都采用了批量写入策略。分配的环非常大，默认大小为 16MB（2048 个标准页），但绝不会超过缓冲区缓
存总大小的 $ \frac{1}{8} $。

*自动回收策略* 在不考虑可见性映射的情况下执行全表扫描时，抽真空流程会使用抽真空策略。环形缓冲区的 RAM 为 256 kB
（32 个标准页）。

缓冲区环并不总能防止不必要的驱逐。如果 UPDATE 或 DELETE 命令会影响大量行，执行的表扫描就会应用批量读取策略，但
由于页面会不断被修改，缓冲环实际上就失去了作用。

另一个值得一提的例子是在 TOAST 表中存储超大数据。尽管需要读取的数据量可能很大，但烤焦的值总是通过索引来访问，因此
可以绕过缓冲区环。

让我们仔细看看批量读取策略。为简单起见，我们将创建一个表，使插入的行占用整个页面。默认情况下，缓冲区缓存大小为
16384 页，每页 8kB。因此，要使用缓冲区环进行扫描，表必须占用超过 4096 页的空间。

#+begin_src sql
  create table big(
    id integer primary key generated always as identity,
    s char(1000)
  ) with (fillfactor=10);
#+end_src

#+begin_src sql
  insert into big(s)
  select 'FOO' from generate_series(1, 4096+1);
#+end_src

让我们来分析一下表:

#+begin_src sql
  analyze big;
  select relname, relfilenode, relpages
  from pg_class
  where relname in ('big', 'big_pkey');
#+end_src

重启服务器以清除缓存，因为现在缓存中包含一些在分析过程中读取过的堆页面。

#+begin_src sh
    pg_ctl restart -l /home/postgres/logfilec
#+end_src

服务器重启后，让我们读取整个表:

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select id from big;
#+end_src

堆页面只占用 32 个缓冲区，这些缓冲区构成了该操作的缓冲区环：

#+begin_src sql
  select count(*)
  from pg_buffercache
  where relfilenode=pg_relation_filenode('big'::regclass);
#+end_src

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from big order by id;
#+end_src

因此，缓冲缓存最终会包含整个表和整个索引：

#+begin_src sql
  select relfilenode, count(*)
  from pg_buffercache
  where relfilenode in (
    pg_relation_filenode('big'),
    pg_relation_filenode('big_pkey')
  )
  group by relfilenode;
#+end_src

** 选择缓冲缓存大小

缓冲区缓存的大小由 shared_buffers 参数定义。众所周知，该参数的默认值较低，因此在安装 PostgreSQL 后立即增加该值
是合理的。在这种情况下，你必须重新加载服务器，因为共享内存是在服务器启动时分配给缓存的。

但我们如何才能确定一个合适的值呢？

即使是超大型数据库，同时使用的热数据集也是有限的。在完美的世界中，这组数据必须适合缓冲区缓存（为一次性数据保留一定空
间）。如果缓存的大小较小，那么正在使用的页面就会一直相互驱逐，从而导致过多的 I/O 操作。但不假思索地增加缓存大小也不
是个好主意： 内存是一种稀缺资源，此外，缓存越大，维护成本越高。

最佳缓冲存储器大小因系统而异：它取决于可用内存的总大小、数据配置文件和工作负载类型等因素。遗憾的是，没有一个神奇的
值或公式能让每个人都同样适合。

你还应该记住，PostgreSQL 中的缓存缺失并不一定会触发物理 I/O 操作。如果缓冲缓存很小，操作系统缓存就会使用剩余的
可用内存，在一定程度上可以平滑处理。但与数据库不同的是，操作系统对读取的数据一无所知，因此会采用不同的驱逐策略。

一般建议从 $ \frac{1}{4} $ 内存开始，然后根据需要调整这一设置。

最好的办法是进行实验：可以增加或减少缓存大小，然后比较系统性能。当然，这需要有一个与生产系统完全类似的测试系统，而
且必须能够重现典型的工作负载。

您还可以使用 pg_buffercache 扩展运行一些分析。例如，根据缓冲区的使用情况探索缓冲区的分布情况

#+begin_src sql
  select useagecount, count(*)
  from pg_buffercache
  group by usagecount
  order by useagecount;

#+end_src

NULL使用次数值对应的是空闲缓冲区。在这种情况下，这些值是意料之中的，因为服务器在重启后大部分时间都处于空闲状态。
已使用的缓冲区大多包含系统目录表的页面，这些页面由后端读取，用于填充系统目录缓存和执行查询。

我们可以检查每种关系的缓存比例，以及这些数据是否热门（如果页面的使用次数大于 1，则视为热门）：

#+begin_src sql
  select c.relname,
    count(*) blocks,
    round(100.0*8192*count(*) /
      pg_table_size(c.oid) ) as "% of rel",
    round(100.0*8192*count(*) filter (where b.usagecount > 1 ) /
      pg_table_size(c.oid) ) as "% hot"
  from pg_buffercache b
    join pg_class c on pg_relation_filenode(c.oid)=b.relfilenode
  where b.reldatabase in (
    0, -- cluster-wide objects
    (select oid from pg_database where datname=current_database())
  )
  and b.usagecount is not null
  group by c.relname, c.oid
  order by 2 desc
  limit 10;
#+end_src

该示例显示，big表及其索引已完全缓存，但其页面并未被频繁使用。

从不同角度分析数据，可以获得一些有用的见解。不过，在运行 pg_buffercache 查询时，请务必遵守以下简单规则：

+ 由于返回的数字会有一定程度的差异，因此请重复此类查询数次。
+ 不要不停地运行此类查询，因为 pg_buffercache 扩展会锁定所查看的缓冲区，即使只是短暂锁定。

** 级存预热

服务器重启后，缓存需要一些时间来预热，也就是说，需要积累当前使用的数据。立即缓存某些表可能会有帮助，pg_prewarm 扩
展正是为此目的而设计的：

#+begin_src sql
  create extension pg_prewarm;
#+end_src

除了将表载入缓冲缓存（或仅载入操作系统缓存）外，该扩展还能将当前缓存状态写入磁盘，并在服务器重启后恢复。要启用此功能
必须将此扩展库添加到 shared_preload_libraries，然后重启服务器：

#+begin_src sql
  alter system set shared_preload_libraries='pg_prewarm';
#+end_src

#+begin_src sh
  pg_ctl restart -l /home/postgres/logfile
#+end_src

如果 pg_prewarm.autoprewarm 设置未变，则会在服务器重载后自动启动一个名为 autoprewarm leader 的进程；一旦进
入 pg_prewarm.autoprewarm_interval 秒，该进程就会将缓存页面列表刷新到磁盘（使用 max_parallel_processes
插槽之一）。

#+begin_src sh
  ps -o pid,command \
     --ppid `head -n /usr/local/pgsql/data/postmaster.pid` | \
      grep prewarm
#+end_src

现在服务器已重新启动，big表不再缓存：

#+begin_src sql
  select count(*)
  from pg_buffercache
  where relfilenode=pg_relation_filenode('big'::regclass);
#+end_src

如果您有充分的理由假设整个表将被频繁使用，而磁盘访问会导致响应时间过长，那么您可以提前将该表加载到缓冲缓存中：

#+begin_src sql
  select pg_prewarm('big');
#+end_src

#+begin_src sql
  select count(*)
  from pg_buffercache
  where relfilenode=pg_relation_filenode('big'::regclass);
#+end_src

页面列表将转储到 PGDATA/autoprewarm.blocks 文件中。您可以等到 autoprewarm 领导第一次完成后再进行转储，但我
们将手动启动转储：

#+begin_src sql
  select autoprewarm_dump_now();
#+end_src

刷新页面的数量大于 4097，因为所有使用过的缓冲区都被考虑在内。文件以文本格式写入，其中包含数据库、表空间和文件的 ID
以及分叉号和段号：

#+begin_src sh
  head -n 10 /usr/local/pgsql/data/autoprewarm.blocks
#+end_src

再次重启服务器

#+begin_src sh
  pg_ctl restart -l /home/postgres/logfile
#+end_src

表会立即出现在缓存中：

#+begin_src sql
  select count(*)
  from pg_buffercache
  where relfilenode=pg_relation_filenode('big'::regclass);
#+end_src

所有的前期工作还是由autoprewarm领导者来完成：它读取文件，按数据库对页面进行排序，重新排序（以便尽可能按顺序读
取磁盘），然后将它们传递给自动重启工作者进行处理。

** 本地缓存

临时表不遵循上述工作流程。由于临时数据只对单个进程可见，因此没有必要将其加载到共享缓冲区缓存中。因此，临时数据使用
的是拥有表的进程的本地缓存。

一般来说，本地缓冲存储器的工作原理与共享缓冲存储器类似：

+ 页面搜索通过哈希表进行。
+ 驱逐遵循标准算法（除了不使用缓冲区环）。
+ 可钉住页面以避免被驱逐。

不过，本地缓存的实现要简单得多，因为它既不需要处理内存结构锁（缓冲区只能由单个进程访问），也不需要容错（临时数据最
多存在到会话结束）。

由于只有少数会话通常会使用临时表，因此本地缓存内存是按需分配的。会话可用的本地缓存最大容量受 temp_buffers 参数限
制

#+begin_comment
  尽管名称相似，但 temp_file_limit 参数与临时表无关；它与查询执行过程中可能创建的临时存储中间数据的文件有关。
#+end_comment

在 EXPLAIN 命令输出中，所有对本地缓冲区缓存的调用都标记为本地，而不是共享：

#+begin_src sql
  create temporary table tmp as select 1;
  explain (analyze, buffers, costs off, timing off, summary off)
  select * from tmp;
#+end_src

* 预写日志

** 日志

如果发生断电、操作系统错误或数据库服务器崩溃等故障，RAM 中的所有内容都将丢失；只有写入磁盘的数据会继续存在。要在故
障后启动服务器，必须恢复数据的一致性。如果磁盘本身已损坏，则必须通过备份恢复来解决同样的问题。

从理论上讲，你可以始终保持磁盘上数据的一致性。但实际上，这意味着服务器必须不断地向磁盘写入随机页面（尽管顺序写入的
成本更低），而且写入的顺序必须保证在任何特定时刻都不影响一致性（这很难实现，尤其是在处理复杂的索引结构时）。

与大多数数据库系统一样，PostgreSQL 采用了不同的方法。

服务器运行时，部分当前数据只能在 RAM 中获得，写入永久存储的时间被推迟。因此，在服务器运行期间，存储在磁盘上的数据总
是不一致的，因为页面不会被一次性刷新。但在 RAM 中发生的每一次变化（例如在缓冲缓存中执行的页面更新）都会被记录下来：
PostgreSQL 会创建一个日志条目，其中包含在需要时重复此操作所需的所有基本信息。

与页面修改相关的日志条目必须先于修改后的页面本身写入磁盘。这就是日志的名称：先写日志（write-ahead log），或
WAL。这一要求保证了在发生故障时，PostgreSQL 可以从磁盘读取 WAL 条目并重新播放，以重复已经完成的操作，因为这些操
作的结果还在 RAM 中，在崩溃前没有写入磁盘。

保持先写日志通常比向磁盘写入随机页面更有效率。WAL 条目构成了一个连续的数据流，即使是硬盘也能处理。此外，WAL 条目
通常小于页面大小。

在发生故障时，需要记录所有可能破坏数据一致性的操作。WAL 中尤其要记录以下操作：

+ 在缓冲区缓存中执行的页面修改--因为写入是延迟的
+ 事务提交和回滚--因为状态变化发生在 CLOG 缓冲区中，不会立即进入磁盘
+ 文件操作（如添加或删除表格时创建和删除文件和目录）--因为此类操作必须与数据变化同步

以下操作不会被记录：

+ 对UNLOGGED表进行操作
+ 对临时表进行操作--因为临时表的生命周期受到生成临时表的会话的限制

#+begin_comment
  在 PostgreSQL 出现之前，散列索引也不记录日志。它们唯一的作用是将哈希函数与不同的数据类型相匹配。
#+end_comment
  
除崩溃恢复外，WAL 还可用于从备份和复制中进行时间点恢复。

** WAL结构

逻辑结构

关于其逻辑结构，我们可以将 WAL 描述为长度可变的日志条目流。每个条目都包含一些有关特定操作的数据，前面有一个标准标
头。其中，标头提供了以下信息：

+ 与条目相关的事务 ID
+ 解释条目的资源管理器
+ 校验和来检测数据是否损坏
+ 条目长度
+ 引用前一个 WAL 条目

#+begin_comment
  WAL 通常是正向读取的，但某些工具（如 pg_rewind）可能会反向扫描。
#+end_comment

WAL 数据本身可以有不同的格式和含义。例如，它可以是一个页面片段，必须在指定偏移量处替换页面的某些部分。相应的资源管
理器必须知道如何解释和重放特定条目。表、各种索引类型、事务状态和其他实体都有单独的管理器。

WAL 文件占用服务器共享内存中的特殊缓冲区。WAL 使用的缓存大小由 wal_buffers 参数定义。默认情况下，该大小会自动
选择为缓冲区缓存总大小的 $ \frac{1}{32} $。

WAL 缓存与缓冲区缓存十分相似，但它通常以环形缓冲区模式运行：新条目被添加到头部，而旧条目则从尾部开始保存到磁盘。如
果 WAL 缓存太小，磁盘同步的执行频率就会超过需要。

在低负载情况下，插入位置（缓冲区头部）几乎总是与已保存到磁盘的条目位置（缓冲区尾部）相同：

#+begin_src sql
  select pg_current_wal_lsn(), pg_current_wal_insert_lsn();
#+end_src

#+begin_comment
  在 PostgreSQL 10 之前，所有函数名称都包含 XLOG 首字母缩写，而不是 WAL。
#+end_comment

PostgreSQL 使用一种特殊的数据类型：pg_lsn（日志序列号，LSN）来引用特定的条目。它表示从 WAL 开始到某个条目的 64
位字节偏移量。LSN 显示为以十六进制符号表示的两个 32 位数字，中间用斜线分隔。

创建一个表

#+begin_src sql
  create table wal(id integer);
  insert into wal values(1);
#+end_src

启动事务并记录 WAL 插入位置的 LSN：

#+begin_src sql
  begin;
  select pg_current_wal_insert_lsn();
#+end_src

现在运行一些任意命令，例如更新一行：

#+begin_src sql
  update wal set id=id+1;
#+end_src

页面修改在 RAM 的缓冲缓存中进行。这一更改会被记录在同样位于 RAM 中的 WAL 页面中。因此，插入 LSN 会提前：

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

为确保修改后的数据页严格按照相应的 WAL 条目刷新到磁盘，页眉会存储与该页相关的最新 WAL 条目的 LSN。您可以使用
pageinspect 查看该 LSN：

#+begin_src sql
  select lsn from page_header(get_raw_page('wal', 0));
#+end_src

整个数据库集群只有一个 WAL，而且会不断有新的条目被添加到 WAL 中。因此，页面中存储的 LSN 可能会小于
pg_current_wal_insert_lsn 函数在一段时间前返回的 LSN。但如果系统没有发生任何变化，这些数字将是相同的。

现在提交这个事务

#+begin_src sql
  commit;
#+end_src

提交操作也会被记录，插入 LSN 会再次更改：

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

提交会更新 CLOG 页面中的事务状态，而 CLOG 页面则保存在自己的缓存中。CLOG 缓存通常占用共享内存中的 128 个页面。
为了确保 CLOG 页面不会在相应的 WAL 条目之前被刷新到磁盘，CLOG 页面也必须跟踪最新 WAL 条目的LSN。但该信息存储
在 RAM 中，而非页面本身。

在某些时候，WAL 条目会被存入磁盘；然后，缓存中的 CLOG 和数据页就有可能被删除。如果必须在更早的时候驱逐它们，就会
被发现，WAL 条目就会被强制先存到磁盘上。

如果知道两个 LSN 位置，只需从一个位置减去另一个位置，就能计算出它们之间 WAL 条目的大小（以字节为单位）。你只需将
它们转换为 pg_lsn 类型：

#+begin_src sql
  select '0/3DF70948'::pg_lsn - '0/3DF708D8'::pg_lsn;
#+end_src

在这种特殊情况下，与 UPDATE 和 COMMIT 操作相关的 WAL 条目占用了大约 100 个字节。

您可以使用同样的方法来估算特定工作负载在单位时间内产生的 WAL 条目量。检查点设置需要这些信息。

物理结构

在磁盘上，WAL 以单独文件或段落的形式存储在 PGDATA/pg_wal 目录中。它们的大小由只读的 wal_segment_size 参数显
示。

对于高负载系统，增加分段大小是有意义的，因为这样可以减少开销，但这一设置只能在集群初始化时修改
（initdb --wal-segsize）。

WAL 条目会进入当前文件，直到空间耗尽；然后，PostgreSQL 会启动一个新文件。

我们可以了解某个条目位于哪个文件中，以及从文件开始的偏移量是多少：

#+begin_src sql
  select file_name, upper(to_hex(file_offset)) file_offset
  from pg_walfile_name_offset('0/3DF708D8');
#+end_src

文件名由两部分组成。最高的八位十六进制数字定义了用于从备份中恢复的时间轴，其余数字代表最高 LSN 位（最低 LSN 位显
示在 file_offset 字段中）。

要查看当前 WAL 文件，可以调用以下函数：

#+begin_src sql
  select *
  from pg_ls_waldir()
  where name='0000000100000000000000003D';
#+end_src

现在，让我们使用 pg_waldump 工具查看一下新创建的 WAL 条目的标头，该工具可以通过 LSN 范围（如本例）和特定事务 ID
过滤 WAL 条目。

pg_waldump 工具应代表 postgres 操作系统用户启动，因为它需要访问磁盘上的 WAL 文件。

#+begin_src sh
  pg_waldump -p /usr/local/pgsql/data/pg_wal -s 0/3DF708D8 -e 0/3DF70948
#+end_src

在这里，我们可以看到两个条目的标题。

第一个是由 Heap 资源管理器处理的 HOT_UPDATE 操作。blkref 字段显示更新的堆页面的文件名和页面 ID：

#+begin_src sql
  select pg_relation_filepath('wal');
#+end_src

第二个条目是由事务资源管理器监督的 COMMIT 操作。

** checkpoint保存点

为了在故障后恢复数据的一致性（即执行恢复），PostgreSQL 必须向前重放 WAL，并将代表丢失更改的条目应用到相应的页面
上。   为了找出丢失的内容，需要将存储在磁盘上的页面的 LSN 与 WAL 条目的 LSN 进行比较。但是，我们应该从哪一点开
始恢复呢？如果开始得太晚，在此之前写入磁盘的页面将无法接收所有更改，从而导致不可逆转的数据损坏。从一开始就进行恢复
是不现实的：我们不可能存储如此巨大的潜在数据量，也不可能接受如此长的恢复时间。我们需要一个逐渐向前移动的检查点，这
样就可以安全地从这一点开始恢复，并删除之前的所有 WAL 条目。

创建检查点的最直接方法是定期暂停所有系统操作，并强制将所有脏页面转到磁盘。这种方法当然是不可接受的，因为系统会无限
期地挂起，但挂起的时间相当长。

因此，检查点在时间上是分散的，实际上构成了一个时间间隔。检查点的执行由一个名为 checkpointer 的特殊后台进程完成。

*checkpoint开始* checkpointer 进程会将所有可即时写入的内容刷新到磁盘上： CLOG 事务状态、子事务元数据和其他
一些结构。

*checkpoint执行* 大部分检查点执行时间都花在将脏页面刷新到磁盘上。

首先，所有在检查点开始时为脏缓冲区的缓冲区头都会被设置一个特殊标签。由于不涉及任何 I/O 操作，所以这个过程非常快。

然后，checkpointer 会遍历所有缓冲区，并将有标记的缓冲区写入磁盘。它们的页面不会从缓存中删除：只是被写入，因此可
以忽略使用量和pin计数。

页面会按照其 ID 的顺序进行处理，以尽可能避免随机写入。为了更好地平衡负载，PostgreSQL 会交替使用不同的表空间（因
为它们可能位于不同的物理设备上）。

后端也可以将有标记的缓冲区写入磁盘--如果它们先写入的话。在任何情况下，缓冲区标签都会在此阶段被移除，因此就检查点而
言，每个缓冲区只会被写入一次。

当然，在检查点进行期间，缓冲区缓存中的页面仍然可以被修改。但由于新的脏缓冲区没有标记，checkpointer 会忽略它们。

*checkpoint完成*  当检查点开始时的所有缓冲区都被写入磁盘时，检查点就算完成了。从现在起（但不是更早！），检查点
的起点将被用作恢复的新起点。在此之前写入的所有 WAL 条目都不再需要。

[[./images/pFKC24.png]]

最后，checkpointer 会创建一个与检查点完成相对应的 WAL 条目，并指定检查点的起始 LSN。由于检查点启动时不会记录任
何日志，因此 LSN 可以属于任何类型的 WAL 条目。

PGDATA/global/pg_control 文件也会更新为最新完成的检查点。(在此过程结束之前，pg_control 会保留之前的检查点）。

[[./images/Kl7EWe.png]]

为了一劳永逸地弄清哪些点在哪里，让我们来看一个简单的例子。我们将使几个缓存页面变脏：

#+begin_src sql
  update big set s='FOO';
  select count(*) from pg_buffercache where isdirty;
#+end_src

当前的WAL位置

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

现在让我们手动完成检查点。所有的脏页面都将被刷新到磁盘上；由于系统中不会发生任何事情，因此不会出现新的脏页面：

#+begin_src sql
  checkpoint;
  select count(*) from pg_buffercache;
#+end_src

让我们看看检查点是如何反映在 WAL 中的：

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

#+begin_src sh
  pg_waldump \
      -p /usr/local/pgsql/data/pg_wal -s 0/3E7EF7E0 -e 0/3E7EF890
#+end_src

最新的 WAL 条目与检查点完成（CHECKPOINT_ONLINE）有关。该检查点的起始 LSN 在重做后指定；该位置与检查点开始时最
新插入的 WAL 条目相对应。

同样的信息也可以在 pg_control 文件中找到：

#+begin_src sh
  pg_controldata \
      -D /usr/local/pgsql/data | egerp 'Latest:.*location'
#+end_src

** 恢复

服务器启动时启动的第一个进程是 postmaster。postmaster 会启动启动进程，在出现故障时负责数据恢复。

为确定是否需要恢复，启动过程会读取 pg_control 文件并检查群集状态。通过 pg_controldata 工具，我们可以查看该文
件的内容：

#+begin_src sql
  pg_controldata \
  -D /usr/local/pgsql/data | grep state 
#+end_src

正常停止的服务器会显示 "shut down"状态；未运行的服务器显示 "in production "状态，则表示出现故障。在这种情况下，
启动进程将自动从同一 pg_control 文件中最新完成的检查点的起始 LSN 开始恢复。

#+begin_comment
  如果 PGDATA 目录中包含与备份相关的 backup_label 文件，则从该文件中获取起始 LSN 位置。
#+end_comment

startup进程会从定义的位置开始逐个读取 WAL 条目，并在页面的 LSN 小于 WAL 条目的 LSN 时将其应用到数据页面。如果
页面包含的 LSN 较大，则不应应用 WAL；事实上，由于 WAL 条目设计为严格按顺序重放，因此必须不应用 WAL。

不过，有些 WAL 条目会构成一个完整的页面映像，或称 FPI。这种类型的条目可应用于页面的任何状态，因为无论如何，所有页
面内容都会被擦除。这种修改被称为idempotent。注册事务状态更改是另一个idempotent 操作的例子：每个事务状态都是由
CLOG 中的某些位定义的，这些位无论之前的值如何都会被设置，因此无需在 CLOG 页面中保留最新更改的 LSN。

WAL 条目会应用到缓冲区缓存中的页面，就像正常运行时的常规页面更新一样。

文件从 WAL 中恢复的方式与此类似：例如，如果 WAL 条目显示文件必须退出，但由于某种原因文件丢失了，就会重新创建文件。

一旦恢复结束，所有未记录的关系都会被相应的初始化分叉覆盖。

最后，执行检查点以确保磁盘上恢复状态的安全。

startup进程的工作至此完成。

#+begin_comment
  经典的恢复过程包括两个阶段。在前滚阶段，重放 WAL 条目，重复丢失的操作。在回滚阶段，服务器会中止故障发生时尚未提
  交的事务。

  在 PostgreSQL 中，不需要第二阶段。恢复后，CLOG 将不包含未完成事务（技术上表示活动事务）的提交或中止位，但由于
  可以确定该事务已不再运行，因此将被视为中止。
#+end_comment

我们可以通过在即时模式下强制停止服务器来模拟故障：

#+begin_src sql
  pg_ctl stop -m immediate
#+end_src

下面是新的群集状态：

#+begin_src sh
  pg_controldata \
  -D /usr/local/pgsql/data | grep 'state'
#+end_src

当我们启动服务器时，startup进程会发现发生了故障，并进入恢复模式：

#+begin_src sh
  pg_ctl start -l /home/postgres/logfile
  tail -n 6 /home/postgres/logfile 
#+end_src

如果服务器正常停止，postmaster 会断开所有客户端，然后执行最后的检查点，将所有脏页面刷新到磁盘上。

注意当前的 WAL 位置：

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

现在让我们正确地停止服务器：

#+begin_src sh
  pg_ctl stop 
#+end_src

下面是新的群集状态：

#+begin_src sh
  pg_controldata \
      -D /usr/local/pgsql/data | grep state
#+end_src

在 WAL 的末尾，我们可以看到 CHECKPOINT_SHUTDOWN 条目，它表示最后的检查点：

最新的 pg_waldump 消息显示，该工具已将 WAL 读取到底。

让我们再次启动实例：

#+begin_src sh
  pg_ctl start -l /home/postgres/logfile
#+end_src

** 后端写入

如果后端需要从缓冲区中驱逐脏页面，就必须将该页面写入磁盘。这种情况是不可取的，因为它会导致等待--在后台异步写入要好
得多。

这项工作部分由 checkpointer 处理，但仍然不够。

因此，PostgreSQL 提供了另一个名为 bgwriter 的进程，专门用于后台写入。除了两个主要区别外，它依赖于与驱逐相同的缓
冲区搜索算法：

+ bgwriter 进程使用自己的时钟指针，绝不会落后于驱逐进程，通常还会超过驱逐进程。
+ 在遍历缓冲区的过程中，使用次数不会减少。

如果缓冲区未被钉住，且使用次数为零，则脏页面会被刷新到磁盘。因此，bgwriter 会在驱逐前运行，并主动将那些极有可能很
快被驱逐的页面写入磁盘。

它提高了被选中驱逐的缓冲区是干净的几率。

** WAL 设置

配置检查点

检查点持续时间（更确切地说，是将脏缓冲区写入磁盘的持续时间）由 checkpoint_completion_target 参数定义。其值指
定了两个相邻检查点开始之间分配给写入的时间分数。避免将该参数设置为 1：否则，下一个检查点可能会在前一个检查点完成之
前就已到期。由于不可能同时执行多个检查点，因此不会发生灾难，但正常运行仍可能受到干扰。

在配置其他参数时，我们可以使用以下方法。首先，我们定义在两个相邻检查点之间存储 WAL 文件的适当容量。卷越大，开销就
越小，但这个值无论如何都会受到可用空闲空间和可接受恢复时间的限制。

要估算通过正常加载生成此卷所需的时间，需要记下初始插入 LSN，并不时检查其与当前插入位置之间的差异。

接收到的数据被假定为检查点之间的典型间隔，因此我们将使用它作为 checkpoint_timeout 参数值。默认设置可能太小，例
如通常会增加到 30 分钟。

不过，有时负载很可能（甚至很有可能）会更高，因此在此时间间隔内生成的 WAL 文件会过大。在这种情况下，必须更频繁地执
行检查点。为了设置这样的触发器，我们将通过 max_wal_size 参数来限制恢复所需的 WAL 文件大小。当超过这个阈值时，服
务器会调用额外的检查点。

恢复所需的 WAL 文件包含最新完成的检查点和当前尚未完成的检查点的所有条目。因此，要估算它们的总容量，应将计算出的检
查点之间的 WAL 大小乘以 1 + checkpoint_completion_target。

在第 11 版之前，PostgreSQL 为两个已完成的检查点保留 WAL 文件，因此乘数为 2 + checkpoint_completion_target。

#+begin_comment
  在第 11 版之前，PostgreSQL 为两个已完成的检查点保留 WAL 文件，因此乘数为 2 +
  checkpoint_completion_target。
#+end_comment

采用这种方法后，大多数检查点都会按计划执行，每个 checkpoint_timeout 间隔执行一次；但如果负载增加，则会在 WAL
大小超过 max_wal_size 值时触发检查点。

定期对照预期数字检查实际进度：

*实际进度* 由已处理的缓存页面分数决定。

*预期进度（按时间）* 由已耗费的时间分数定义。假定检查点必须在 checkpoint_timeout ×
checkpoint_completion_target时间间隔内完成

*预期进度（按大小）* 由已经填满的 WAL 文件的分数定义，其预期数量根据 max_wal_size ×
checkpoint_completion_target 值估算。

如果脏页面被提前写入磁盘，checkpointer 就会暂停一段时间；如果有任何一个参数出现延迟，它就会尽快跟上。由于时间和
数据大小都考虑在内，PostgreSQL 可以使用相同的方法管理计划检查点和按需检查点。

检查点完成后，恢复不再需要的 WAL 文件将被删除；但仍保留几个文件（总大小不超过 min_wal_size）供重复使用，并进行
简单的重命名。

这种重命名可以减少不断创建和删除文件所产生的开销，但如果不需要，也可以使用 wal_recycle 参数关闭这一功能。

下图显示了正常情况下磁盘上存储的 WAL 文件大小的变化情况。

[[./images/toXskY.png]]

需要注意的是，磁盘上 WAL 文件的实际大小可能会超过 max_wal_size 值：

+ max_wal_size 参数指定的是所需的目标值，而不是硬性限制。如果负载激增，写入可能会落后于计划。
+ 服务器无权删除尚未复制或通过持续存档处理的 WAL 文件。如果启用此功能，必须对其进行持续监控，因为它很容易导致磁盘
  溢出。
+ 通过配置 wal_keep_size 参数，可以为 WAL 文件保留一定的空间。


配置后端写入

一旦配置了 checkpointer，还应该设置 bgwriter。这些进程必须能够在后端需要重用脏缓冲区之前将其写入磁盘。

在运行过程中，bgwriter 会定期暂停，睡眠时间以 bgwriter_delay 为单位。

两次暂停之间写入的页数取决于自上次运行以来后端访问缓冲区的平均数量（PostgreSQL 使用移动平均值来消除可能出现的峰
值，避免同时依赖非常旧的数据）。计算出的数字再乘以 bgwriter_lru_multiplier。但无论如何，单次运行中写入的页数不
能超过 bgwriter_lru_maxpages 值。

如果没有检测到脏缓冲区（即系统中没有发生任何事情），bgwriter 就会休眠，直到某个后端访问缓冲区。然后它就会被唤醒，
继续正常运行。

监控

检查点设置可以也应该根据监测数据进行调整。

如果执行大小触发检查点的频率超过 checkpoint_warning 参数的定义，PostgreSQL 就会发出警告。该设置应与预期的峰值
负载保持一致。

log_checkpoints 参数可将检查点相关信息打印到服务器日志中。让我们打开它：

#+begin_src sql
  alter system set log_checkpoints=on;
  select pg_reload_conf();
#+end_src

现在，我们将修改一些数据并执行检查点：

#+begin_src sql
  update big set s='BAR';
  checkpoint;
#+end_src

服务器日志会显示写入缓冲区的数量、检查点后 WAL 文件更改的一些统计信息、检查点持续时间以及两个相邻检查点起点之间的
距离（以字节为单位）：

#+begin_src sh
  tail -n 2 /home/postgres/logfile
#+end_src

最有用的数据是 pg_stat_bgwriter 视图中提供的后台写入和检查点执行的统计数据，这些数据会影响你的配置决策。

#+begin_comment
  在 9.2 版之前，这两项任务都由 bgwriter 执行；之后引入了一个单独的校验指针进程，但通用视图保持不变。
#+end_comment

#+begin_src sql
  select * from pg_stat_bgwriter \gx
#+end_src

除其他外，该视图还显示已完成检查点的数量：

+ checkpoints_timed 字段显示计划的检查点（达到 checkpoint_timeout 间隔时触发）。
+ checkpoints_req 字段显示按需检查点（包括达到 max_wal_size 大小时触发的检查点）。

checkpoint_req 值（与 checkpoints_timed 值相比）越大，表示执行检查点的频率越高。

以下关于页数的统计数据也非常重要：

+ buffers_checkpoint页由checkpointer写入
+ buffers_backend页由后端进程写入
+ buffers_clean页由bgwriter写入

在配置良好的系统中，buffers_backend 的值必须大大低于 buffers_checkpoint 和 buffers_clean 的总和。

设置后台写入时，请注意 maxwritten_clean 值：它显示 bgwriter 因超过 bgwriter_lru_maxpages 定义的阈值而不得
不停止的次数。

下面的调用将删除收集到的统计数据：

#+begin_src sql
  select pg_stat_reset_shared('bgwriter');
#+end_src

* WAL模式

** 性能

当服务器正常运行时，WAL 文件会不断写入磁盘。不过，这些写入都是顺序写入：几乎没有随机访问，因此即使是硬盘也能应付这
项任务。由于这种类型的负载与典型的数据文件访问截然不同，因此值得为 WAL 文件设置一个单独的物理存储空间，并用一个指
向挂载文件系统中目录的符号链接来取代 PGDATA/pg_wal 目录。

#+begin_comment
  有几种情况需要同时写入和读取 WAL 文件。第一种是显而易见的崩溃恢复；第二种是流复制。walsender 进程会直接从文件
  中读取 WAL 条目。 因此，如果副本没有收到 WAL 条目，而所需页面仍在主服务器的操作系统缓冲区中，则必须从磁盘读取数
  据。但访问仍然是顺序的，而不是随机的。
#+end_comment

WAL 条目可以用以下一种模式写入：

+ 在事务提交将所有相关 WAL 条目保存到磁盘之前，同步模式禁止任何进一步操作。
+ 异步模式意味着即时事务提交，WAL 条目随后在后台写入磁盘。

当前模式由同步synchronous_commit定义。  

*同步模式* 要可靠地记录提交事实，仅仅向操作系统传递 WAL 条目是不够的，还必须确保磁盘同步已经成功完成。由于同步意
味着实际的 I/O 操作（速度相当慢），因此最好尽量少执行同步。

为此，完成事务并将 WAL 条目写入磁盘的后端可以根据 commit_delay 参数的定义稍作停顿。不过，这只有在系统中至少有
commit_siblings 活动事务的情况下才会发生：在暂停期间，其中一些事务可能会完成，服务器将设法一次性同步所有 WAL 条
目。这就好比在电梯里等着有人冲进来。

默认情况下不会暂停。只有执行大量短期 OLTP 事务的系统才有必要修改 commit_delay 参数。

在可能的暂停后，完成事务的进程会将所有累积的 WAL 条目刷新到磁盘上，并执行同步（保存提交条目和与该事务相关的所有以前
的条目很重要；其他条目被写入只是因为不会增加成本）。

从这时起，ACID 的持久性要求就得到了保证--事务被视为已可靠提交。这就是同步模式成为默认模式的原因。

同步提交的缺点是延迟时间较长（COMMIT 命令在同步结束前不会返回控制权），系统吞吐量较低，尤其是对于 OLTP 负载。

*异步模式* 要启用异步提交，必须关闭 synchronous_commit 参数。

在异步模式下，WAL 条目由 walwriter 进程写入磁盘，该进程在工作和休眠之间交替运行。暂停的持续时间由
wal_writer_delay 值定义。

从暂停中醒来后，进程会检查缓存中是否有新的已完全填充的 WAL 页面。如果有这样的页面出现，进程会将它们写入磁盘，跳过
当前页面。否则，它会写入当前半空的页面，因为它已经醒来。

这种算法的目的是避免多次刷新同一个页面，从而为数据变化密集的工作负载带来明显的性能提升。

尽管 WAL 缓存被用作环形缓冲区，但当写到缓存的最后一页时，walwriter 就会停止；暂停之后，下一个写入周期会从第一页
开始。因此，在最坏的情况下，walwriter 需要运行三次才能写入特定的 WAL 条目：首先，它会写入缓存末尾的所有完整页面，
然后回到起始页，最后处理包含条目的未填充页面。但在大多数情况下，这只需要一到两个周期。

每次写入 wal_writer_flush_after 数据量时都会执行同步，并在写入周期结束时再次执行同步。

异步提交比同步提交更快，因为它们无需等待向磁盘的物理写入。但可靠性会受到影响：在故障发生前的 3 ×
wal_writer_delay 时限内（默认为 0.6 秒），提交的数据可能会丢失。

在现实世界中，这两种模式互为补充。在同步模式下，与长事务相关的 WAL 条目仍可异步写入空闲的 WAL 缓冲区。反之亦然，
即使在异步模式下，与即将从缓冲区缓存中剔除的页面相关的 WAL 条目也会被立即刷新到磁盘上，否则就无法继续运行。

在大多数情况下，系统设计师必须在性能和耐用性之间做出艰难的选择。

还可以为特定事务设置同步提交参数。如果能在应用程序级别将所有事务划分为绝对关键（如处理财务数据）或不太重要的事务，
就能在提高性能的同时避免丢失非关键事务。

为了了解异步提交可能带来的性能提升，让我们使用 pgbench 测试来比较两种模式下的延迟和吞吐量。

首先，初始化所需的表格：

#+begin_src sh
  pgench -i internals 
#+end_src

在同步模式下开始 30 秒测试：

#+begin_src sh
  pgbench -T 30 internals
#+end_src

现在以异步模式运行相同的测试：

#+begin_src sql
  alter system set synchronous_commit=off;
  select pg_reload_conf();
#+end_src

#+begin_src sh
  pgbench -T 30 internals
#+end_src

在异步模式下，这个简单的基准测试表明延迟明显降低，吞吐量（TPS）明显提高。当然，每个特定系统都会根据当前的负载情况
得出自己的数据，但很明显，这对短期 OLTP 事务的影响是非常明显的。

让我们恢复默认设置：

#+begin_src sql
  alter system reset synchronous_commit;
  select pg_reload_conf();
#+end_src

** 容错

不言而喻，在任何情况下，先写日志都必须保证崩溃恢复（除非持久存储本身损坏）。影响数据一致性的因素有很多，但我只介绍
最重要的几种：缓存、数据损坏和非原子写入。

缓存

数据在到达非易失性存储器（如硬盘）之前，会经过各种缓存。

磁盘写入只是指示操作系统将数据放入其缓存（缓存也容易崩溃，就像 RAM 的其他部分一样）。根据操作系统 I/O 调度程序的
设置，实际写入是异步进行的。

一旦调度程序决定刷新累积的数据，这些数据就会被转移到存储设备（如硬盘）的缓存中。存储设备也可以延迟写入，例如，将相
邻页面组合在一起。RAID 控制器在磁盘和操作系统之间增加了一个缓存级别。

除非采取特殊措施，否则数据在磁盘上可靠存储的时间仍是未知数。这通常并不重要，因为我们有 WAL，但 WAL 条目本身必须立
即可靠地保存到磁盘上。异步模式也是如此，否则就无法保证 WAL 条目比修改的数据更早进入磁盘。

检查点进程还必须以可靠的方式保存数据，确保脏页面从操作系统缓存中移至磁盘。此外，它还必须同步其他进程执行的所有文件
操作（如页面写入或文件删除）：当检查点完成时，所有这些操作的结果必须已经保存在磁盘上。

还有一些其他情况需要进行故障安全写入，例如在最小 WAL 级别执行未日志记录的操作。

操作系统提供了各种方法来确保将数据立即写入非易失性存储器。所有这些方法归结起来主要有以下两种：一种是在写入后调用单
独的同步命令（如 fsync 或 fdatasync），另一种是在打开或写入文件时指定执行同步（甚至绕过操作系统缓存直接写入）的
要求。

pg_test_fsync 实用程序可以帮助你根据操作系统和文件系统确定同步 WAL 的最佳方法；首选方法可以在 wal_sync_method
参数中指定。对于其他操作，系统会自动选择适当的同步方法，无法进行配置。

这里有一个微妙的方面，即在每种特定情况下，最合适的方法取决于硬件。例如，如果使用带有备用电池的控制器，就可以利用其
缓存，因为电池可以在断电时保护数据。

你应该记住，异步提交和缺乏同步是完全不同的两种情况。关闭同步（通过 fsync 参数）可以提高系统性能，但任何故障都会导
致致命的数据丢失。异步模式可以保证崩溃恢复到一致的状态，但可能会丢失一些最新的数据更新。

数据损坏

技术设备是不完美的，数据在内存和磁盘中或通过接口电缆传输时都可能受到损坏。这些错误通常都是在硬件层面上处理的，但也
会有一些漏网之鱼。

为了及时发现问题，PostgreSQL 总是通过校验和来保护 WAL 条目。

数据页也可以计算校验和。计算方法是在集群初始化时或在服务器停止时运行 pg_checksums 工具。

在生产系统中，必须始终启用校验和，尽管会产生一些（微小的）计算和验证开销。尽管仍存在一些死角，但它提高了及时发现损
坏的几率：

+ 校验和校验仅在访问页面时执行，因此数据损坏可能在很长时间内都不会被察觉，直到它进入所有备份，并且没有正确数据的来源
+ 归零的页面被认为是正确的，因此如果文件系统错误地将页面归零，这个问题将不会被发现。
+ 校验和只针对关系的主叉进行计算，其他复刻和文件（如 CLOG 中的事务状态）仍不受保护。

让我们来看看只读 data_checksums 参数，确保已启用校验和：

#+begin_src sql
  show data_checksums;
#+end_src

现在停止服务器，将表复刻零页中的几个字节清零：

#+begin_src sql
  select pg_relation_filepath('wal');
#+end_src

#+begin_src sh
  pg_ctl stop
  dd if=/dev/zero of=/usr/local/pgsql/data/${wal_man_fork}
#+end_src

再次开启服务器

#+begin_src sh
  pg_ctl start -l logfile 
#+end_src

事实上，我们本可以让服务器继续运行--只需将页面写入磁盘并从缓存中删除即可（否则，服务器将继续使用其缓存版本）。但这
样的工作流程较难重现。

现在，让我们试着读一下表格：

#+begin_src sql
  select * from wal limit 1;
#+end_src

如果无法从备份中恢复数据，至少可以尝试读取损坏的页面（冒着输出乱码的风险）。为此，必须启用
ignore_checksum_failure 参数：

#+begin_src sql
  set ignore_checksum_failure=on;
  select * from wal limit 1;
#+end_src

在这种情况下一切正常，因为我们损坏的是页眉的非关键部分（最新 WAL 条目的 LSN），而不是数据本身。

非原子写入

一个数据库页面通常需要 8kB ，但在底层，写入是按块进行的，而块通常更小（通常为 512 字节或 4kB）。因此，如果发生故
障，可能只能写入部分页面。在恢复过程中，对这样的页面应用常规 WAL 条目是没有意义的。

为避免部分写入，当检查点启动后首次修改页面时，PostgreSQL 会在 WAL 中保存完整页面映像（FPI）。这一行为由
full_page_writes 参数控制，但关闭它可能会导致致命的数据损坏。

如果恢复进程在 WAL 中发现了 FPI，它会无条件地将其写入磁盘（无需检查其 LSN）；就像任何 WAL 条目一样，FPI 也受到
校验和的保护，因此它们的损坏不会被忽视。然后，常规 WAL 条目将被应用到该状态，并保证其正确性。

没有单独的 WAL 条目类型用于设置提示位：这一操作被视为非关键操作，因为访问页面的任何查询都将重新设置所需的位。但是，
任何提示位的改变都会影响页面的校验和。因此，如果启用了校验和（或开启了关闭 wal_log_hints 参数），提示位的修改会
被记录为 FPI。

即使日志机制排除了 FPI 中的空白空间，生成的 WAL 文件的大小仍然会大幅增加。如果通过关闭 wal_compression 参数启
用 FPI 压缩，情况就会大大改善

让我们使用 pgbench 实用程序做一个简单的实验。我们将执行一个检查点，然后立即开始一个硬设置事务数的基准测试：

#+begin_src sql
  checkpoint;
  select pg_current_wal_insert_lsn();
#+end_src

#+begin_src sh
  pgbench -t 20000 internals
#+end_src

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

下面是生成的 WAL 条目的大小：

#+begin_src sql
  select pg_size_pretty('0/449755C0'::pg_lsn - '0/42CE5DA8'::pg_lsn);
#+end_src

在本例中，FPI 占据了 WAL 总大小的一半以上。你可以从收集到的统计数据中看到这一点，其中显示了 WAL 条目数（N）、常
规条目大小（记录大小）和每种资源类型的 FPI 大小（类型）：

#+begin_src sh
  pg_waldump --stats \
             -p /data/pg_wal -s 0/42CE5DA8 -e 0/449755C0
#+end_src

总而言之，当启用校验和或全页写入导致大量 FPI 时（即几乎总是如此），尽管会增加 CPU 开销，但使用压缩还是有意义的。

** WAL等级

先写日志的主要目的是实现崩溃恢复。但如果扩大记录信息的范围，WAL 还可以用于其他目的。

PostgreSQL 提供最小、副本和逻辑日志级别。每个级别都包含前一个级别记录的所有内容，并添加了更多信息。

使用的级别由 wal_level 参数定义；修改该参数需要重启服务器。

Minimal

最小级别只保证崩溃恢复。为了节省空间，如果对当前事务中创建或截断的关系进行操作会导致插入大量数据（如 CREATE TABLE
AS SELECT 和 CREATE INDEX 命令），则不会记录这些操作。所有需要记录的数据都会立即刷新到磁盘上，而不会被记录，系
统目录的更改也会在事务提交后立即可见。

如果此类操作因故障而中断，则已存入磁盘的数据将保持不可见，不会影响一致性。如果在操作完成时发生故障，应用后续 WAL 条
目所需的所有数据都已保存到磁盘中。

要使优化生效，必须写入新创建关系的数据量由 wal_skip_threshold 参数定义。

让我们看看最低级别的记录内容。

默认情况下，使用支持数据复制的较高副本级别。如果选择最低级别，还必须在 max_wal_senders 参数中将允许的 walsender
进程数设为零：

#+begin_src sql
  alter system set wal_level=minimal;
  alter system set max_wal_senders=0;
#+end_src

必须重新启动服务器，这些更改才能生效：

#+begin_src sh
  pg_ctl restart -l /home/postgres/logfile
#+end_src

注意当前wal的位置

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

截断表，并在同一事务中不断插入新行，直到超过 wal_skip_threshold 为止：

#+begin_src sql
  begin;
  truncate table wal;
  insert into wal
  select id from generate_series(1, 1000000) id;
  commit;
  select pg_current_wal_insert_lsn();
#+end_src

#+begin_comment
  我没有创建新表，而是运行 TRUNCATE 命令，因为它生成的 WAL 条目更少。
#+end_comment

让我们使用已经熟悉的 pg_waldump 工具来检查生成的 WAL。

#+begin_src sh
  pg_waldump \
      -p /data/pg_wal -s 0/45767698 -e 0/45767840#
#+end_src

第一条记录的是为关系创建一个新文件（因为 TRUNCATE 实际上重写了表）。

接下来的四个条目与系统目录操作有关。它们反映了 pg_class 表及其三个索引的变化。

最后是与提交相关的条目。数据插入不记录。

Replica

在崩溃恢复期间，WAL 条目会被重放，以将磁盘上的数据恢复到一致的状态。备份恢复的工作方式与此类似，但它也可以使用 WAL
存档将数据库状态恢复到指定的恢复目标点。存档 WAL 条目的数量可能相当多（例如，它们可能跨越数天），因此恢复期将包括
多个检查点。因此，最小 WAL 级别是不够的：如果操作未被记录，就不可能重复操作。对于备份恢复，WAL 文件必须包含所有操
作。

复制也是如此：未记录的命令不会发送到副本，也不会在副本上重播。

如果使用副本来执行查询，情况就会变得更加复杂。首先，它需要掌握主服务器上获取的独占锁信息，因为它们可能与副本上的查
询冲突。其次，它必须能够捕获快照，这就需要活动事务的信息。当我们处理副本时，本地事务和主服务器上运行的事务都必须考
虑在内。

向副本发送这些数据的唯一方法就是定期将其写入 WAL 文件。 这项工作由 bgwriter 进程完成，每 15 秒一次（时间间隔为
硬编码）。

从备份中执行数据恢复和使用物理复制的能力在复制级别得到保证。

默认情况下使用的是副本级别，因此我们只需重置上面配置的参数并重新启动服务器即可：

#+begin_src sql
  alter system reset wal_level;
  alter system reset max_wal_senders;
#+end_src

#+begin_src sh
  pg_ctl restart -l /data/logfile
#+end_src

让我们重复之前的工作流程（但现在我们只插入一行，以获得更整洁的输出）：

#+begin_src sql
  select pg_current_wal_insert_lsn();
#+end_src

#+begin_src sql
  begin;
  truncate table wal;
  insert into wal values(42);
  commit;
  select pg_current_wal_insert_lsn();
#+end_src

查看生成的 WAL 条目。

除了我们所看到的最低水平外，我们还有以下条目：

+ 复制相关的备用资源管理器条目： RUNNING_XACTS （活动事务）和 LOCK
+ 记录 UPDATE+INIT 操作的条目，该操作初始化一个新页面，并在该页面中插入一条新记录

#+begin_src sh
  pg_waldump \
      -p /data/pg_wal -s 0/45D88E48 -e 0/45D89108
#+end_src

Logical

最后但并非最不重要的一点是，逻辑层可以实现逻辑解码和逻辑复制。它必须在发布服务器上激活。

如果我们看一下 WAL 条目，就会发现这一级几乎与复制相同：它添加了与复制源相关的条目， 以及应用程序可能生成的一些任
意逻辑条目。在大多数情况下，逻辑解码依赖于活动事务信息（RUNNING_XACTS），因为它需要捕获快照来跟踪系统目录的变化。




























* 表级锁

** 关于锁

锁控制对共享资源的并发访问。

并发访问是指多个进程同时尝试获取同一个资源。这些进程是并行执行（如果硬件允许）还是在分时模式下顺序执行并无区别。如
果没有并发访问，则无需获取锁（例如，共享缓冲存储器需要加锁，而本地缓冲存储器则无需加锁）。

在访问资源前，进程必须获取资源锁；操作完成后，必须释放资源锁，其他进程才能使用资源。如果锁由数据库系统管理，那么既
定的操作顺序就会自动保持；如果锁由应用程序控制，那么协议就必须由应用程序自己执行。

在底层，锁只是一块共享内存，它定义了锁的状态（是否被获取）；它还可以提供一些附加信息，如进程编号或获取时间。

#+begin_comment
  正如你所猜测的，共享内存段本身就是一种资源。对此类资源的并发访问受操作系统提供的同步原语（如 semaphores 或
  mutexes）的控制。它们保证访问共享资源的代码严格连续执行。在最底层，这些基元基于 CPU 的原子指令（如
  test-and-set 或 compare-and-swap）。
#+end_comment

一般来说，我们可以使用锁来保护任何资源，只要它能被明确识别并分配一个特定的锁地址。

例如，我们可以锁定数据库对象，如表（由系统目录中的 oid 标识）、数据页（由文件名和文件中的位置标识）、行版本（由页
面和页面中的偏移量标识）。我们还可以锁定一个内存结构，例如哈希表或缓冲区（由分配的 ID 标识）。我们甚至可以锁定没有
物理表示的抽象资源。

但并不是每次都能一次性获得锁：资源可能已被其他人锁定。这时，进程要么加入队列（如果该特定锁类型允许的话），要么过一
段时间再尝试。无论哪种方式，进程都必须等待锁被释放。

我想特别指出两个会极大影响锁定效率的因素。

*粒度* 或锁的 "粒度"。如果资源形成层次结构，粒度就非常重要。

例如，表由页组成，页又由元组组成。所有这些对象都可以通过锁来保护。表级锁是粗粒度的；它们禁止并发访问，即使进程需要
访问不同的页面或行。

行级锁是细粒度的，因此没有这个缺点；但是，锁的数量会增加。为了避免与锁相关的元数据占用过多内存，PostgreSQL 可以采
用多种方法，其中之一就是锁升级：如果细粒度锁的数量超过某个阈值，它们就会被粒度更粗的单个锁取代。

*获取锁的一系列模式。*

通常只应用两种模式。独占模式与其他所有模式都不兼容，包括它自己。共享模式允许多个进程同时锁定一个资源。共享模式可用
于读取，而独占模式则用于写入。

一般来说，还可能有其他模式。模式的名称并不重要，重要的是它们的兼容性矩阵。

更精细的粒度和对多种兼容模式的支持为并发执行提供了更多机会。

所有的锁都可以按其持续时间分类。

*长期* 锁（Long-term locks）的获取时间可能会很长（在大多数情况下，直到事务结束）；它 们通常会保护关系
（relationship）和行（rows）等资源。这些锁通常由 PostgreSQL 自动管理，但用户对这一过程仍有一定的控制权。

长期锁提供多种模式，可对数据进行各种并发操作。它们通常有大量的基础设施（包括等待队列、死锁检测和仪器等功能），因为其
维护费用无论如何都要比对受保护数据的操作便宜得多。

*短期* 锁的获取时间仅为几分之一秒，持续时间很少超过几个 CPU 指令；它们通常保护共享内存中的数据结构。PostgreSQL
以完全自动化的方式管理此类锁。

短期锁通常只提供很少的模式和基本的基础设施，可能根本没有仪器。

PostgreSQL 支持多种类型的锁。重量级锁（在关系和其他对象上获取）和行级锁被视为长期锁。短期锁包括内存结构上的各种
锁。此外，还有一组不同的谓词锁，尽管它们的名字叫 "谓词锁"，但其实根本不是锁。

** 重量级锁

重量级锁是长期锁。它们在对象级别上获得，主要用于关系，但也可用于某些其他类型的对象。重量级锁通常保护对象不被并发更
新，或在重构过程中禁止使用对象，但也可以满足其他需求。这种模糊的定义是有意为之：这种类型的锁可用于各种用途。它们唯
一的共同点是内部结构。

除非另有明确规定，锁定一词通常意味着重量级锁定。

重量级锁位于服务器的共享内存中，可以在 pg_locks 视图中显示。它们的总数受 max_locks_per_transaction 值乘以
max_connections 的限制。

所有事务都使用共同的锁池，因此一个事务可以获得超过 max_locks_per_transaction 的锁。真正重要的是系统中锁的总数
不超过定义的限制。由于锁池是在服务器启动时初始化的，因此更改这两个参数中的任何一个都需要重启服务器。

如果资源已经被锁定在不兼容模式下，试图获取另一个锁的进程就会加入队列。等待的进程不会浪费 CPU 时间：它们会进入睡眠
状态，直到锁被释放，操作系统将其唤醒。

如果第一个事务在获得另一个事务锁定的资源之前无法继续运行，而另一个事务又需要第一个事务锁定的资源，那么两个事务就会
陷入死锁。这种情况比较简单，死锁也可能涉及两个以上的事务。由于死锁会导致无限等待，PostgreSQL 会自动检测到它们，并
中止其中一个受影响的事务，以确保正常操作可以继续。

不同类型的重量级锁有不同的用途，保护不同的资源，支持不同的模式，因此我们将分别考虑。

下面的列表提供了在 pg_locks 视图的 locktype 列中出现的锁类型名称：

事务ID和虚拟xid － 事务ID相关锁

表 － 表级锁

元组 － 锁定一个元组

对象 － 对非关系对象的锁定

扩展 － 某些索引类型使用的页面级锁

咨询 － 咨询锁

几乎所有重量级锁都是根据需要自动获取的，并在相应事务完成后自动释放。但也有一些例外：例如，关系级锁可以显式设置，而
咨询锁则始终由用户管理。

** 事务 ID 上的锁

每个事务总是对自己的 ID（虚拟和真实 ID，如果有的话）持有独占锁。

PostgreSQL 为此提供了两种锁定模式：独占模式和共享模式。它们的兼容性矩阵非常简单：共享模式与自身兼容，而独占模式不
能与任何模式结合。

|           | Shared | Exclusive |
| Shared    |        | X         |
| Exclusive | X      | X         |

为了跟踪某个特定事务的完成情况，进程可以在任何模式下请求这个事务 ID 上的锁。由于事务本身已经对自己的 ID 上了独占
锁，因此不可能再获得另一个锁。请求这个锁的进程会加入队列并进入休眠状态。一旦事务完成，锁被释放，队列中的进程就会醒
来。显然，它无法获取这个锁，因为相应的资源已经消失，但这个锁并不是实际需要的。

让我们在一个单独的会话中启动一个事务，并获取后台的进程 ID（PID）：

#+begin_src sql
  begin;
  select pg_backend_pid();
#+end_src

启动的事务对自己的虚拟 ID 持有独占锁：

#+begin_src sql
  select locktype, virtualxid, mode, granted
  from pg_locks where pid=38980;
#+end_src

locktype 是锁的类型，virtualxid 是虚拟事务 ID（标识被锁资源），mode 是锁定模式（本例中为独占模式）。granted
标志表示请求的锁是否已被获取。

一旦事务获得真实 ID，相应的锁就会被添加到这个列表中：

#+begin_src sql
  select pg_current_xact_id();
#+end_src

#+begin_src sql
  select locktype, virtualxid, transactionid as xid, mode, granted
  from pg_locks where pid=28980;
#+end_src

现在，该事务在其两个 ID 上都有独占锁。

** 表级锁

PostgreSQL 提供了多达八种锁定关系（表、索引或任何其他对象）的模式。有了这么多的模式，你就可以最大限度地增加在一个
关系上运行的并发命令数量。

下一页显示了兼容性矩阵，并附有需要相应锁定模式的命令示例。记住所有这些模式或试图找出它们命名背后的逻辑是没有意义的，
但浏览一下这些数据，得出一些一般性结论，并在需要时参考此表，肯定是非常有用的。

|                        | AS | RS | RE | SUE | S | SRE | E | AE |                                  |
| Access Share           |    |    |    |     |   |     |   | X  | SELECT                           |
| Row Share              |    |    |    |     |   |     | X | X  | SELECT FOR UPDATE/SHARE          |
| Row Exclusive          |    |    |    |     | X | X   | X | X  | INSERT,UPDATE,DELETE             |
| Share Update Exclusive |    |    |    | X   | X | X   | X | X  | VACCUM,CREATE INDEX CONCURRENTLY |
| Share                  |    |    | X  | X   |   | X   | X | X  | CREATE INDEX                     |
| Share Row Exclusive    |    |    | X  | X   | X | X   | X | X  | CREATE TRIGGER                   |
| Exclusive              |    | X  | X  | X   | X | X   | X | X  | REFRESH MAT.VIEW CONCURRENTLY    |
| ACCESS Exclusive       | X  | X  | X  | X   | X | X   | X | X  | DROP,TRUNCATE,VACUUM FULL,       |
|                        |    |    |    |     |   |     |   |    | LOCK TABLE,REFRESH MAT.VIEW      |

访问共享模式是最弱的一种模式；它可以与除访问独占模式以外的任何其他模式一起使用，而访问独占模式与所有模式都不兼容。
因此，SELECT 命令几乎可以与任何操作并行运行，但不能丢弃正在查询的表。

前四种模式允许并发修改堆，而其他四种则不允许。例如，CREATE INDEX 命令使用 "共享 "模式，该模式与自身兼容（因此可
以在一张表上并发创建多个索引），也与只读操作使用的模式兼容。因此，SELECT 命令可以与索引创建并行运行，而 INSERT、
UPDATE 和 DELETE 命令将被阻塞

相反，修改堆数据的未完成事务会阻塞 CREATE INDEX 命令。取而代之的是调用 CREATE INDEX CONCURRENTLY，它使用的
是较弱的共享更新独占模式：创建索引需要更长的时间（该操作甚至可能失败），但作为回报，允许并发数据更新。

ALTER 表命令有多种类型，使用不同的锁定模式（共享更新独占、共享行独占、访问独占）。所有这些在文档中都有说明。

本书这一部分的示例再次依赖于accounts表：

#+begin_src sql
  truncate accounts;
  insert into accounts(id, client, amount)
  values
  (1, 'alice', 100.00),
  (2, 'bob', 200.00),
  (3, 'charlie', 300.00);
#+end_src

我们将不得不多次访问 pg_locks 表，因此让我们创建一个视图，在单列中显示所有 ID，从而使输出更简洁：

#+begin_src sql
  create view locks as
  select pid,
    locktype,
    case locktype
      when 'relation' then relation::regclass::text
      when 'transactionid' then transactionid::text
      when 'virtualxid' then virtualxid
    end as lockid,
    mode,
    granted
  from pg_locks
  order by 1, 2, 3;
#+end_src

仍在第一个会话中运行的事务更新了一条记录。该操作会锁定accounts表及其所有索引，从而导致在行独占模式下获得两个关系
类型的新锁：

#+begin_src sql
  update accounts set amount=amount+100.00 where id=1;
#+end_src

#+begin_src sql
  select locktype, lockid, mode, granted
  from locks where pid=28980;
#+end_src

** 等待队列

重量级锁形成一个公平等待队列。如果进程试图获取的锁与当前锁或队列中其他进程请求的锁不兼容，该进程就会加入队列。

当第一个会话正在进行更新时，让我们尝试在另一个会话中为该表创建索引：

#+begin_src sql
  select pg_backend_pid();

  create index on accounts(client);
#+end_src

命令挂起，等待资源释放。事务尝试以共享模式锁定表，但无法锁定：

#+begin_src sql
  select locktype, lockid, mode, granted
  from locks where pid=29459;
#+end_src

现在让第三个会话启动 VACUUM FULL 命令。它也将加入队列，因为它需要使用 "访问独占 "模式，而该模式与所有其他模式都
有冲突：

#+begin_src sql
  select pg_backend_pid();

  vacuum full accounts;
#+end_src

#+begin_src sql
  select locktype, lockid, mode, granted
  from locks where pid=29662;
#+end_src

现在，所有后续竞争者都必须加入队列，无论其锁定模式如何。即使是简单的 SELECT 查询，也会老老实实地遵循 VACUUM
FULL，尽管它们与执行更新的第一个会话所持有的行独占锁兼容。

#+begin_src sql
  select pg_backend_pid();

  select * from accounts;
#+end_src

#+begin_src sql
  select locktype, lockid, mode, granted
  from locks where pid=29872;
#+end_src

[[./images/xq2zje.png]]

pg_blocking_pids 函数提供了所有等待的高级概览。它会显示在指定进程之前排队的所有进程的 ID，这些进程已经持有或希
望获得不兼容的锁：

#+begin_src sql
  select pid,
  pg_blocking_pids(pid),
  wait_event_type,
  state,
  left(query, 50) as query
  from pg_stat_activity
  where pid in (28980, 29459, 29662, 29872) \gx
#+end_src

要获取更多详细信息，可以查看 pg_locks 表中提供的信息。

一旦事务完成（提交或中止），所有锁都会被释放。队列中的第一个进程获得请求的锁并唤醒。

在这里，第一个会话中的事务提交会导致所有排队进程的顺序执行：

#+begin_src sql
  rollback;
#+end_src

* 行级锁

** 锁设计

得益于快照隔离，读取堆元组时无需锁定。但是，不能允许两个写事务同时修改同一条记录。在这种情况下，必须锁定行，但重量
级锁并不是一个很好的选择：每个重量级锁都会占用服务器共享内存的空间（数百字节，更不用说所有的支持基础架构了），而且
PostgreSQL 的内部机制并不是为处理大量并发的重量级锁而设计的。

一些数据库系统通过锁升级来解决这个问题：如果行级锁过多，就用粒度更细的单个锁（例如，页面级或表级锁）来代替。这种方
法简化了实施过程，但会极大地限制系统吞吐量。

在 PostgreSQL 中，特定行是否被锁定的信息只保留在其当前堆元组的头部。行级锁实际上是堆页面中的属性，而不是实际的锁，
它们不会以任何方式反映在 RAM 中。

记录通常在更新或删除时被锁定。 在这两种情况下，行的当前版本都会被标记为已删除。用于此目的的属性是 xmax 字段中指定的
当前事务的 ID，正是这个 ID（加上额外的提示位）表明行已被锁定。如果一个事务想修改一条记录，但在其当前版本的 xmax 字
段中看到一个活动事务 ID，那么它就必须等待该事务完成。一旦完成，所有锁都会被释放，等待的事务就可以继续。

这种机制可以根据需要锁定任意多行，无需额外费用。

这种解决方案的缺点是其他进程无法形成队列，因为 RAM 中没有关于此类锁的信息。因此，仍然需要重量级的锁：等待行被释放
的进程会请求对当前正在处理该行的事务 ID 加锁。一旦事务完成，该行就会再次可用。因此，重量级锁的数量与并发进程的数量
成正比，而不是与被修改的行成正比。

** 行级锁模式

行级锁支持四种模式。其中两种实现了独占锁，每次只能由一个事务获取，而另外两种提供了共享锁，可以由多个事务同时持有。

以下是这些模式的兼容性矩阵：

|               | Key Share | Share | No Key Update | Update |
|---------------+-----------+-------+---------------+--------|
| Key Share     |           |       |               | X      |
| Share         |           |       | X             | X      |
| No Key Update |           | X     | X             | X      |
| Update        | X         | X     | X             | X      |

排他模式

更新模式允许修改任何元组字段，甚至删除整个元组，而无键更新模式只允许那些不涉及与唯一索引相关的任何字段的更改（换句
话说，外键必须不受影响）。

UPDATE 命令会自动选择最弱的锁定模式；键通常保持不变，因此通常会在无键更新模式下锁定行。

让我们创建一个函数，使用 pageinspect 显示我们感兴趣的一些元组元数据，即 xmax 字段和几个提示位：

#+begin_src sql
  create function row_locks(relname text, pageno integer)
  returns table(
    ctid tid, xmax text,
    lock_only text, is_multi text,
    keys_upd text, keyshr text,
    shr text 
  )
  as $$
    select (pageno, lp)::text::tid,
    t_xmax,
    case when t_infomask & 128 = 128 then 't' end,
    case when t_infomask & 4096 = 4096 then 't' end,
    case when t_infomask2 & 8192 = 8192 then 't' end,
    case when t_infomask & 16 = 16 then 't' end,
    case when t_infomask & 16+64 = 16+64 then 't' end
    from heap_page_items(get_raw_page(relname, pageno))
    order by lp;
  $$ language sql;
#+end_src

现在在accounts表中启动一个事务，更新第一个账户的余额（键保持不变）和第二个账户的 ID（键得到更新）：

#+begin_src sql
  begin
  update accounts set amount=amount+100.00 where id=1;
  update accounts set id=20 where id=2;
#+end_src

该页面现在包含以下元数据：

#+begin_src sql
  select * from row_locks('accounts', 0) limit 2;
#+end_src

锁定模式由 keys_updated 提示位定义。

#+begin_src sql
  rollback;
#+end_src

SELECT FOR 命令使用相同的 xmax 字段作为锁定属性，但在这种情况下，还必须设置 xmax_lock_only 提示位。该位表示
元组已锁定但未删除，这意味着它仍是当前元组：

#+begin_src sql
  begin;
  select * from accounts where id=1 for no key update;
  select * from accounts where id=2 for update;
  select * from row_locks('accounts', 0) limit 2;
  rollback;
#+end_src

共享模式

共享模式适用于需要读取记录，但必须禁止其他事务修改该记录的情况。键共享模式允许更新除键属性外的任何元组字段。

在所有共享模式中，PostgreSQL 内核只使用 "键共享"（Key Share），在检查外键时使用。由于它与 "无键更新"（No Key
Update）独占模式兼容，因此外键检查不会干扰非键属性的并发更新。至于应用程序，它们可以使用自己喜欢的任何共享模式。

请允许我再次强调，简单的 SELECT 命令从不使用行级锁。

#+begin_src sql
  begin;
  select * from accounts where id=1 for key share;
  select * from accounts where id=2 for share;
#+end_src

下面是我们在堆元组中看到的内容：

#+begin_src sql
  select * from row_locks('accounts', 0) limit 2;
#+end_src

这两种操作都会设置 xmax_keyshr_lock 位，但可以通过其他提示位识别共享模式。

** 多事务

正如我们所见，锁定属性由 xmax 字段表示，该字段被设置为获得锁的事务的 ID。那么，如何为多个事务同时持有的共享锁设
置该属性呢？

在处理共享锁时，PostgreSQL 会使用所谓的多事务（multitransactions）。多事务（multitransaction）是一组事务，
它们被分配一个单独的 ID。组内成员及其锁定模式的详细信息存储在 PGDATA/pg_multixact 目录下的文件中。为了加快访问
速度，锁定的页面会缓存在服务器的共享内存中；所有更改都会被记录下来，以确保容错。

多重事务 ID 的 32 位长度与普通事务 ID 相同，但它们是独立发布的。这意味着事务和多重事务可能拥有相同的 ID。为了区
分这两种情况，PostgreSQL 使用了一个额外的提示位：xmax_is_multi。

让我们再添加一个由另一个事务获取的独占锁（键共享和无键更新模式兼容）：

#+begin_src sql
  begin;
  update accounts set amount=amount+100.00 where id=1;
#+end_src

#+begin_src sql
  select * from row_locks('accounts', 0) limit 2;
#+end_src

xmax_is_multi 位显示第一行使用的是多事务 ID 而不是普通 ID。

在不进一步讨论实现细节的情况下，让我们使用 pgrowlocks 扩展来显示所有可能的行级锁的信息：

#+begin_src sql
  create extension pgrowlocks;
  select * from pgrowlocks('accounts') \gx
#+end_src

它看起来很像查询 pg_locks 视图，但 pgrowlocks 函数必须访问堆页面，因为 RAM 不包含行级锁的信息。

#+begin_src sql
  commit;
#+end_src

#+begin_src sql
  rollback;  
#+end_src

由于multixact ID是32位的，它们会因为计数器的限制而被包围，就像普通的事务ID一样。因此，PostgreSQL 必须
以与冻结类似的方式处理多重事务 ID：用新的多重事务 ID 替换旧的多重事务 ID（如果当时只有一个事务持有锁，则用普通事
务 ID 替换旧的多重事务 ID）。

但是，普通事务 ID 只在 xmin 字段中冻结（因为 xmax 不为空表示元组已经过时，很快就会被删除），而对于多事务来说，必
须冻结的是 xmax 字段：当前行版本可能会被共享模式下的新事务重复锁定。

多事务冻结可通过服务器参数进行管理，这些参数与常规冻结参数类似：vacuum_multixact_freeze_min_age、
vacuum_multixact_freeze_table_age、autovacuum_multixact_freeze_max_age 以及
vacuum_multixact_failsafe_age。

** 等待队列

排他模式

由于行级锁只是一个属性，队列的排列方式并不复杂。当一个事务要修改一条记录时，它必须遵循以下步骤：

1. 如果 xmax 字段和提示位都表明该行以不兼容模式锁定，则对正在修改的元组获取排他性重量级锁定。
2. 如有必要，可通过请求 xmax 事务 ID 上的锁（如果 xmax 包含一个 mutixact ID，则可请求多个事务），等待所有不兼
   容的锁被释放。
3. 在元组标头 xmax 中写入自己的 ID，并设置所需的提示位。
4. 如果在第一步中获得了元组锁，则释放该锁。

元组锁是另一种重量级锁，具有元组类型（不要与普通的行级锁混淆）。

第 1 步和第 4 步看似多余，只需等待所有锁定事务结束即可。然而，如果多个事务都试图更新同一条记录，那么所有这些事务都
将等待当前正在处理这条记录的事务。一旦该事务完成，它们就会发现自己处于争夺锁定该行权利的竞争状态，一些 "不幸 "的事
务可能不得不无限期地等待很长时间。这种情况称为资源饥饿。

元组锁可识别队列中的第一个事务，并保证它是下一个获得锁的事务。

但你可以自己看一下。由于 PostgreSQL 在运行过程中会获得许多不同的锁，而每一个锁都会反映在 pg_locks 表中的单独
一行中，因此我将在 pg_locks 表上创建另一个视图。它将以更简洁的形式显示这些信息，只保留我们当前感兴趣的锁（与
accounts表和事务本身有关的锁，虚拟 ID 上的锁除外）：

#+begin_src sql
  create view locks_accounts as
  select pid,
    locktype,
    case locktype
      when 'relation' then relation::reglcass::text
      when 'transactionid' then transactionid::text
      when 'tuple' then relation::regclass||'('||page||','||tuple||')'
    end as lockid,
    mode,
    granted
  from pg_locks
  where locktype in ('relation', 'transactionid', 'tuple')
    and (locktype!='relation' or relation='accounts'::regclass)
  order by 1, 2, 3;
#+end_src

让我们开始第一个事务并更新一行：

#+begin_src sql
  begin;
  select txid_current(), pg_backend_pid();
  update accounts set amount=amount+100.00 where id=1;
#+end_src

该事务已完成工作流程中的所有四个步骤，并锁定了表格：

#+begin_src sql
  select * from locks_accounts where pid=30723;
#+end_src

启动第二个事务并尝试更新同一行。该事务将挂起，等待锁定：

#+begin_src sql
  begin;
  select txid_current(), pg_backend_pid();
  update accounts set amount=amount+100.00 where id=1;
#+end_src

[[./images/s4Wgr6.png]]

第二个事务只完成了第二步。因此，除了锁定表和自己的 ID 外，它还增加了两个锁，这两个锁也反映在 pg_locks 视图中：第
一步获得的元组锁和第二步请求的第二个事务的 ID 锁：

#+begin_src sql
  select * from locks_accounts where pid=30790;
#+end_src

第三个事务将卡在第一步。它将尝试获取元组上的锁，并在此时停止：

#+begin_src sql
  begin
  select txid_current(), pg_backend_pid();
  update accounts set amount=amount+100.00 where id=1;
#+end_src

#+begin_src sql
  select * from locks_accounts where pid=30865;
#+end_src

试图更新该行的第四个事务和所有后续事务在这方面与第三个事务没有区别：它们都在等待同一个元组锁。

#+begin_src sql
  begin;
  select txid_current(), pg_backend_pid();
  update accounts set amount=amount+100.00 where id=1;
#+end_src

#+begin_src sql
  select * from locks_accounts where pid=30865;
#+end_src

[[./images/bRDwNq.png]]

要全面了解当前的等待情况，可以用锁定进程的信息来扩展 pg_stat_activity 视图：

#+begin_src sql
  select pid, wait_event_type,
    pg_blocking_pids(pid)
  from pg_stat_activity
  where pid in (30723, 30794, 30865, 30936);
#+end_src

如果第一个事务被中止，一切都会按预期进行：所有后续事务都会向前移动一步，不会跳过队列。

然而，第一个事务更有可能被提交。在可重复读取或可串行化隔离级别，这会导致串行化失败，因此第二个事务必须中止（队列中
的所有后续事务也会中止）。但在已提交读取隔离层，修改后的记录将被重新读取，其更新将被重试

因此，第一个事务已提交：

#+begin_src sql
  commit;
#+end_src

第二个事务唤醒并成功完成工作流程的第三和第四步：

#+begin_src sql
  select * from locks_accounts where id=30794;
#+end_src

第二个事务释放元组锁后，第三个事务也会醒来，但它会发现新元组的 xmax 字段已包含不同的 ID。

至此，上述工作流程结束。在 "已提交读取 "隔离级别，会再尝试锁定记录，但不会按照概述的步骤进行。现在，第三个事务正在
等待第二个事务完成，而没有尝试获取元组锁：

#+begin_src sql
  select * from locks_accounts where pid=30865;
#+end_src

第四次事务也是如此：

#+begin_src sql
  select * from locks_accounts where pid=30936;
#+end_src

现在，第三个和第四个事务都在等待第二个事务的完成，有可能陷入竞赛状态。队列实际上已经崩溃。

如果其他事务在队列还存在时就加入，那么所有事务都会被拖入这场竞赛。

结论：在多个并发进程中更新同一个表行不是一个好主意。在高负载情况下，这个热点会很快变成瓶颈，导致性能问题。

让我们提交所有已启动的事务。

#+begin_src sql
  commit;
#+end_src

#+begin_src sql
  commit;
#+end_src

#+begin_src sql
  commit;
#+end_src

共享模式

PostgreSQL 获取共享锁仅用于参照完整性检查。在高负载应用程序中使用共享锁会导致资源枯竭，而两级锁模型无法避免这种结
果。

让我们回顾一下事务锁定记录的步骤：

1. 如果 xmax 字段和提示位表明该行在独占模式下被锁定，则获取独占的重量级元组锁。
2. 如果需要，可通过请求 xmax 事务 ID 上的锁（如果 xmax 包含多重 ID，则可请求多个事务），等待所有不兼容的锁被释
   放。
3. 将自己的 ID 写入元组标头的 xmax 中，并设置所需的提示位。
4. 如果在第一步中获得了元组锁，则释放该锁。

前两个步骤意味着，如果锁定模式兼容，事务将跳转队列。

让我们从头开始重复实验。

#+begin_src sql
  truncate accounts;
#+end_src

#+begin_src sql
  insert into accounts(id, client, amount)
  values
    (1, 'alice', 100.00),
    (2, 'bob', 200.00),
    (3, 'charlie', 300.00)
#+end_src

开始第一个事务

#+begin_src sql
  begin;
  select txid_current(), pg_backend_pid();
#+end_src

现在，该行已锁定为共享模式：

#+begin_src sql
  select * from accounts where id=1 for share;
#+end_src

第二个事务试图更新同一行，但这是不允许的： 共享和无键更新模式不兼容：

#+begin_src sql
  begin;
  select txid_current(), pg_backend_pid();
  update accounts set amount=amount+100.00 where id=1;
#+end_src

在等待第一个事务完成的同时，第二个事务持有元组锁，就像前面的例子一样：

#+begin_src sql
  select * from locks_accounts where pid=30794;
#+end_src

[[./images/MziVSL.png]]

现在让第三个事务以共享模式锁定该行。这种锁与已获得的锁兼容，因此该事务会跳转到队列中：

#+begin_src sql
  begin;
  select txid_current(), pg_backend_pid();
  select * from accounts where id=1 for share;
#+end_src

我们有两个事务在锁定同一行：

#+begin_src sql
  select * from pgrowlocks('accounts') \gx
#+end_src

[[./images/GAB8uK.png]]

如果第一个事务在此时完成，第二个事务就会醒来，发现该行仍被锁定，并返回到队列中，但这次它会发现自己排在第三个事务之
后：

#+begin_src sql
  commit;
#+end_src

#+begin_src sql
  select * from locks_accounts where pid=30794;
#+end_src

只有当第三个事务完成后，第二个事务才能执行更新（除非在此时间间隔内出现其他共享锁）。

#+begin_src sql
  commit;
#+end_src

#+begin_src sql
  commit;
#+end_src

外键检查不太可能导致任何问题，因为键属性通常保持不变，而且键共享可以与无键更新一起使用。但在大多数情况下，应避免在
应用程序中共享行级锁。

** 无等待锁

SQL 命令通常会等待请求的资源被释放。但有时，如果不能立即获得锁，取消操作也是有意义的。为此，SELECT、LOCK 和
ALTER 等命令提供了 NOWAIT 子句。

锁定一行

#+begin_src sql
  begin;
  update accounts set amount=amount+100.00 where id=1;
#+end_src

如果请求的资源已锁定，则带有 NOWAIT 子句的命令会立即完成，并显示错误：

#+begin_src sql
  select * from accounts for update nowait;
#+end_src

应用程序代码可以捕捉并处理此类错误。

UPDATE 和 DELETE 命令没有 NOWAIT 子句。相反，可以使用 SELECT FOR UPDATE NOWAIT 命令尝试锁定记录，然后在尝
试成功后更新或删除记录。

在某些罕见的情况下，跳过已锁定的行并立即开始处理可用的行可能会很方便。这正是使用 SKIP LOCKED 子句运行 SELECT
FOR 时要做的事情：

#+begin_src sql
  select * from accounts
  order by id
  for update skip locked limit 1;
#+end_src

在本例中，跳过了第一行（已锁定），查询锁定并返回了第二行。

通过这种方法，我们可以批量处理行，或设置事件队列的并行处理。不过，请避免为该命令发明其他用例--大多数任务都可以用简
单得多的方法来解决。

最后但并非最不重要的一点是，您可以通过设置超时来避免长时间等待：

#+begin_src sql
  set lock_timeout='1s';
  alter table accounts drop column amount;
#+end_src

由于未能在一秒内获得锁，命令完成时出现错误。超时不仅可以在会话级别设置，也可以在更低级别设置，例如针对某个事务。

当需要独占锁的命令在负载情况下执行时，该方法可防止在表格处理过程中出现长时间等待。如果发生错误，该命令可以在一段时
间后重试。

#+begin_comment
  statement_timeout 限制操作符执行的总时间，而 lock_timeout 参数则定义等待锁的最长时间。
#+end_comment

#+begin_src sql
  rollback;
#+end_src

** 死锁

一个事务有时可能需要另一个事务正在使用的资源，而另一个事务可能正在等待第三个事务锁定的资源，如此循环。此类事务会使用
重量级锁进行排队。

但是，队列中的事务有时可能需要另一个资源，因此必须再次加入同一队列，等待该资源被释放。这时就会出现死锁：队列现在有一
个循环依赖关系，无法自行解决。

为了更直观，我们来画一个等待图。图中的节点代表活动进程，而箭头所示的边则从等待锁的进程指向持有这些锁的进程。如果图
中出现循环，即节点可以沿着箭头到达自身，则表示发生了死锁。

#+begin_comment
  这里的插图显示的是事务而不是进程。这种替换通常是可以接受的，因为一个事务由一个进程执行，而锁只能在一个事务中获
  取。但一般来说，更正确的说法是进程，因为有些锁可能不会在事务完成后立即释放。
#+end_comment

如果发生了死锁，而参与方都没有设置超时，那么事务将永远互相等待。这就是锁管理器自动检测死锁的原因。

不过，这种检查需要花费一些精力，而每次请求锁时都不应该浪费精力（毕竟死锁不会经常发生）。因此，如果进程获取锁的尝试
不成功，并在加入队列后睡着了，PostgreSQL 就会自动设置一个由 deadlock_timeout 参数定义的超时。如果资源提前可用，
那就太好了，可以避免检查的额外费用。但如果在 deadlock_timeout 单位时间后继续等待，等待进程就会醒来并启动检查。

[[./images/jYjEmN.png]]

这种检查实际上是建立一个等待图，并在其中搜索周期。为了 "冻结 "图的当前状态，PostgreSQL 会在整个检查过程中停止任
何重量级锁的处理。

如果没有检测到死锁，进程就会再次进入休眠状态；迟早会轮到它。

如果检测到死锁，其中一个事务将被迫终止，从而释放锁，使其他事务能够继续执行。在大多数情况下，启动检查的事务会被中
断，但如果循环中包括一个autovacuum进程，而该进程当前没有冻结元组以防止修改，服务器就会终止优先级较低的
autovacuum进程。

死锁通常表明应用程序设计不当。要发现这种情况，需要注意两点：服务器日志中的相应信息和 pg_stat_database 表中不断
增加的死锁值。

行更新产生的死锁

虽然死锁最终是由重量级锁造成的，但主要是以不同顺序获取的行级锁导致了死锁。

假设一笔交易要在两个账户之间转账 100 美元。首先从第一个账户中提取这笔款项：

#+begin_src sql
  begin;
  update accounts set amount=amount-100.00 where id=1;
#+end_src

与此同时，另一笔交易将从第二个账户向第一个账户转账 10 美元。它首先从第二个账户中提取这笔钱：

#+begin_src sql
  begin;
  update accounts set amount=amount-10.00 where id=2;
#+end_src

现在，第一笔交易试图增加第二个账户的金额，但发现相应的行已被锁定：

#+begin_src sql
  update accounts set amount=amount+100.00 where id=2;
#+end_src

然后第二个交易试图更新第一个账户，但也被锁定：

#+begin_src sql
  update accounts set amount=amount+10.00 where id=1;
#+end_src

这种循环等待永远不会自行解决。由于无法在一秒内获取资源，第一个事务会启动死锁检查，并被服务器中止：

[[./images/5aS7ax.png]]

现在第二个事务可以继续了。它唤醒并执行更新：

完成这个事务

#+begin_src sql
  rollback;
#+end_src

#+begin_src sql
  rollback;
#+end_src

执行此类操作的正确方法是按相同顺序锁定资源。例如，在本例中，可以根据账户编号按升序锁定账户。

两个UPDATE语句产生的死锁

在某些情况下，死锁似乎是不可能发生的，但它们确实发生了。

我们通常认为 SQL 命令是原子性的，但它们真的是原子性的吗？让我们仔细看看 UPDATE：该命令在更新记录时锁定记录，而不
是一次性全部更新，而且不会同时进行。因此，如果一条 UPDATE 命令以一种顺序修改多条记录，而另一条命令以另一种顺序进
行同样的修改，就会出现死锁。

让我们重现一下这个场景。首先，我们要在金额列上建立一个降序索引：

#+begin_src sql
  create index on accounts(amount desc);
#+end_src

为了能够观察这一过程，我们可以编写一个函数来减慢速度：

#+begin_src sql
  create function inc_slow(n numeric)
  returns numeric
  as $$
    select pg_sleep(1);
    select n+100.00;
  $$ language sql;
#+end_src

第一条 UPDATE 命令将更新所有数据元组。执行计划依赖于对整个表的顺序扫描。

#+begin_src sql
  explain (costs off)
  update accounts set amount=inc_slow(amount);
#+end_src

为了确保堆页面根据金额列以升序存储行，我们必须截断表并重新插入行：

#+begin_src sql
  truncate accounts;
  insert into accounts(id, client, amount)
  values
    (1, 'alice', 100.00),
    (2, 'bob', 200.00),
    (3, 'charlie', 300.00);
  analyze accounts;
  select ctid, * from accounts;
#+end_src

顺序扫描将以相同的顺序更新行（但对于大型表来说，并非总是如此）。

让我们开始更新吧：

#+begin_src sql
  update accounts set amount=inc_slow(amount);
#+end_src

同时，我们将在另一个会话上禁止顺序扫描：

#+begin_src sql
  set enable_seqscan=off;
#+end_src

因此，规划器会为下一条 UPDATE 命令选择索引扫描。

#+begin_src sql
  explain (costs off)
  update accounts set amount=inc_slow(amount)
  where amount>100.00;
#+end_src

第二和第三行满足条件；由于索引是降序的，因此行将以相反的顺序更新。

开始下一个更新

#+begin_src sql
  update accounts set amount=inc_slow(amount)
  where amount>100.00;
#+end_src

pgrowlocks 扩展显示，第一个操作符已经更新了第一行（0,1），而第二个操作符已经更新了最后一行（0,3）：

#+begin_src sql
  select locked_row, locker, modes from pgrowlocks('accounts');
#+end_src

又过了一秒钟。第一个操作更新了第二行，另一个操作也想更新，但不允许。

#+begin_src sql
  select locked_row, locker, modes from pgrowlocks('accounts');
#+end_src

现在，第一个操作想更新最后一条表记录，但它已被第二个操作锁定。死锁发生了。

其中一个事务被中止：

[[./images/GaEljH.png]]

而另一个则完成了它的执行：

虽然这种情况看似不可能发生，但在高负载系统中执行批量行更新时确实会发生。

* 杂项锁

** 非对象锁

要锁定不被视为关系的资源，PostgreSQL 使用对象类型的重量级锁。你几乎可以锁定存储在系统目录中的任何东西：表空间、
订阅、模式、角色、策略、枚举数据类型等。

让我们开始一个创建表的事务：

#+begin_src sql
  begin;
  create table example(n integer);
#+end_src

现在看看 pg_locks 表中的非相关锁：

#+begin_src sql
  select database,
  (
    select datname from pg_database where oid=database 
  ) as dbname,
  classid,
  (
    select relname from pg_class where oid=classid 
  ) as classname
  objid,
  mode,
  granted
  from pg_locks
  where locktype='object'
    and pid=pg_backend_pid() \gx
#+end_src

在这里，锁定的资源由三个值定义：

database - 包含被锁定对象的数据库的 oid（如果该对象是整个群集共有的，则为零）。

classid - pg_class 中列出的 oid，该 oid 与定义资源类型的系统目录表名称相对应

objid - 由 classid 引用的系统目录表中列出的 oid

database值指向 internals 数据库；它是当前会话所连接的数据库。classid 列指向 pg_namespace 表，该表列出了模
式。

现在我们可以破译 objid 了：

#+begin_src sql
  select nspname from pg_namespace where oid=2200;
#+end_src

因此，PostgreSQL 锁定了public模式，以确保没有人能在事务仍在运行时删除它。

同样，删除对象需要对对象本身及其依赖的所有资源加独占锁。

#+begin_src sql
  rollback;
#+end_src

** 表扩展锁

随着关系中元组数的增加，PostgreSQL 会尽可能在已有页面的空闲空间中插入新的元组。但很显然，在某些时候，它不得不增
加新的页面，也就是扩展关系。就物理布局而言，新的页面会被添加到相应文件的末尾（这反过来又会导致创建一个新的文件）。

对于一次只能由一个进程添加新页面的情况，该操作受扩展类型的特殊重量级锁保护。索引回收也使用这种锁来禁止在索引扫描过
程中添加新页面。

表扩展锁的行为与我们目前看到的有些不同：

+ 扩展创建后，它们会立即释放，无需等待事务完成。
+ 它们不会造成死锁，因此不包括在等待图中。

  不过，如果扩展关系的过程耗时超过 deadlock_timeout，则仍会执行死锁检查。这种情况并不常见，但如果大量进程同时
  执行多个插入操作，就会出现这种情况。在这种情况下，死锁检查会被调用多次，实际上会导致系统正常运行瘫痪。

  为了将这种风险降到最低，堆文件会一次扩展若干页（与等待锁的进程数量成比例，但每次操作不超过 512 页）。 B 树索引
  文件是个例外，它每次只扩展一页。


** 页锁

页面类型的页面级重量级锁定仅适用于 GIN 索引，且仅在以下情况下使用。

GIN 索引可以加快对复合值元素（如文本文档中的单词）的搜索。它们可以被粗略地描述为 B 树，存储单独的单词而不是整个文
档。当添加新文档时，索引必须彻底更新，以包含该文档中出现的每个单词。

为了提高性能，GIN 索引允许延迟插入，这由 fastupdate 存储参数控制。新词首先会被快速添加到一个无序的待定列表中，
一段时间后，所有累积的词条都会被移入主索引结构中。由于不同的文档很可能包含重复的词，因此这种方法被证明是相当经济有
效的。

为避免多个进程同时传输字，索引元页以独占模式锁定，直到所有字从待处理列表移到主索引。这种锁定不会影响索引的正常使用。

与关系扩展锁一样，页面锁也会在任务完成后立即释放，无需等待事务结束，因此不会造成死锁。

** 咨询锁

与其他重量级锁（如关系锁）不同，咨询锁不会自动获取：它们由应用程序开发人员控制。如果应用程序需要专门的锁定逻辑来实
现某些特定目的，使用这些锁就很方便。

假设我们需要锁定一个与任何数据库对象都不对应的资源（我们可以使用 SELECT FOR 或 LOCK TABLE 命令锁定该资源）。
在这种情况下，需要为资源分配一个数字 ID。如果资源有一个唯一的名称，最简单的方法就是为该名称生成一个哈希代码：

#+begin_src sql
  select hashtext('resource1');
#+end_src

PostgreSQL 提供了一整套管理咨询锁的函数。这些函数的名称以 pg_advisory 前缀开头，可以包含以下暗示函数用途的词语：

*lock* － 获取一个锁
*try*  － 获取一个锁没有等待
*unlock* - 释放一个锁
*share* － 使用共享锁定模式（默认情况下使用排他模式）
*xact* - 获取并保持锁直到事务结束（默认情况下，锁保持到会话结束）

让我们获取一个独占锁，直到会话结束：

#+begin_src sql
  begin;
  select pg_advisory_lock(hashtext('resource1'));
  select locktype, objid, mode granted
  from pg_locks where locktype='advisory' and pid=pg_backend_pid();
#+end_src

要使咨询锁真正发挥作用，其他进程在访问资源时也必须遵守既定顺序；应用程序必须保证这一点。

即使在事务完成后，获得的锁也会被保留：

#+begin_src sql
  commit;
  select locktype, objid, mode, granted
  from pg_locks where locktype='advisory' and pid=pg_backend_pid();
#+end_src

一旦对资源的操作结束，就必须明确释放锁：

#+begin_src sql
  select pg_advisory_unlock(hashtext('resource1'));
#+end_src

** 谓词锁

当时面临的问题是，锁定所有要读取和更新的记录仍然不能保证完全隔离。事实上，如果有满足过滤条件的新记录插入表中，它们
就会变成幽灵。

因此，建议锁定条件（谓词）而不是记录。如果运行一个带有 a > 10 谓词的查询，锁定该谓词后，如果新行满足该条件，则不
允许向表中添加新行，因此可以避免出现幻读。麻烦的是，如果出现不同谓词的查询，例如 a < 20，就必须找出这些谓词是否重
叠。从理论上讲，这个问题在算法上是无法解决的；在实践中，只有非常简单的一类谓词（如本例）才能解决这个问题。

在 PostgreSQL 中，可序列化隔离级别是以另一种方式实现的：它使用可序列化快照隔离（SSI）协议。谓词锁（predicate
lock）一词依然存在，但其含义已发生了根本变化。事实上，这种 "锁 "并不锁定任何东西：它们被用来跟踪不同事务之间的数
据依赖关系。

事实证明，除了写偏移和只读事务异常外，可重复读取级别的快照隔离不允许出现任何异常。这两种异常会导致数据依赖图中出现
某些模式，而发现这些模式的成本相对较低。

问题在于，我们必须区分两类依赖关系：

+ 第一个事务读取的记录后来被第二个事务更新（RW 依赖关系）。
+ 第一个事务修改了一条记录，随后第二个事务读取了这条记录（WR 依赖性）。

WR 依赖关系可以使用常规锁来检测，但 RW 依赖关系必须通过谓词锁来跟踪。在 Serializable 隔离级别上，这种跟踪会自动
开启，这也正是为什么所有事务（或至少所有相互关联的事务）都必须使用这个级别的原因。如果任何事务运行在不同的级别，它
将不会设置（或检查）谓词锁，因此可串行级别将降级为可重复读取。

我想再次强调，尽管名字叫谓词锁，但它并不锁定任何东西。相反，当一个事务要提交时，会检查它是否有 "危险 "的依赖关系，
如果 PostgreSQL 怀疑有异常，就会中止该事务。

让我们创建一个带索引的表，该索引将跨越多个页面（可以通过使用较低的填充因子值来实现）：

#+begin_src sql
  create table pred(n numeric, s text);
  insert into pred(n) select n from generate_series(1, 10000) n;
  create index on pred(n) with (fillfactor=10);
  analyze pred;
#+end_src

如果查询执行的是顺序扫描，则会在整个表上获取一个谓词锁（即使某些记录不满足所提供的过滤条件）。

#+begin_src sql
  select pg_backend_pid();
  begin isolation level serializable;
  explain (analyze, costs off, timing off, summary off)
  select * from pred where n>100;
#+end_src

虽然谓词锁有自己的基础结构，但 pg_locks 视图会将它们与重量级锁一起显示。所有谓词锁都是以 SIRead 模式获取的，
SIRead 代表可序列化隔离读取（Serializable Isolation Read）：

#+begin_src sql
  select relation::regclass, locktype, page, tuple
  from pg_locks where mode='SIReadLock' and pid=34753
  order by 1, 2, 3, 4;
#+end_src

#+begin_src sql
  rollback
#+end_src

请注意，谓词锁的保持时间可能比事务持续时间更长，因为它们用于跟踪事务之间的依赖关系。但无论如何，它们都会被自动管理。

如果查询执行的是索引扫描，情况就会有所改善。对于 B 树索引，只需在已读取的堆元组和已扫描的索引叶页上设置谓词锁即可。
它将 "锁定 "已读取的整个范围，而不仅仅是精确值。

#+begin_src sql
  begin isolation level serializable;
  explain (analyze, costs off, timing off, summary off)
  select * from pred where n between 1000 and 1001;
#+end_src

#+begin_src sql
  select relation::regclass, locktype, page, tuple
  from pg_locks where mode='SIReadLock' and pid=34753
  order by 1, 2, 3, 4;
#+end_src

与已扫描的元组相对应的叶页数量可能会发生变化：例如，当表中插入新行时，索引页可能会被拆分。不过，PostgreSQL 会考虑
到这一点，并锁定新出现的页面：

#+begin_src sql
  insert into pred
  select 1000+(n/1000.0) from generate_series(1, 999) n;
  select relation::regclass, locktype, page, tuple
  from pg_locks where mode='SIReadLock' and pid=34753
  order by 1, 2, 3, 4;
#+end_src

每个读取的元组都会被单独锁定，这样的元组可能会有很多。谓词锁使用服务器启动时分配的自己的池。谓词锁的总数受
max_pred_locks_per_transaction 值乘以 max_connections 值的限制（尽管参数名称相同，但谓词锁并不按独立事务
计算）。

在这里，我们会遇到与行级锁相同的问题，但解决方法不同：应用锁升级。

一旦与一个页面相关的元组锁数量超过 max_pred_locks_per_page 参数的值，它们就会被单个页级锁取代。

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from pred where n between 1000 and 1002;
#+end_src

我们现在有了一个页面类型的锁，而不是三个元组类型的锁：

#+begin_src sql
  select relation::regclass, locktype, page, tuple
  from pg_locks where mode='SIReadLock' and pid=34753
  order by 1, 2, 3, 4;
#+end_src

#+begin_src sql
  rollback;
#+end_src

页面级锁的升级遵循同样的原则。如果特定关系的此类锁的数量超过了 max_pred_locks_per_relation 值，它们就会被单
个表级锁取代。(如果该参数设置为负值，阈值的计算方法是 max_pred_locks_per_transaction 除以
max_pred_locks_per_relation 的绝对值；因此，默认阈值为 32）。

锁升级肯定会导致多个假阳性序列化错误，从而对系统吞吐量造成负面影响。因此，你必须在性能和将可用 RAM 用于锁之间找到
一个适当的平衡点。

谓词锁支持以下索引类型：

+ B树
+ hash索引，GiST和GIN索引

如果执行了索引扫描，但索引不支持谓词锁，那么整个索引都将被锁定。在这种情况下，预计无故中止的事务数量也会增加。

为了在可串行化级别上更有效地运行，使用 READ ONLY 子句显式地声明只读事务是有意义的。如果锁管理器认为只读事务不会与
其他事务冲突，它就可以释放已设置的谓词锁，并避免获取新锁。如果该事务也被声明为 "可取消"（DEFERRABLE），那么也就避
免了只读事务的异常情况。

* 内存结构锁

** 自旋锁

为了保护共享内存中的数据结构，PostgreSQL 使用了几种较轻、较便宜的锁，而不是常规的重量级锁。

最简单的锁是自旋锁。它们的获取时间间隔通常很短（不超过几个 CPU 周期），以保护特定内存单元免受并发更新的影响。

自旋锁基于 CPU 原子指令，如比较和交换。 它们只支持排他性锁定模式。如果所需资源已被锁定，进程就会忙于等待，重复执行
命令（在循环中 "旋转"，因此得名）。如果在指定的时间间隔内无法获得锁定，进程会暂停一段时间，然后开始另一个循环。

如果发生冲突的概率估计很低，那么在一次不成功的尝试后，很可能在几条指令内就能获得锁，这种策略是合理的。

Spinlocks 既没有死锁检测功能，也没有仪表化功能。从实用的角度来看，我们只需知道它们的存在；正确实现它们的全部责任
在于 PostgreSQL 开发人员。

** 轻量级锁

其次是所谓的轻量级锁（或 lwlocks）。轻量级锁是根据处理数据结构（例如哈希表或指针列表）所需的时间而获取的，通常时
间较短；但当用于保护 I/O 操作时，时间可能会更长。

轻量级锁支持两种模式：独占（用于修改数据）和共享（用于只读操作）。轻量级锁不存在队列：如果多个进程都在等待一个锁，
那么其中一个进程将或多或少以随机方式访问资源。在有多个并发进程的高负载系统中，这可能会导致一些令人不快的后果。

PostgreSQL 不提供死锁检查；我们必须相信 PostgreSQL 开发人员会正确实现轻量级锁。不过，这些锁都有仪器，所以与自
旋锁不同，它们是可以被观察到的。

** 示例

为了了解如何以及在何处使用自旋锁和轻量级锁，让我们来看看两个共享内存结构：缓冲缓存和 WAL 缓冲。我将只列举其中一些
锁；全貌过于复杂，可能只有 PostgreSQL 核心开发人员才会感兴趣。

要访问用于在高速缓存中定位特定缓冲区的哈希表，进程必须获取 BufferMapping 轻量级锁，读取时采用共享模式，如果要进
行任何修改，则采用独占模式。

要访问用于在高速缓存中定位特定缓冲区的哈希表，进程必须获取 BufferMapping 轻量级锁，读取时采用共享模式，如果要进
行任何修改，则采用独占模式。

[[./images/xDEM9Y.png]]


哈希表的访问频率非常高，因此这个锁经常成为瓶颈。为了最大限度地提高细粒度，它被设计成由 128 个独立的轻量级锁组成，
每个锁保护哈希表的一个单独部分。

#+begin_comment
 早在 2006 年，PostgreSQL 8.2 版本就将哈希表锁转换成了 16 个锁；十年后，当 9.5 版本发布时，锁的大小增加到了
 128 个，但对于现代多核系统来说，这可能仍然不够。
#+end_comment

要访问缓冲区头，进程需要获取一个缓冲区头自旋锁（名称是任意的，因为自旋锁没有用户可见的名称）。某些操作（如递增使用
计数器）不需要显式锁，可以使用 CPU 原子指令执行。

要读取缓冲区中的某一页，进程会在缓冲区的头部获取 BufferContent 锁。通常，只有在读取元组指针时才会使用该锁；之后，
缓冲区钉住提供的保护就足够了。如果需要修改缓冲区内容，则必须在独占模式下获取 BufferContent 锁。

从磁盘读取缓冲区（或将缓冲区写入磁盘）时，PostgreSQL 也会在缓冲区头中获取 BufferIO 锁；它实际上是一个用作锁的
属性，而不是实际的锁。它向其他请求访问该页面的进程发出信号，告诉它们必须等待，直到 I/O 操作完成。

指向空闲缓冲区的指针和驱逐机制的时钟指针由一个通用缓冲区策略自旋锁保护。

WAL缓冲区

[[./images/z19B5z.png]]

WAL 缓存也使用哈希表将页面映射到缓冲区。与缓冲区缓存哈希表不同的是，它受单个 WALBufMapping 轻量级锁保护，因为
WAL 缓存较小（通常只占缓冲区缓存大小的 $ \frac{1}{32} $），而且缓冲区访问更有序。

将 WAL 页写入磁盘受 WALWrite 轻量级锁保护，该锁可确保每次只有一个进程执行此操作。

要创建 WAL 条目，进程首先要在 WAL 页面内预留一些空间，然后将数据填入其中。空间保留是严格有序的；进程必须获得一个
插入位置自旋锁，以保护插入指针。  但是，一旦空间被保留，它就可以被多个并发进程填满。为此，每个进程都必须获取构成
WALInsert 部分的八个轻量级锁中的任意一个。

** 监听等待

毫无疑问，锁对于 PostgreSQL 的正确操作是不可或缺的，但它也可能导致不必要的等待。跟踪这些等待以了解其起因是非常有
用的。

查看长期锁的最简单方法是打开 log_lock_waits 参数；它可以记录所有导致事务等待时间超过 deadlock_timeout 的锁。
这些数据会在死锁检查完成后显示，因此该参数也叫死锁超时。

不过，pg_stat_activity 视图能提供更有用、更完整的信息。每当一个进程--无论是系统进程还是后台进程--因为等待某些东
西而无法继续执行任务时，这种等待就会反映在 wait_event_type 和 wait_event 字段中，这两个字段分别显示等待的类型
和名称。

所有等待可分为以下几类。

各个锁的等待者是一个庞大的群体

*Lock* 重量级锁
*LWLock* 轻量级锁
*BufferPin* 钉住页面

但进程也可以等待其他事件的发生：

*IO* I/O，当需要读取或写入某些数据时
*Client* 客户端发送的数据（psql 大部分时间都处于这种状态）
*IPC* 另一进程发送的数据
*Extension* 插件注册的特定事件

有时，进程根本不执行任何有用的工作。这类等待通常是 "正常 "的，也就是说，它们并不表示任何问题。这组等待包括以下等待：

*Activity* 主循环的后端进程
*Timeout* 定时器

每种等待类型的锁都会根据等待名称进一步分类。例如，轻量级锁的等待会获得锁的名称或相应的批次。

请注意，pg_stat_activity 视图只显示源代码中以适当方式处理的等待。除非等待的名称出现在该视图中，否则进程不处于任
何已知类型的等待状态。这样的时间应视为未计算时间；它并不一定意味着进程没有在等待任何东西--我们只是不知道此刻正在发
生什么。

#+begin_src sql
  select backend_type, wait_event_type as event_type, wait_event
  from pg_stat_activity;
#+end_src

在这里，当视图采样时，所有后台进程都处于空闲状态，而客户端后端正忙着执行查询，没有任何等待。

** 采样

遗憾的是，pg_stat_activity 视图只显示当前的等待信息，统计数据不会累积。收集长期等待数据的唯一方法是定期对视图进
行采样。

我们必须考虑到采样的随机性。与采样间隔相比，等待时间越短，检测到等待时间的几率就越低。因此，较长的采样间隔需要更多
的采样来反映实际情况（但随着采样率的提高，开销也会增加）。出于同样的原因，采样对于分析短期会话几乎毫无用处。

PostgreSQL 没有提供用于采样的内置工具；不过，我们仍然可以使用 pg_wait_sampling 扩展进行尝试。为此，我们必须在
shared_preload_libraries 参数中指定其库，然后重启服务器：

#+begin_src sql
  alter system set shared_preload_libraries = 'pg_wait_sampling';
  pg_ctl restart -l /home/postgres/logfile 
#+end_src

现在，让我们将扩展安装到数据库中：

#+begin_src sql
  create extension pg_wait_sampling;
#+end_src

该扩展可以显示保存在环形缓冲区中的等待历史记录。不过，更有趣的是获取等待概况--整个会话期间的累积统计数据。

例如，我们来看看基准测试过程中的等待时间。我们必须启动 pgbench 实用程序，并确定其运行时的进程 ID：

#+begin_src sql
  /usr/local/pgsql/bin/pgbench -T 60 internals
  select pid from pg_stat_activity
  where application_name='pgbench';
#+end_src

测试完成后，等待配置文件将如下所示：

#+begin_src sql
  select pid, event_type, event, count
  from pg_wait_sampling_profile where pid=36367
  order by count desc limit 4;
#+end_src

默认情况下（由 pg_wait_sampling.profile_period 参数设置），每秒采样 100 次。因此，要估算以秒为单位的
等待时长，必须用计数值除以 100。

在这种特殊情况下，大部分等待都与将 WAL 条目刷新到磁盘有关。它很好地说明了未计算的等待时间：WALSync 事件直到
PostgreSQL 12 才被检测到；对于较低版本，虽然等待本身仍然存在，但等待配置文件不会包含第一行。

如果我们人为地将文件系统的每个 I/O 操作的速度减慢到 0.1 秒（我为此使用了 slowfs），配置文件就会变成这样：

#+begin_src sql
  /usr/local/pgsql/bin/pgbench -T 60 internals
  select pid from pg_stat_activity
  where application_name='pgbench';
#+end_src

#+begin_src sql
  select pid, event_type, event, count
  from pg_wait_sampling_profile where pid=36747
  order by count desc limit 4;
#+end_src

现在最慢的是 I/O 操作--主要是那些在同步模式下将 WAL 文件写入磁盘的操作。由于 WAL 的写入受到 WALWrite 轻量级锁
的保护，因此配置文件中也会出现相应的行。

显然，在上一个示例中也获得了同样的锁，但由于等待时间短于采样间隔，因此要么采样次数很少，要么根本没有进入配置文件。这
再次说明，要分析短等待时间，必须对其进行长时间采样。


* 查询执行阶段

** 示例数据库
本书前几部分的示例基于只有少量行的简单表。本部分和后续部分涉及的是查询执行，在这方面要求更高：我们需要行数更多的相关
表。我没有为每个示例创建一个新的数据集，而是使用了一个现有的演示数据库，该数据库展示了俄罗斯的航空客运交通情况。它有
多个版本；我们将使用 2017 年 8 月 15 日创建的较大版本。要安装该版本，必须从压缩包中提取包含数据库副本的文件，并在
psql 中运行该文件。

在开发这个演示数据库时，我们努力使其模式足够简单，无需额外解释即可理解；同时，我们又希望它足够复杂，以便编写有意义
的查询。数据库中充满了真实的数据，这使得示例更加全面，使用起来也会很有趣。

在此，我将简要介绍主要的数据库对象；如果您想查看整个模式，可以参考脚注中的完整描述。

主要实体是预订（映射到预订表）。一个预订可以包括多个乘客，每个乘客都有一张单独的电子票（车票）。乘客并不是一个独立
的实体；在我们的实验中，我们将假设所有乘客都是唯一的。

每张机票包括一个或多个航段（映射到 ticket_flights 表）。在两种情况下，一张机票可以有多个航段：要么是往返机票，
要么是联程机票。虽然模式中没有相应的约束，但预订中的所有机票都被假定为具有相同的航班航段。

每个航班从一个机场飞往另一个机场。航班号相同的航班出发点和目的地相同，但出发日期不同。

航线视图以航班表为基础，显示不依赖于特定航班日期的航线信息。

办理值机手续时，每位旅客都会收到一张带有座位号的登机牌 (boarding_passes)。只有在机票中包含某个航班时，乘客才能
办理该航班的登机手续。航班座位组合必须是唯一的，因此不可能为同一个座位签发两张登机牌。

飞机上的座位（席位）数量及其在不同舱位之间的分布取决于执行飞行任务的飞机（机型）的具体型号。假设每种机型只能有一种客
舱配置。

有些表使用代理主键，有些则使用自然主键（其中有些是复合主键）。这只是为了演示，绝不是可以效仿的范例。

演示数据库可以看作是真实系统的转储：它包含过去某一特定时间的数据快照。要显示这个时间，可以调用 bookings.now() 函
数。在演示查询中使用该函数时，在现实生活中需要使用 now() 函数。

机场、城市和飞机型号的名称存储在 airports_data 表和 aircrafts_data 表中；它们以两种语言（英语和俄语）提供。在
构建本章示例时，我通常会查询实体关系图中显示的机场和飞机视图；这些视图会根据 bookings.lang 参数值选择输出语言。不
过，一些基础表的名称仍会出现在查询计划中。

[[./images/Gap5iC.png]]

** 简单查询协议
客户端-服务器协议的一个简单版本可以执行 SQL 查询：它向服务器发送查询文本，并获得完整的执行结果（无论包含多少行）。

解析

首先，PostgreSQL 必须解析查询文本，以了解需要执行的内容。

词法和句法分析。词法分析器将查询文本分割成一组词素（如关键字、字符串字面量和数字字面量），而解析器则根据 SQL 语言语
法验证这组词素。 PostgreSQL 依赖标准的解析工具，即 Flex 和 Bison 工具。

解析后的查询以抽象语法树的形式反映在后端内存中。

例如，我们来看看下面的查询：

#+begin_src sql
  select schemaname, tablename
  from pg_tables
  where tableowner='postgres'
  order by tablename;
#+end_src

词法选择器会选出五个关键字、五个标识符、一个字符串字面意义和三个单字母词素（逗号、等号和分号）。解析器使用这些词素
构建解析树，下图是一棵非常简化的解析树。树节点旁边的标题说明了查询的相应部分：

[[./images/TLkU80.png]]

RTE 是 Range Table Entry（范围表输入）的缩写，这个缩写相当晦涩难懂。PostgreSQL 源代码使用范围表一词来指表、
子查询、连接结果，换句话说，指任何可由 SQL 操作符处理的记录集。

语义分析。语义分析的目的是确定数据库中是否包含该查询名称所指的任何表或其他对象，以及用户是否有权限访问这些对象。语义
分析所需的所有信息都存储在系统目录中

收到解析树后，语义分析器会进行进一步重组，包括添加对特定数据库对象、数据类型和其他信息的引用。

如果启用 debug_print_parse 参数，就可以在服务器日志中查看完整的解析树，但这并没有什么实际意义。

变换

在下一阶段，可以对查询进行转换（重写）。

PostgreSQL 核心使用转换来实现几个目的。其中之一就是将解析树中的视图名称替换为与该视图的基本查询相对应的子树。

使用转换的另一种情况是行级安全实施。

递归查询的 SEARCH 和 CYCLE 子句也会在此阶段进行转换。

在上面的示例中，pg_tables 是一个视图；如果我们把它的定义放到查询文本中，就会如下所示：

#+begin_src sql
  select schemaname, tablename
  from (
     -- pg_tables
     select n.nspname as schemaname,
     c.relname as tablename,
     pg_get_userbyid(c.relowner) as tableowner,
     ...
     from pg_class c
       left join pg_namespace n on n.oid=c.relnamespace
       left join pg_tablespace t on t.oid=c.reltablespace
     where c.relkind=any(array['r'::char, 'p'::char])
   )
   where tableowner='postgres'
   order by tablename;
  
#+end_src

不过，服务器不会处理查询的文本表示；所有操作都是在解析树上执行的。图中显示的是已转换树的缩小版本（如果启用
debug_print_rewitten 参数，可以在服务器日志中查看完整版本）。

解析树反映了查询的语法结构，但并不说明执行操作的顺序。

PostgreSQL 还支持自定义转换，用户可通过重写规则系统实现自定义转换。

[[./images/7tfzd1.png]]

规则系统支持被宣布为 Postgres 开发的主要目标之一；在规则首次实施时，它还是一个学术项目，但从那时起，它们已经被重
新设计了多次。规则系统是一个非常强大的机制，但却很难理解和调试。甚至有人提议从 PostgreSQL 中完全删除规则，但这一
想法并未得到一致支持。在大多数情况下，使用触发器而不是规则更安全、更简单。

规划器

SQL 是一种声明式语言：查询指定要获取哪些数据，但不指定如何获取。

任何查询都有多种执行路径。解析树中显示的每个操作都可以通过多种方式完成：例如，可以通过读取整个表（并过滤掉冗余）或
通过索引扫描查找所需记录来检索结果。数据集总是成对连接的，因此在连接顺序上有大量不同的选择。此外，还有各种连接算法：
例如，执行器可以扫描第一个数据集的行，然后在另一个数据集中搜索匹配的行，或者先对两个数据集进行排序，然后合并在一起。
对于每种算法，我们都能找到其性能优于其他算法的使用案例。


最优计划和非最优计划的执行时间可能相差几个数量级，因此优化解析查询的规划器是系统中最复杂的组件之一。

计划树。执行计划也用树形表示，但其节点处理的是数据上的物理操作，而不是逻辑操作。

如果想查看完整的计划树，可以启用 debug_print_plan 参数将其转储到服务器日志中。但实际上，查看 EXPLAIN 命令显示
的计划文本就足够了。

现在，让我们注意以下两点：

+ 计划树中的三个查询表只包含两个：规划器发现其中一个表不需要用于检索结果，因此将其从计划树中删除。
+ 在树的每个节点上，规划器都会提供估计成本和预计要处理的行数。

#+begin_src sql :engine postgresql
  explain select schemaname, tablename
  from pg_tables
  where tableowner='postgres'
  order by tablename;
#+end_src

查询计划中显示的 Seq Scan 节点对应于读表，而 Nested Loop 节点表示连接操作。

[[./images/qlf7ma.png]]


计划搜索。PostgreSQL 使用基于成本的优化器；它会查看潜在的计划，并估算执行这些计划所需的资源（如 I/O 操作或 CPU
周期）。这一估算值被归一化为一个数值，称为计划成本。在所有考虑过的计划中，选择成本最低的一个。

问题在于，潜在可用计划的数量会随着连接表的数量呈指数增长，因此不可能考虑所有计划，即使是相对简单的查询也是如此。通
常使用动态规划算法结合一些启发式方法来缩小搜索范围。这样，规划器就能在可接受的时间内为表数较多的查询找到数学上精确
的解决方案。

#+begin_comment
  精确的解决方案并不能保证所选计划确实是最优的，因为规划者使用的是简化的数学模型，而且可能缺乏可靠的输入数据。
#+end_comment


管理连接顺序。查询的结构可以在一定程度上限制搜索范围（有可能错过最佳计划）。

+ 普通表表达式和主查询可以分开优化；为保证这种行为，可以指定 MATERIALIZED 子句。
+ 在非 SQL 函数中运行的查询总是单独进行优化。(SQL 函数有时可以内联到主查询中。）
+ 如果设置了 join_collapse_limit 参数并在查询中使用了显式 JOIN 子句，那么某些连接的顺序将由查询语法结构来定义
  from_collapse_limit 参数对子查询也有同样的作用。


后一点可能需要解释一下。让我们看看没有为 FROM 子句中列出的表指定任何显式连接的查询：

#+begin_src sql
  select ...
  from a, b, c, d, e
  where ...
#+end_src

在这里，规划器必须考虑所有可能的连接对。查询由解析树的以下部分表示（如图所示）：

[[./images/FyoxVR.png]]

在下一个示例中，连接具有由 JOIN 子句定义的特定结构：

#+begin_src sql
  select ...
  from a, b join c on ..., d, e
  where ...
#+end_src

解析树反映了这种结构：

[[./images/EluhJc.png]]

规划器通常会将连接树扁平化，使其看起来像第一个示例中的树。该算法会递归遍历连接树，并将每个 JOINEXPR 节点替换为其
元素的扁平列表。

但是，只有当生成的扁平列表中的元素数量不超过 join_collapse_limit 时，才会执行这种折叠操作。在这种特殊情况下，
如果 join_collapse_limit 值小于 5，JOINEXPR 节点就不会折叠。

对于规划器来说，这意味着以下几点：

+ 表 B 必须与表 C 连接（反之亦然，C 必须与 B 连接；表对中的连接顺序不受限制）。
+ A、D、E 以及连接 B 和 C 的结果可以任意顺序连接。

如果 join_collapse_limit 参数设置为 1，显式 JOIN 子句定义的顺序将得到保留。

至于全外连接操作数，无论 join_collapse_limit 参数的值如何，它们都不会折叠。

from_collapse_limit 参数以类似的方式控制子查询的扁平化。虽然子查询看起来并不像 JOIN 子句，但其相似性在解析树层
次上却很明显。

下面是一个查询示例：

#+begin_src sql
  select ...
  from a,
  ( select ... from b, c where ...) bc, d, e
  where ...
#+end_src

相应的连接树如下所示。唯一不同的是，这棵树包含的是 FROMEXPR 节点，而不是 JOINEXPR（参数名称由此而来）。

[[./images/xJvniE.png]]

遗传查询优化。一旦扁平化，树的一个层次可能包含过多元素--无论是表还是连接结果，都必须分别进行优化。规划时间与需要连
接的数据集数量成指数关系，因此其增长可能超出所有合理的限制。

如果启用了 geqo 参数，且某一级元素数量超过了 geqo_threshold 值，规划器将使用遗传算法优化查询。这种算法比动态编
程算法快得多，但不能保证找到的计划是最优的。因此，经验法则是通过减少需要优化的元素数量来避免使用遗传算法。

遗传算法有几个可配置的参数，但我不打算在这里介绍。

选择最佳计划。计划是否最优取决于特定客户将如何使用查询结果。如果客户需要一次性获得全部结果（例如，创建一份报告），
则计划应优化所有行的检索。但如果优先级是尽快返回第一行（例如，在屏幕上显示），最佳计划可能完全不同。

要做出这种选择，PostgreSQL 会计算成本的两个组成部分：

#+begin_src sql
  explain
  select schemaname, tablename
  from pg_tables
  where tableowner='postgres'
  order by tablename;
#+end_src

第一部分（启动成本）是您为准备节点执行所支付的费用，而第二部分（总成本）则包括获取结果所产生的所有费用。

#+begin_comment
  有时人们会说，启动成本就是检索结果集第一行的成本，但这并不十分准确。
#+end_comment

为了选出首选计划，优化器会检查查询是否使用了游标（通过 SQL 中提供的 DECLARE 命令或在 PL/pgSQL 中明确声明）。如
果没有，则假定客户需要一次性得到全部结果，优化器会选择总成本最低的计划。

如果查询是使用游标执行的，所选计划必须只优化检索所有记录中的 cursor_tuple_fraction。更准确地说，PostgreSQL 会
选择以下表达式中值最小的计划：

#+begin_center
 startup cost+cursor_tuple_fraction(total cost - startup cost)
#+end_center

成本估算概要。要估算一个计划的总成本，我们必须对其所有节点进行成本估算。节点的成本取决于其类型（显然，读取堆数据的
成本与排序成本不同）和节点处理的数据量（数据量越大，成本通常越高）。虽然节点类型是已知的，但数据量只能根据输入集的
估计卡入度（节点作为输入的行数）和节点的选择性（输出中剩余行的比例）来预测。这些计算依赖于收集到的统计数据，如表格
大小和表格列中的数据分布。

因此，所进行的优化取决于自动真空收集和更新的统计数据的正确性。

如果对每个节点的Cardinality估计准确，计算出的成本就有可能充分反映实际成本。主要的规划缺陷通常源于对中心性和选
择性的不正确估计，其原因可能是统计数据不准确或过时、无法使用统计数据，或在较小程度上源于规划模型不完善。

Cardinality估算 要计算节点的卡性，规划器必须递归完成以下步骤：

1. 估算每个子节点的Cardinality，并评估节点将从它们那里接收的输入行数。
2. 估算节点的Selectivity，即输入行中能保留到输出的部分。

节点的Cardinality是这两个值的乘积。

#+begin_comment
  数字越小，选择性越高；反之亦然，数字越接近 1，选择性越低。这看似不合逻辑，但我们的想法是，选择性高的条件几乎会
  剔除所有行，而只剔除少数行的条件选择性低。
#+end_comment

首先，规划器会估算定义数据访问方法的叶节点的Cardinality。这些计算依赖于收集到的统计数据，例如表的总大小。

过滤条件的Selectivity取决于其类型。在最普通的情况下，它可以被假定为一个恒定值，不过规划器会尽量利用所有可用信
息来完善估算。一般来说，只要知道如何估算简单的过滤条件就足够了；如果条件包含逻辑运算，其选择性可通过以下公式计算：

#+begin_export latex
sel_{x and y} =sel_xsel_y
sel_{x or y}=1-(1-sel_x)(1-sel_y)=sel_x+sel_y-sel_xsel_y
#+end_export

遗憾的是，这些公式假设谓词 x 和 y 互不相关。对于相关的谓词，这样的估算将是不准确的。

为了估算连接的Cardinality ，规划器必须获取笛卡尔积（即两个数据集的Cardinality之积）的Cardinality，并估算
连接条件的选择性，这同样取决于条件类型。

其他节点（如排序或聚合）的 Cardinality 也是以类似方式估算的。

值得注意的是，对较低计划节点的Cardinality估计不正确会影响所有后续计算，导致总成本估计不准确和计划选择错误。更糟
糕的是，规划器没有关于连接结果的统计数据，只有关于表的统计数据。

成本估算。估算成本的过程也是递归的。要计算子树的成本，需要计算并汇总其所有子节点的成本，然后再加上父节点本身的成本。

要估算一个节点的成本，PostgreSQL 会将已估算出的节点Cardinality作为输入，应用该节点所执行操作的数学模型。对于
每个节点，都会计算启动成本和总成本。

有些操作没有先决条件，因此会立即开始执行；这些节点的启动成本为零。

相反，其他操作则需要等待一些初步操作完成。例如，排序节点通常需要等待来自其子节点的所有数据，然后才能继续执行自己的
任务。这类节点的启动成本通常高于零：即使上述节点（或客户端）只需要全部输出中的一行，也必须支付这一代价。

规划器进行的所有计算都只是估算，可能与实际执行时间无关。它们的唯一目的是在相同条件下对同一查询的不同计划进行比较。
在其他情况下，比较查询（尤其是不同查询）的成本毫无意义。例如，由于统计数据过时，成本可能被低估了；一旦统计数据被刷
新，计算出的数字可能会上升，但由于估算变得更加准确，服务器会选择更好的计划。

执行

现在必须执行查询优化过程中建立的计划。

执行器会在后端内存中打开一个门户，这是一个保存当前正在执行的查询状态的对象。该状态用一棵树来表示，它重复了计划树的
结构。该树的节点像流水线一样运行，相互请求和发送记录。

[[./images/YFSvIs.png]]


查询从根节点开始执行。根节点（在本例中代表 SORT 操作）从其子节点获取数据。收到所有行后，它会对其进行排序，并将其
传递给客户端。

有些节点（如图中所示的 NESTLOOP 节点）会连接从不同来源接收的数据集。这样的节点从两个子节点中提取数据，并在接收到
一对满足连接条件的记录后，立即将得到的记录向上传递（与排序不同，排序必须先得到所有记录）。此时，节点的执行将被中断，
直到其父节点请求下一条记录。如果只需要部分结果（例如，查询中有 LIMIT 子句），则不会执行全部操作。

树中的两个 SEQSCAN 叶节点负责表格扫描。当父节点向这些节点请求数据时，它们会从相应的表中获取后续行。

因此，有些节点不存储任何行，而是立即向上传递，但其他节点（如 SORT）则必须保存潜在的大量数据。为此，会在后端内存中
分配一个 work_mem 块；如果不够用，剩余的数据就会溢出到磁盘上的临时文件中。

一个计划可能有多个节点需要数据存储，因此 PostgreSQL 可能会分配多个内存块，每个内存块的大小为 work_mem。查询可使
用的总内存大小不受任何限制。

** 扩展查询协议

在使用简单查询协议时，每条命令（即使重复多次）都必须经过上述所有阶段：

1. 解析
2. 转换
3. 规划器
4. 执行器

然而，重复解析同一个查询毫无意义。重复解析仅常量不同的查询也没有多大意义--解析树结构仍然保持不变。

简单查询协议的另一个缺点是，无论查询结果包含多少行，客户端都会一次性收到全部结果。

一般来说，使用 SQL 命令可以克服这些限制。要解决第一个问题，可以在运行 EXECUTE 命令前准备查询；第二个问题可以通过
使用 DECLARE 创建游标并通过 FETCH 返回记录来解决。但在这种情况下，这些新创建对象的命名必须由客户端来处理，而服务
器则要承担解析额外命令的额外开销。

扩展的客户端-服务器协议提供了另一种解决方案，可以在协议本身的命令层对独立的操作员执行阶段进行精确控制。

准备工作

在准备阶段，查询会像往常一样被解析和转换，但生成的解析树会保存在后端内存中。

PostgreSQL 没有查询的全局缓存。这种架构的缺点显而易见：每个后端都必须解析所有传入的查询，即使同一个查询已经被另一
个后端解析过了。但也有一些好处。由于锁的存在，全局缓存很容易成为瓶颈。 一个客户端运行多个小而不同的查询（比如只有常
量变化的查询）会产生大量流量，并对整个实例的性能产生负面影响。在 PostgreSQL 中，查询是在本地解析的，因此不会影响
其他进程。

准备好的查询可以被参数化。下面是一个使用 SQL 命令的简单示例（虽然与协议级的准备不同，但最终效果是一样的）：

#+begin_src sql
  prepare plane(text) as
  select * from aircrafts where aircrafts_code=$1;
#+end_src

所有已命名的预处理语句都显示在 pg_prepared_statements 视图中：

#+begin_src sql
  select name, statement, parameter_types
  from pg_prepared_statments \gx
#+end_src

在这里找不到任何未命名的语句（使用扩展查询协议或 PL/pgSQL 的语句）。其他后端编写的语句也不会显示：因为无法访问其
他会话的内存。

参数绑定

在执行准备语句之前，必须绑定实际参数值。

#+begin_src sql
  execute plane('733');
#+end_src

在预处理语句中绑定参数，而不是将文字与查询字符串连接起来，其优点是绝对不可能发生 SQL 注入：绑定的参数值无法以任何
方式修改已构建的解析树。如果不使用预处理语句，要达到相同的安全级别，就必须仔细剔除从不可信来源接收的每个值。

规划和执行

在执行准备语句时，查询计划是根据实际参数值执行的，然后将计划传递给执行器。

不同的参数值可能意味着不同的最优计划，因此必须考虑到确切的参数值。例如，在查找价格昂贵的预订时，计划器会假设匹配的
行数不多，并使用索引扫描：

#+begin_src sql
  create index on bookings(total_amount);
  explain select * from bookings
  where total_amount > 1000000;
#+end_src

但如果所有预订都满足所提供的条件，就没有必要使用索引，因为必须扫描整个表：

#+begin_src sql
  explain select * from bookings where total_amount > 100;
#+end_src

在某些情况下，规划器可能会同时保留解析树和查询计划，以避免重复规划。这种计划不考虑参数值，因此称为通用计划（与基于
实际值的自定义计划相比）。服务器可以使用通用计划而不影响性能的一个明显例子是不带参数的查询。

参数化准备语句的前五次优化始终依赖于实际参数值；规划器根据这些值计算自定义计划的平均成本。从第六次执行开始，如果通
用计划的平均效率高于自定义计划（考虑到自定义计划每次都要重新创建），规划器将保留通用计划并继续使用，跳过优化阶段。

plane准备语句已经执行过一次。在接下来的三次执行之后，服务器仍然使用自定义计划--你可以从查询计划中的参数值看出这
一点：

#+begin_src sql
  execute plane('763');
  execute plane('773');
  explain execute plane('319');
#+end_src

执行第五次后，规划器切换到通用计划：通用计划与自定义计划没有区别，成本也相同，但后台可以一次生成，跳过优化阶段，从
而减少规划开销。现在，"explain"命令显示，参数是按位置而不是按值引用的：

我们不难想象，当最初的几个定制计划比通用计划更昂贵时，就会出现令人不快的情况；随后的计划本可以更有效率，但规划器根
本不会考虑这些计划。此外，它比较的是估算成本而不是实际成本，这也会导致计算错误。

不过，如果规划器出错，您可以覆盖自动决定，并通过相应设置自动计划缓存模式参数来选择通用计划或自定义计划：

#+begin_src sql
  set plan_cache_mode='force_custom_plan';
  explain execute plane('CN1');
#+end_src

其中，pg_prepared_statements 视图显示所选计划的统计数据：

#+begin_src sql
  select name, generic_plans, custom_plans
  from pg_prepared_statements;
#+end_src

取得成果

扩展查询协议允许分批而非一次性检索数据。SQL 游标具有几乎相同的效果（只是服务器需要做一些额外的工作，而且规划器会优
化获取第一个 cursor_tuple_fraction 行，而不是整个结果集）：

#+begin_src sql
  begin;
  declare cur cursor for
  select *
  from aircrafts
  order by aircraft_code;
  fetch 3 from cur;
  fetch 2 from cur;
  commit;
#+end_src

如果查询返回许多行，而客户端需要所有行，那么系统吞吐量在很大程度上取决于批量大小。批次中的记录越多，访问服务器和获取
响应所产生的通信开销就越少。但是，随着批量大小的增加，这些优势就变得不那么明显了：虽然逐条获取记录和批量获取 10 条
记录之间的差异可能很大，但如果比较 100 条和 1000 条记录的批量，差异就不那么明显了。

* 统计数据

** 基本的统计数据
基本的表相关数据存储在catalog目录的pg_class包含如下数据

+ 表中所有元组数(reltuples)
+ 表大小，以页为单位(relpages)
+ 在可见性中标记的页数量(relallvisible)


flights表的在pg_class中的数据
  
#+begin_src sql
  select reltuples, relpages, relallvisible
  from pg_class where relname='flights';
#+end_src

如果查询不附加任何过滤条件，则以 reltuples 值作为估计的Cardinality

#+begin_src sql
  explain select * from flights;
#+end_src

在手动和自动的表格分析过程中都会收集统计数据。此外，由于基本统计数据至关重要，因此在进行其他一些操作（VACCUM FULL
和 CLUSTER、CREATE INDEX 和 REINDEX）时也会计算这些数据，并在抽清理时进行完善。

为便于分析，将对 300×100 default_statistics_target 随机行进行采样。建立特定精度的统计数据所需的样本大小与分
析数据量的关系不大，因此不考虑表的大小。

取样行是从相同数量（300 × default_statistics_target）的随机页中抽取的。显然，如果表格本身较小，读取的页数可能
较少，被选中进行分析的行数也较少。

在大型表格中，统计数据收集并不包括所有行，因此估计值可能与实际值有偏差。这很正常：如果数据不断变化，统计数据无论如
何也不可能一直准确。通常一个数量级的精确度就足以选择一个合适的计划。

让我们创建一个禁用autovacuum的flights副本，以便控制自动分析的启动时间：

#+begin_src sql
  create table flights_copy(like flights)
  with (autovacuum_enable = false);
#+end_src

目前数据的表的统计

#+begin_src sql
  select reltuples, relpages, relallvisible
  from pg_class where relname='flights_copy';
#+end_src

reltuples = -1 的值用于区分尚未分析的表和没有任何行的真正空表。

在创建表格后，很可能会立即向表中插入一些行。因此，在不了解当前情况的情况下，规划器假设表包含 10 页：

#+begin_src sql
  explain select * from flights_copy;
#+end_src

行数是根据单行的大小估算的，在计划中显示为宽度。行宽通常是在分析过程中计算出的平均值，但由于尚未收集统计数据，这里
只是根据列数据类型进行近似估算。

现在，让我们从flights表中复制数据并进行分析：

#+begin_src sql
  insert into flights_copy select * from flights;
  analyze flights_copy;
#+end_src

收集的统计数据反映了实际行数（表的大小足够小，分析仪可以收集所有数据的统计数据）：

#+begin_src sql
  select reltuples, relpages, relallvisible
  from pg_class where relname='flights_copy';
#+end_src

relallvisible 值用于估算仅索引扫描的成本。该值由 VACUUM 更新：

#+begin_src sql
  vaccum flights_copy;
  select relallvisible from pg_class where relname='flights_copy';
#+end_src

现在，让我们在不更新统计信息的情况下将记录数增加一倍，并检查查询计划中的Cardinality估计值：

#+begin_src sql
  insert into flights_copy select * from flights;
  select count(*) from flights_copy;
  explain select * from flights_copy;
#+end_src

尽管 pg_class 数据已经过时，但估算结果仍然是准确的：

#+begin_src sql
  select reltuples, relpages
  from pg_class where relname='flights_copy';
#+end_src

由于文件大小比 relpages 增加了一倍，规划器会在假设数据密度不变的情况下调整估计的行数：

#+begin_src sql
  select reltuples *
  (pg_relation_size('flights_copy') / 8192) / relpages as tuples
  from pg_class where relname='flights_copy';
#+end_src

当然，这种调整不一定总能奏效（例如，如果我们删除一些行，估计结果将保持不变），但在某些情况下，它可以让规划器坚持到
重大变化触发下一次分析运行。

** NULL 值
虽然理论家们对 NULL 值嗤之以鼻，但它在关系数据库中仍然发挥着重要作用：它提供了一种方便的方法来反映一个未知或不存在
的值。

然而，特殊的价值需要特殊的处理方法。除了理论上的不一致性，我们还必须考虑多种实际挑战。常规的布尔逻辑被三值逻辑所取
代，因此 NOT IN 的表现出乎意料。不清楚 NULL 值应被视为大于还是小于常规值（因此在排序时使用了 NULLS FIRST 和
NULL LAST 子句）。聚合函数是否必须考虑 NULL 值，这一点也不太清楚。严格来说，NULL 值根本就不是值，因此规划器需要
额外的信息来处理它们。

除了在表级别收集最简单的基本统计信息外，分析器还收集关系中每一列的统计信息。这些数据存储在系统目录的 pg_statistic
表中，但也可以通过 pg_stats 视图访问，该视图以更方便的格式提供这些信息。

NULL值比例属于列级统计；在分析过程中计算得出，显示为 null_frac 属性。

例如，在搜索尚未起飞的航班时，我们可以依赖于其起飞时间未定义：

#+begin_src sql
  explain select * from flights where actual_departure is null;
#+end_src

为了估算结果，规划器会将总行数乘以 NULL 值的比例：

#+begin_src sql
  select round(reltuples * s.null_frac) as rows
  from pg_class
  join pg_stats s on s.tablename=relname
  where s.tablename='flights'
  and s.attname='actual_departure';
#+end_src

下面是实际行数：

#+begin_src sql
  select count(*) from flights where actual_departure is null;
#+end_src

** 不重复值
pg_stats 视图的 n_distinct 字段显示列中不同值的数量。

如果 n_distinct 为负数，其绝对值表示列中唯一值的比例，而不是实际的列数。例如，-1 表示所有列中的值都是唯一的，而
-3 则表示每个值平均出现在三行中。如果估计的唯一值数量超过总行数的 10%，分析器就会使用分数；在这种情况下，进一步的
数据更新不太可能改变这一比例。

[[./images/rWsuJI.png]]

如果预期数据分布均匀，则使用不同值的数量来代替。例如，在估算 "列 = 表达式 "条件的Cardinality数时，如果表达式
的确切值在规划阶段未知，规划器就会假设表达式可以以相同概率取任意列值：

#+begin_src sql
  explain select *
  from flights
  where depatrue_airport=(
  select airport_code from aiprots where city='Saint Petersburg'
  );
#+end_src

在这里，InitPlan 节点只执行一次，计算值将用于主计划。

#+begin_src sql
  select round(reltuples / s.n_distinct) as rows
  from pg_class
  join pg_stat s on s.tablename=relname
  where s.tablename='flights'
  and s.attname='departure_airport';
#+end_src

如果估计的不同值数量不正确（因为分析的行数有限），则可以在列级覆盖：

#+begin_src sql
  alter table ...
      alter column ...
      set (n_distinct = ...);
#+end_src

如果所有数据总是均匀分布，那么这些信息（加上最小值和最大值）就足够了。然而，对于非均匀分布（这在实践中更为常见），
这种估计是不准确的：

#+begin_src sql
  select min(cnt), round(avg(cnt)) avg, max(cnt)
  from (
  select depature_airport, count(*) cnt
  from flights
  group by depature_airport
  )t;
#+end_src

** most_common_vals值
如果数据分布不均匀，则会根据最常见值 (MVC) 及其频率的统计数据对估算进行微调。pg_stats 视图会在 most_common_vals
和 most_common_freqs 字段中分别显示这些数组。

以下是有关各类飞机的此类统计数据的示例：

[[./images/roYhLU.png]]

#+begin_src sql
  select most_common_vals as mcv,
  left(most_common_freqs::text, 60) || '...' as mcf
  from pg_stats
  where tablename='flights' and attname='aircraft_code' \gx
#+end_src

要估算 "列 = 值 "条件的选择性，只需在 most_common_vals 数组中找到该值，并从具有相同索引的 most_common_freqs
数组元素中提取其频率即可：

#+begin_src sql
  explain select * from flights where aircraft_code = '733';
#+end_src

#+begin_src sql
  select round(reltuples * s.most_common_freqs[
  array_position((s.most_common_vals::text::text[]), '733')
  ])
  from pg_class
  join pg_stat s on s.tablename=relname
  where s.tablename='flights'
  and s.attname='aircraft_code';
#+end_src

显然，这种估算将接近实际值：

#+begin_src sql
  select count(*) from flights where aircraft_code='733';
#+end_src

MCV 列表还用于估算不等式条件的选择性。例如，"列 < 值 "这样的条件要求分析器在 most_common_vals 中搜索所有小于目
标值的值，并求和 most_common_freqs 中列出的相应频率。

当独立值不多时，MCV 统计效果最佳。数组的最大大小由 default_statistics_target 参数定义，该参数还限制了为分析目
的而随机抽样的行数。

在某些情况下，可以增加默认参数值，从而扩大 MCV 列表并提高估算的准确性。您可以在列级别上这样做：

#+begin_src sql
  alter table ...
     alter column ...
     set statistics ...;
#+end_src

样本量也会增加，但仅限于指定的表格。

由于 MCV 数组存储的是实际值，因此可能会占用大量空间。为了控制 pg_statistic 的大小，避免给计划器增加无用功，大于
1 KB 的值将被排除在分析和统计之外。不过，由于这些大值很可能是唯一的，因此无论如何，它们都不可能进入
most_common_vals。

** 柱状图

如果差异值过多，无法存储在数组中，PostgreSQL 会使用直方图。在这种情况下，数值会分布在直方图的几个桶中。桶的数量也
受 default_statistics_target 参数的限制。

水桶宽度的选择方式是让每个水桶都能获得大致相同数量的数值（这一特性在图表中体现为大阴影矩形的面积相等）。包含在 MCV
列表中的值不计算在内。因此，每个水桶中数值的累积频率等于 $$ \frac{1}{number of buckets} $$

直方图以桶边界值数组的形式存储在 pg_stats 视图的 histogram_bounds 字段中：

#+begin_src sql
  select left(histogram_bounds::text, 60) || '...' as hist_bounds
  from pg_stats s
  where s.tablename='boarding_passes' and s.attname='seat_no';
#+end_src

结合 MCV 列表，直方图可用于估算大于和小于条件的选择性等操作。例如，我们来看看为后排签发的登机牌数量：

[[./images/HQf3Es.png]]

#+begin_src sql
  explain select * from boarding_passes where seat_no > '30B';
#+end_src

我有意选择了位于两个直方图桶边界上的座位号。

该条件的选择性将以 N 个桶的数量来估算，其中 N 是容纳满足条件的值（即位于指定值右侧的值）的桶的数量。还必须考虑到
MCV 不包括在直方图中。

顺便提一下，直方图中也不会出现 NULL 值，但 seat_no 列中无论如何也不会包含此类值：

#+begin_src sql
  select s.null_frac from pg_stats s
  where s.tablename='boarding_passes' and s.attname='seat_no';
#+end_src

首先，让我们找出满足条件的 MCV 分数：

#+begin_src sql
  select sum(s.most_common_freqs[
  array_position((s.most_common_vals::text::text[]), v)
  ])
  from pg_stats s, unnest(s.most_common_vals::text::[]) v
  where s.tablename='boarding_passes' and s.attname='seat_no'
  and v> '30B';
#+end_src

MCV 的总体份额（被柱状图忽略）为

#+begin_src sql
  select sum(s.most_common_freqs[
  array_position((s.most_common_vals::text::text[]), v)
  ])
  from pg_stats s, unnest(s.most_common_vals::text::text[]) v
  where s.tablename='boarding_passes' and s.attname='seat_no';
#+end_src

由于符合指定条件的值正好占 𝑁 个桶（可能有 100 个桶），我们可以得到以下估计值：

#+begin_src sql
  select round(reltuples *(
  0.21226657 -- MCV share
  +(1-0.67816657-0)*(51/100.0) -- histogram share
  ))
  from pg_class
  where relname='boarding_passes';
#+end_src

[[./images/RiqJUz.png]]

在非边界值的一般情况下，规划器采用线性插值，以考虑到包含目标值的桶的部分。

这是后排座椅的实际数量：

#+begin_src sql
  select count(*) from boarding_passes where seat_no>'30B';
#+end_src

随着 default_statistics_target 值的增加，估算精度可能会提高，但正如我们的示例所示，即使列中包含许多唯一值，直
方图与 MCV 列表相结合通常也能得到很好的结果：

#+begin_src sql
  select n_distinct from pg_stats
  where tablename='boarding_passes' and attname='seat_no';
#+end_src

只有当提高估算精度能带来更好的规划时，提高估算精度才有意义。不假思索地增加 default_statistics_target 值可能会
减慢规划和分析速度，却不会带来任何好处。也就是说，降低该参数值（降为零）可能会导致错误的计划选择，尽管这样做确实会
加快规划和分析速度。这种节省通常是不合理的。

** 非标量数据类型的统计数据

对于非标量数据类型，PostgreSQL 不仅可以收集值分布的统计数据，还可以收集用于构建这些值的元素分布的统计数据。当你查
询不符合第一正则表达式的列时，它可以提高规划的准确性。

+ most_common_elems 和 most_common_elem_freqs 数组显示最常见的元素列表及其使用频率。
  收集的这些统计数据将用于估算数组和 tsvector 数据类型操作的选择性。
+ elem_count_histogram 数组显示数值中不同元素数量的直方图。
  收集的这些数据仅用于估算阵列操作的选择性。
+ 对于范围类型，PostgreSQL 会为范围长度和范围的上下限建立分布直方图。这些直方图用于估计对这些类型进行各种操作的选
  择性，但 pg_stats 视图不会显示它们。

  还为多范围数据类型收集了类似的统计数据。


** 平均字段宽度

pg_stats 视图的 avg_width 字段显示了存储在列中的值的平均大小。当然，对于整数或 char(3) 等类型，这个大小总是相
同的，但对于长度可变的数据类型（如文本），每一列的大小可能会有很大差异：

#+begin_src sql
  select attname, avg_width from pg_stats
  where (tablename, attname) in (values
  ('tickets', 'passenger_name'), ('ticket_flights', 'fare_conditions')
  );
#+end_src

该统计量用于估算排序或散列等操作所需的内存量。

** 相关性

pg_stats 视图的相关性字段显示数据的物理顺序与比较操作定义的逻辑顺序之间的相关性。如果数值严格按照升序存储，其相关
性将接近 1；如果按照降序排列，其相关性将接近-1。磁盘上的数据分布越混乱，相关性就越接近零。

#+begin_src sql
  select attname, correlation
  from pg_stats where tablename='airports_data'
  order by abs(correlation) desc;
#+end_src

请注意，坐标列不收集此统计量：点类型未定义小于和大于运算符。

相关性用于估算索引扫描的成本。

** 表达式统计

只有当比较操作的左侧或右侧部分指向列本身，且不包含任何表达式时，才能使用列级统计。例如，规划器无法预测计算列的函数
会如何影响统计量，因此对于 "函数调用 = 常量 "这样的条件，选择性总是估计为 0.5%。

#+begin_src sql
  eplain select * from flights
  where extract(
  month from schedule_depature at time zone 'Europe/Moscow'
  )=1;
#+end_src

规划者对函数的语义一无所知，即使是标准函数也是如此。我们的常识表明，1 月份执行的航班约占航班总数的
$$ \frac{1}{12} $$，比预测值高出一个数量级。

为了改进估计，我们必须收集表达式统计数据，而不是依赖列级统计数据。有两种方法可以做到这一点。

扩展表达式统计

第一个选项是使用扩展表达式统计。默认情况下不会收集此类统计数据；必须通过运行 CREATE STATISITCS 命令手动创建相应
的数据库对象：

#+begin_src sql
  create statistics flights_expr on (extract(
  month from scheduled_depature at time zone 'Europe/Moscow'
  ))
  from flights;
#+end_src

一旦收集到数据，估算的准确性就会提高：

#+begin_src sql
  analyze flights;
  explain select * from flights
  where extract(
  month from scheduled_depature at time zone 'Europe/Moscow'
  )=1;
#+end_src

要应用收集的统计数据，查询必须以与 CREATE STATISTICS 命令完全相同的形式指定表达式。

可通过运行 ALTER STATISTICS 命令单独调整扩展统计数据的大小限制。例如

#+begin_src sql
  alter statistics flights_expr set statistics 42;
#+end_src

与扩展统计相关的所有元数据都存储在系统目录的 pg_statistic_ext 表中，而收集的数据本身则存储在名为
pg_statistic_ext_data 的单独表中。这种分离用于对敏感信息实施访问控制。

可在单独的视图中以更方便的格式显示特定用户可用的扩展表达式统计数据：

#+begin_src sql
  select left(expr, 50) || '...' as expr,
  null_frac, avg_width, n_distinct,
  most_comm_vals as mcv,
  left(most_comm_freqs::text, 50) || '...' as mcf,
  from pg_stats_ext_exprs
  where statistics_name='flights_expr' \gx
#+end_src

表达式索引统计

另一种改进Cardinality的方法是使用为表达式索引收集的特殊统计数据；这些统计数据会在创建此类索引时自动收集，就像
为表所做的那样。如果真的需要索引，这种方法会非常方便。

#+begin_src sql
  drop statistics flights_expr;
  create index on flights(extract(
  month from scheduled_departure at time zone 'Europe/Moscow'
  ));

  analyze flights;

  explain select * from flights
  where extract(
  month from scheduled_departure at time zone 'Europe/Moscow'
  )=1;
#+end_src

表达式索引统计信息的存储方式与表统计信息的存储方式相同。例如，在查询 pg_stats 时，将索引名称指定为 tablename，
就可以获得不同值的数量：

#+begin_src sql
  select n_distinct from pg_stats
  where tablename='flights_extract_idx';
#+end_src

您可以使用 ALTER INDEX 命令调整索引相关统计信息的准确性。如果不知道与索引表达式相对应的列名，则必须先找到它。例如

#+begin_src sql
  select attname from pg_attribute
  where attrelid='flgihts_extract_idx'::regclass;

  alter index flights_extract_idx
  alter column extract set statistics 42;
#+end_src

** 多元统计
还可以收集跨多个表列的多元统计。前提条件是，必须使用 CREATE STATISTICS 命令手动创建相应的扩展统计量。

PostgreSQL 实现了三种多元统计。

列之间的功能依赖关系

如果一列中的数值（完全或部分）依赖于另一列中的数值，而筛选条件又包括这两列，那么Cardnality将被低估。

让我们考虑一个有两个过滤条件的查询：

#+begin_src sql
  select count(*) from flights
  where flight_no='PG0007' and departure_airport='VKO';
#+end_src

其价值被大大低估了：

#+begin_src sql
  explain select * from flights
  where flight_no='PG0007' and departure_airport='VKO';
#+end_src

这是一个众所周知的相关谓词问题。规划器假定谓词之间互不相关，因此整体选择性是根据逻辑 AND 组合的过滤条件选择性的乘
积来估算的。上面的计划清楚地说明了这个问题：一旦位图堆扫描节点根据 departure_airport 列上的条件对结果进行过滤，
位图索引扫描节点对 flight_no 列上条件的估计值就会大大降低。

然而，我们知道机场是由航班号明确定义的：第二个条件实际上是多余的（当然，除非机场名称有误）。在这种情况下，我们可以
通过对功能依赖性进行扩展统计来改进估算。

让我们对两列之间的功能依赖性进行扩展统计：

#+begin_src sql
  create statistics flights_dep(dependencies)
  on flight_no, departure_airport from flights;
  #+end_src

下一次分析运行将收集这一统计数据，从而改进估算结果：

#+begin_src sql
  analyze flights;
  explain select * from flights
  where flight_no='PG0007'
  and departure_airport='VKO';
#+end_src

收集到的统计数据存储在系统目录中，可以像这样访问：

#+begin_src sql
  select dependencies
  from pg_stats_ext where statistics_name='flights_dep';
#+end_src

这里的 2 和 5 是存储在 pg_attribute 表中的列号，而相应的值则定义了功能依赖程度：从 0（无依赖）到 1（第二列中的
值完全依赖于第一列中的值）。

多元差异值数量

对存储在不同列中的值的唯一组合数进行统计，可改进对多列执行 GROUP BY 操作的Cardinality估计。

例如，这里估计的出发机场和到达机场的可能对数是机场总数的平方；但实际值要小得多，因为并非所有对数都有直达航班：

#+begin_src sql
  select count(*)
  from (
  select distinct departure_airport, arrival_airport from flights
  ) t;
#+end_src

#+begin_src sql
  explain select distinct departure_airport, arrival_airport
  from flights;
#+end_src

让我们定义并收集一个关于不同值的扩展统计量：

#+begin_src sql
  create statistics flights_nd(ndistinct)
  on departure_airport, arrival_airport from flights;
  analyze flights;
#+end_src

Cardinality估计值就会提高

#+begin_src sql
  explain select distinct departure_airport, arrival_airport
  from flights;
#+end_src

您可以在系统目录中查看收集到的统计数据：

#+begin_src sql
  select n_distinct
  from pg_stats_ext where statistics_name='flights_nd';
#+end_src

多元 MCV 列表

如果数值的分布不均匀，那么仅仅依靠功能依赖性可能是不够的，因为估算的准确性在很大程度上取决于特定的数值对。例如，规划
器低估了从谢列梅捷沃机场起飞的波音 737 航班数量：

#+begin_src sql
  select count(*) from flights
  where departure_airport='SVO' and aircraft_code='733';
#+end_src

#+begin_src sql
  explain select * from flights
  where departure_airport='SVO' and aircraft_code='733';
#+end_src

在这种情况下，可以通过收集多元 MCV 列表的统计数据来改进估算：

#+begin_src sql
  create statistics flights_mcv(mcv)
  on departure_airport, aircraft_code from flights;
  analyze flights;
#+end_src

新的Cardinality估算更加准确

#+begin_src sql
  explain select * from flights
  where departure_airport='SVO' and aircraft_code='733';
#+end_src

为获得这一估计值，规划器依赖于系统目录中存储的频率值：

#+begin_src sql
  select values, frequency
  from pg_statistic_ext stx
  join pg_statistic_ext_data stxd on std.oid=stxd.stdoid,
  pg_mcv_list_items(stxdmcv) m
  where stxname='flights_mcv'
  and values='{SVO, 733}';
#+end_src

与普通 MCV 列表一样，多变量列表可容纳 100 个 default_statistics_target 值（如果在列级别也设置了该参数，则使
用其最大值）。

如果需要，还可以更改列表的大小，就像扩展表达式统计一样：

#+begin_src sql
  alter statistics ... set statistics ...;
#+end_src

在所有这些示例中，我只使用了两列，但您也可以收集更多列的多元统计数据。

要在一个对象中结合多种类型的统计信息，可以在其定义中提供这些类型的逗号分隔列表。如果没有指定类型，PostgreSQL 将为
指定列收集所有可能类型的统计数据。

除实际列名外，多元统计还可以使用任意表达式，就像表达式统计一样。


* 表访问方法

** 可插拔式存储引擎

PostgreSQL 所使用的数据布局并不是唯一可行的，也不是适用于所有负载类型的最佳 布局。根据可扩展性的理念，PostgreSQL
允许创建和插入各种表访问方法（可插拔存储引擎），但目前只有一种方法是开箱即用的：

#+begin_src sql
  select amname, amhandler from pg_am where amtype='t';
#+end_src

创建表格时，可以指定要使用的引擎（CREATE TABLE ... USING）；否则，将使用堆 default_table_access_method 参
数中列出的默认引擎。

为使 PostgreSQL 内核能以相同方式与各种引擎协同工作，表访问方法必须实现一个特殊接口。amhandler 列中指定的函数会
返回接口结构，其中包含核心所需的所有信息。

所有表格访问方法都可以使用以下核心组件：

+ 事务管理器，包括 ACID 和快照隔离支持
+ 缓冲区管理
+ I/O子系统
+ TOAST
+ 优化器和执行器
+ 索引支持

这些部件始终由存储引擎支配，即使没有全部使用它们。

反过来，存储引擎也是这样定义的

+ 元组格式和数据结构
+ 表扫描实现和代价估计
+ insert,update,delete的实现和锁操作
+ 可见性规则
+ 自动回收和分析处理

从历史上看，PostgreSQL 使用的是单一的内置数据存储，没有任何适当的编程接口，因此现在很难设计出既考虑到标准引擎的所
有特性又不干扰其他方法的好方法。

#+begin_comment
例如，目前还不清楚如何处理 WAL。新的访问方法可能需要记录它们自己的操作，而内核并不知道这些操作。现有的通用 WAL 机
制通常是个糟糕的选择，因为它会带来过多的开销。你可以添加另一个接口来处理新类型的 WAL 条目，但这样一来，崩溃恢复将依
赖于外部代码，这是非常不可取的。目前唯一可行的解决方案就是为每个特定引擎的内核打补丁。
#+end_comment

因此，我没有刻意严格区分表访问方法和核心。本书前几部分所描述的许多特性在形式上都属于堆访问方法，而不是核心本身。这种
方法很可能一直是PostgreSQL的终极标准引擎，而其他方法将填补各自的空白，以应对特定负载类型的挑战。

在目前正在开发的所有新型存储引擎中，我想提及以下几种：

+ Zheap 的目的是防止表格臃肿。它实现了就地行更新，并将与 MVCC 相关的历史数据移至单独的撤销存储区。这种引擎对涉及
  频繁数据更新的负载非常有用。

  对于 Oracle 用户来说，Zheap 体系结构似乎并不陌生，不过它也有一些细微差别（例如，索引访问方法的接口不允许创建具
  有自己版本的索引）。
+ Zedstore 实现列式存储，这在 OLAP 查询中可能是最有效的。

  存储数据的结构是元组 ID 的 B 树；每一列都存储在与主 B 树相关联的自己的 B 树中。将来有可能在一棵 B 树中存储多
  列数据，从而实现混合存储。

** 顺序扫描

存储引擎定义表数据的物理布局，并提供访问表数据的方法。唯一支持的方法是顺序扫描，即全文读取表fork的文件（或多个文
件）。在每个读取页面中，都会检查每个元组的可见性；不满足查询要求的元组会被过滤掉。

[[./images/lCbMtr.png]]

扫描进程会经过缓冲缓存；为确保大表不会剔除有用数据，会使用一个小尺寸的缓冲环。其他正在扫描同一张表的进程会加入这个
缓冲环，从而避免了额外的磁盘读取；这种扫描被称为同步扫描。因此，扫描不必总是从文件的起始位置开始。

顺序扫描是读取整个表或其中最佳部分的最有效方法。换句话说，当选择性较低时，顺序扫描的价值最大。(如果选择性高，即查询
只需选择几行，则最好使用索引）。

代码估算

在查询执行计划中，顺序扫描由 Seq Scan 节点表示：

#+begin_src sql
  explain select *
  from flights;
#+end_src

估计行数作为基本统计数据的一部分提供：

#+begin_src sql
  select reltuples from pg_class where relname='flights';
#+end_src

在估算成本时，优化器会考虑以下两个因素：磁盘 I/O 和 CPU 资源。

I/O 成本的计算方法是，将表中的页数与读取单个页面的成本相乘，假定页面是按顺序读取的。当缓冲区管理器请求读取一个页面
时，操作系统实际上会从磁盘读取更多数据，因此在操作系统缓存中很可能会出现多个后续页面。因此，使用顺序扫描读取单个页
面的成本（规划器估计为 seq_page_cost）低于随机访问成本（由 random_page_cost 值定义）。

默认设置对 HDD 运行良好；如果使用 SSD，则应大幅降低 random_page_cost 值（seq_page_cost 参数通常保持不变，作
为参考值）。由于这些参数之间的最佳比例取决于硬件，因此通常在表空间级别进行设置（ALTER TABLESPACE ... SET）。

#+begin_src sql
  select relpages,
  current_setting('seq_page_cost') as seq_page_cost,
  relpages * current_setting('seq_page_cost')::real as total
  from pg_class where relname='flights';
#+end_src

这些计算清楚地显示了不及时抽真空导致表膨胀的后果：表的fork越大，需要扫描的页数就越多，而不管其中包含的活图组数有
多少。

CPU 资源估算包括处理每个元组的成本（规划器估算为  cpu_tuple_cost）:

#+begin_src sql
  select reltuples,
  current_setting('cpu_tuple_cost') as cpu_tuple_cost,
  reltuples * current_setting('cpu_tuple_cost')::real as total
  from pg_class where relname='flights';
#+end_src

这两个估算值的总和就是计划的总成本。启动成本为零，因为顺序扫描没有先决条件。

如果需要对扫描的表进行过滤，则应用的过滤条件会出现在 Seq Scan 节点过滤部分的计划中。估计的行数取决于这些条件的选
择性，而成本估计包括相关的计算费用。

EXPLAIN ANALYZE 命令同时显示实际返回的行数和已过滤掉的行数：

#+begin_src sql
  explain (analyze, timing off, summary off)
  select * from flights
  where status='Scheduled';
#+end_src

让我们来看看一个使用聚合的更复杂的执行计划：

#+begin_src sql
  explain select count(*) from seats;
#+end_src

该计划由两个节点组成：计算count函数的上层节点（Aggregate）从扫描表的下层节点（Sequ Scan）提取数据。

聚合节点的启动成本包括聚合本身：如果不从下层节点获取所有记录，就不可能返回第一行（在本例中是唯一的一行）。聚合成本
是根据每个输入行的条件操作执行成本（按 cpu_operator_cost 估算）估算的：

#+begin_src sql
  select reltuples,
  current_setting('cpu_operator_cost') as cpu_operator_cost,
  round((
  reltuples * current_setting('cpu_operator_cost')::real
  )::numeric, 2) as cpu_cost
  from pg_class where relname='seats';
#+end_src

收到的估算值将加到 Seq Scan 节点的总成本中。

聚合节点的总成本还包括处理要返回的记录的成本，估计为 cpu_tuple_cost：

#+begin_src sql
  with t(cput_cost) as (
  select round((
  reltuples * current_setting('cpu_operator_cost')::real
  )::numeric, 2)
  from pg_class where relname='seats'
  )
  select 21.39 + t.cput_cost as startup_cost,
  round((
  21.39+t.cpu_cost+
  1*current_setting('cpu_tuple_cost')::real
  )::numeric, 2) as total_cost
  from t;
#+end_src

[[./images/1lJUGc.png]]

** 并行计划

PostgreSQL 支持并行查询执行。执行查询的领导进程（通过 postmaster）会产生多个工作进程，同时执行计划的同一个并行
部分。执行查询的领导进程（通过 postmaster）会催生多个工作进程，这些工作进程会同时执行计划中的同一个并行部分，并将
结果传递给领导进程，领导进程会将这些结果放在 Gather2 节点中。在不接受数据时，领导进程也可以参与计划并行部分的执行

如果需要，可以关闭 parallel_leader_participation 参数，禁止领导者进程参与并行计划的执行。

[[./images/ZKyoaD.png]]

当然，启动这些进程并在它们之间发送数据并不是免费的，因此到目前为止，并非所有查询都应并行化。

此外，即使允许并行执行，也并非计划的所有部分都能同时处理。有些操作只能由领导者以顺序模式单独执行。

#+begin_comment
 PostgreSQL 不支持并行计划执行的另一种方法，即由多个工作进程执行数据处理，这些工作进程实际上形成了一条流水线（粗
 略地说，每个计划节点都由一个单独的进程执行）；PostgreSQL 开发人员认为这种机制效率低下。
#+end_comment

** 并行顺序扫描

Parallel Seq Scan 节点是为并行处理而设计的节点之一，它可执行并行顺序扫描。

这个名字听起来有点争议（到底是顺序扫描还是并行扫描？如果我们看一下文件访问，表页是按照简单顺序扫描的顺序读取的。不
过，这一操作是由多个并发进程执行的。为了避免重复扫描同一个页面，执行器通过共享内存同步这些进程。

这里的一个微妙之处在于，操作系统无法获得典型的顺序扫描的全貌，相反，它看到的是几个执行随机读取的进程。因此，通常能
加快顺序扫描速度的数据预取变得毫无用处。为了尽量减少这种令人不快的影响，PostgreSQL 为每个进程分配的读取页面不只是
一个，而是多个连续的页面。

因此，并行扫描的意义不大，因为通常的读取成本会因进程间的数据传输而进一步增加。不过，如果工作者对获取的行进行任何后
处理（如聚合），总执行时间可能会大大缩短。

代价估算

让我们来看看一个在大型表格上执行聚合的简单查询。执行计划是并行化的：

#+begin_src sql
  explain select count(*) from bookings;
#+end_src

Gather 下面的所有节点都属于计划的并行部分。它们由每个工作进程执行（这里计划了两个工作进程），也可能由领导进程执行
（除非通过 parallel_leader_participation 参数关闭了该功能）。Gather 节点本身及其上方的所有节点构成计划的顺序
部分，由领导进程单独执行。

Parallel Seq Scan 节点表示并行堆扫描。行数字段显示单个进程要处理的估计平均行数。总的来说，执行必须由三个进程（一
个领导进程和两个工作进程）完成，但领导进程处理的行数较少：随着工作进程数量的增加，领导进程的份额也会变小。在这种特殊
情况下，系数为 2.4

#+begin_src sql
  select reltuples::numeric, round(reltuples / 2.4) as per_process
  from pg_class where relname='bookings';
#+end_src

并行顺序扫描成本的计算方法与顺序扫描类似。接收到的值较小，因为每个进程处理的行数较少；I/O 部分全部包括在内，因为仍
需逐页读取整个表：

#+begin_src sql
  select round((
  relpages * current_setting('seq_page_cost')::real +
  reltuples / 2.4 * current_setting('cpu_tuple_cost')::real
  )::numeric, 2)
  from pg_class where relname='bookings';
#+end_src

接下来，"Partial Aggregate"节点对获取的数据进行聚合；在这种特殊情况下，它会计算行数。

聚合成本按常规方式估算，并添加到表格扫描的成本估算中：

#+begin_src sql
  with t(startup_cost)
  as (
  select 22243.29 + round((
  reltuples / 2.4 * current_setting('cpu_operator_cost')::real
  )::numeric, 2)
  from pg_class
  where relname='bookings'
  )
  select startup_cost,
  startup_cost+round((
  1*current_setting('cpu_tuple_cost')::real
  )::numeric, 2) as total_cost
  from t;
#+end_src

下一个节点（Gather）由领导进程执行。该节点负责启动工作者并收集他们返回的数据。

为便于规划，启动进程（无论其数量多少）的成本估算由 parallel_setup_cost 参数定义，而进程间每行传输的成本则由
parallel_tuple_cost 估算。

在此示例中，启动成本（用于启动进程的成本）占主导地位；此值已添加到部分聚合节点的 启动成本中。总成本中还包括传输两行
的成本；该值将计入 "Partial Aggregate"节点的总成本：

#+begin_src sql
  select
  24442.36+round(
  current_setting('parallel_setup_cost')::numeric,
  2) as setup_cost,
  24442.37+round(
  current_setting('parallel_setup_cost')::numeric+
  2*current_setting('parallel_tuple_cost')::numeric,
  2) as total_cost;
#+end_src

最后但并非最不重要的是，"Finalize Aggregate"节点汇总 "Gather "节点从并行进程中收到的所有部分结果。

最终聚合的估算与其他聚合一样。它的启动成本基于聚合三条记录的成本；这个值会加到聚合的总成本中（因为计算结果需要所有
记录）。最终聚合的总成本还包括返回一条记录的成本。

#+begin_src sql
  with t(startup_cost) as (
  select 25442.57+round((
  3*current_setting('cpu_operator_cost')::real
  )::numeric, 2)
  from pg_class where relname='bookings'
  )
  select startup_cost,
  startup_cost+round((
  1*current_setting('cpu_tuple_cost')::real
  )::numeric, 2) as total_cost
  from t;
#+end_src

成本估算之间的依赖关系取决于节点是否需要先积累数据，然后再将结果传递给上级节点。聚合节点在获得所有输入行之前无法返
回结果，因此其启动成本基于下级节点的总成本。相反，聚合节点会在获取记录后立即开始向上游发送记录。因此，该操作的启动
成本取决于下层节点的启动成本，而总成本则基于下层节点的总成本。

下面是依赖关系图：

[[./images/hQJyfP.png]]

** 并行执行的限制

后端workers进程的数量

进程数量由三个参数组成的层次结构控制。同时运行的后台工作者的最大数量由 max_worker_processes 值定义。

然而，并行查询执行并不是唯一需要后台工作者的操作。例如，它们还参与逻辑复制，并可用于扩展。专门为并行计划执行分配的
进程数量受限于 max_parallel_workers 值。

其中，最多 max_parallel_workers_per_gather 进程可为一个领导者服务。

这些参数值的选择取决于以下因素：

+ 软件能力：系统必须有专门用于并行执行的空闲内核。
+ 容量：数据库必须包含大型表格。
+ 典型负载：必须有可能受益于并行执行的查询。

满足这些标准的通常是 OLAP 系统，而不是 OLTP 系统。

如果估计要读取的堆数据量不超过 min_parallel_table_scan_size 值，规划器根本不会考虑并行执行。

除非在 parallel_workers 存储参数中明确指定了特定表的进程数，否则进程数将按以下公式计算：

$$ 1+logs_{3}{(\frac{table size}{min_parallel_table_scan_size})} $$

这意味着表每增长三倍，PostgreSQL 就会多分配一个并行工作者进行处理。默认设置下的数据如下：

| table,MB | number of processes |
|----------+---------------------|
|        8 |                   1 |
|       24 |                   2 |
|       72 |                   3 |
|      216 |                   4 |
|      648 |                   5 |
|     1944 |                   6 |

无论如何，并行工作者的数量不能超过 max_parallel_workers_per_gather 参数定义的上限。

如果我们查询一个 19MB 的小表，将只计划并启动一个 Worker：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select count(*) from flights;
#+end_src
  
在一个 105MB 的表上进行查询，只能获得两个进程，因为它达到了最大并行工作进程数的限制：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select count(*) from bookings;
#+end_src

如果取消这一限制，我们将得到估计的三个过程：

#+begin_src sql
  alter system set max_parallel_workers_per_gather=4;
  select pg_reload_conf();
  explain (analyze, costs off, timing off, summary off)
  select count(*) from bookings;
#+end_src

如果查询执行期间空闲的插槽数量少于计划值，则只会启动可用的workers数量。

让我们把并行进程的总数限制在 5 个，同时运行两个查询：

#+begin_src sql
  alter system set max_parallel_workers=5;
  select pg_reload_conf();
  explain (analyze, costs off, timing off, summary off)
  select count(*) from bookings;
  explain (analyze, costs off, timing off,  summary off)
  select count(*) from bookings;
#+end_src


虽然在这两种情况下都预计有三个进程，但其中一个查询只获得了两个时段。

让我们恢复默认设置：

#+begin_src sql
  alter system reset all;
  select pg_reload_conf();
#+end_src

不可并行查询

并非所有查询都可以并行化。特别是，并行计划不能用于以下查询类型：

+ 修改或锁定数据的查询（UPDATE、DELETE、SELECT FOR UPDATE 等）。
  此限制不适用于以下命令中的子查询：
  CREATE TABLE AS, SELECT INTO, CREATE MATERIALIZED VIEW
  REFRESH MATERIALIZED VIEW
  不过，在所有这些情况下，行插入仍按顺序进行。
+ 可暂停的查询。它适用于在游标内运行的查询，包括 PL/pgSQL 中的 FOR 循环。
+ 调用 PARALLEL UNSAFE 函数的程序。默认情况下，这些都是用户定义的函数和一些标准函数。您可以通过查询系统目录获得
  不安全函数的完整列表：
  #+begin_src sql
    select * from pg_proc where proparallel='u';
  #+end_src
+ 如果从并行化查询中调用了函数内的查询（以避免worker数量的递增），则应调用这些函数。

其中一些限制可能会在未来的 PostgreSQL 版本中被移除。例如，在 Serializable 隔离级别并行查询的功能已经存在。

#+begin_comment
  目前正在开发使用 INSERT 和 COPY 等命令并行插入记录的功能。
#+end_comment

查询未并行化可能有几个原因：

+ 这种查询完全不支持并行化。
+ 服务器配置禁止使用并行计划（例如，由于强制规定的表大小限制）。
+ 并行计划比顺序计划更昂贵。

要检查查询是否可以并行化，可以暂时关闭 force_parallel_mode 参数。这样，规划器就会尽可能建立并行计划：

#+begin_src sql
  explain select * from flights;
#+end_src

#+begin_src sql
  set force_parallel_mode=on;
  explain select * from flights;
#+end_src

并行限制查询

计划的并行部分越大，可能实现的性能提升就越多。不过，某些操作只能由领导进程严格按顺序执行，尽管它们并不影响并行化。
换句话说，它们不能出现在聚集节点下面的计划树中。

不可扩展的子查询。不可扩展子查询最明显的例子就是扫描 CTE 结果（在计划中由 CTE 扫描节点表示）：

#+begin_src sql
  explain (costs off)
  with t as materialized(
  select * from flights
  )
  select count(*) from t;
#+end_src

如果 CTE 没有实体化，则计划不包含 CTE SCAN节点，因此此限制不适用。

不过，请注意，如果 CTE 本身的计算成本较低，也可以在并行模式下进行计算：

#+begin_src sql
  explain (costs off)
  with t as materialized(
  select count(*) from flights;
  )
  select * from t;
#+end_src

下图中的 SubPlan 节点下显示了另一个不可扩展子查询的示例：

#+begin_src sql
  explain (costs off)
  select * from flights f
  where f.scheduled_depature > ( -- SubPlan
  select min(f2.scheduled_depature)
  from flights f2
  where f2.aircraft_code=f.aircraft_code
  );
#+end_src

前两行表示主查询的计划：按顺序扫描航班表，并根据提供的过滤器检查每一行。过滤器条件包括一个子查询；该子查询的计划从
第三行开始。因此，SubPlan 节点会被执行多次，在这种情况下，通过顺序扫描获取的每一条记录都会被执行一次。

该计划的上层 Seq Scan 节点不能参与并行执行，因为它依赖于 SubPlan 节点返回的数据。

最后，这里还有一个由 InitPlan 节点表示的不可扩展子查询：

#+begin_src sql
  explain (costs off)
  select * from flights f
  where f.scheduled_depature > ( -- SubPlan
  select min(f2.scheduled_depature)
  from flights f2
  where exists ( -- InitPlan
  select * from ticket_flights tf
  where tf.flight_id=f.flight_id
  )
  );
#+end_src

[[./images/KIPsEQ.png]]

与 SubPlan 节点不同，InitPlan 只评估一次（在本例中，每次执行 SubPlan 2 节点时评估一次）。

InitPlan 的父节点不能参与并行执行（但接收 InitPlan 评估结果的节点可以，如本示例）。

临时表。临时表不支持并行扫描，因为只能由创建临时表的进程访问。它们的页面是在本地缓冲缓存中处理的。要让多个进程都能
访问本地缓冲区，就需要像共享缓冲区那样的锁定机制，这将使其其他优点变得不那么突出。

#+begin_src sql
  create temporary table flights_tmp as select * from flights;
  explain (costs off)
  select count(*) from flights_tmp;
#+end_src

并行限制函数。定义为 PARALLEL RESTRICTED 的函数只允许在计划的顺序部分使用。您可以通过运行以下查询从系统目录中获
取此类函数的列表：

#+begin_src sql
  select * from pg_proc where proparallel='r';
#+end_src

只有在完全了解所有影响并仔细研究了所有施加的限制后，才能将您的功能标记为 PARALLEL RESTRICTED（更不用说
PARALLEL SAFE）。



* 索引访问方法

** 索引和可扩展性

索引是数据库对象，主要用于加速数据访问。它们是辅助结构：任何索引都可以根据堆数据删除和重新创建。除了加快数据访问速
度外，索引还用于执行某些完整性约束。

PostgreSQL 核心提供六种内置索引访问方法（索引类型）：

#+begin_src sql
  select amname from pg_am where amtype='i';
#+end_src

PostgreSQL 的可扩展性意味着可以在不修改内核的情况下添加新的访问方法。其中一个扩展方法（bloom 方法）已被纳入标准
模块集。

尽管各种索引类型之间存在诸多差异，但它们最终都会将一个键（例如索引列的值）与包含该键的堆元组相匹配。元组由六个字节
的元组 ID 或 TID 表示。知道了键或关于键的一些信息，就可以快速读取可能包含所需数据的元组，而无需扫描整个表。

为了确保新的访问方法可以作为扩展添加进来，PostgreSQL 实现了一个通用的索引引擎。其主要目的是检索和处理特定访问方
法返回的 TID：

+ 从相应的堆元组中读取数据
+ 根据特定快照检查元组可见性
+ 如果方法对条件的评估不确定，则重新检查条件

索引引擎还参与执行优化阶段制定的计划。在评估各种执行路径时，优化器需要了解所有可能适用的访问方法的属性：方法是否能
按要求的顺序返回数据，还是需要单独的排序阶段？是否可以立即返回几个首值，还是需要等待整个结果集被获取？

不仅仅是优化器需要了解访问方法的具体细节。创建索引需要回答更多问题：访问方法是否支持多列索引？该索引能否保证唯一性？

索引引擎允许使用多种访问方法；为了获得支持，访问方法必须实现特定的接口，以声明其特征和属性。

访问方法用于完成以下任务：

+ 实施建立索引以及插入和删除索引项的算法
+ 在页面之间分配索引条目（由缓冲区缓存管理器进一步处理）
+ 实施回收算法
+ 获取锁以确保正确的并行操作
+ 生成 WAL 条目
+ 按键获取索引数据
+ 估算索引扫描成本

可扩展性还表现为添加新数据类型的能力，而访问方法事先对这些数据类型一无所知。因此，访问方法必须定义自己的接口，以便
插入任意数据类型。

要使用特定的访问方法来使用新的数据类型，就必须实现相应的接口，即提供可与索引一起使用的操作符，并可能提供一些辅助支持
函数。这样一组操作符和函数被称为操作符类。

索引逻辑部分由访问方法本身实现，但也有一部分外包给了操作符类。这种分配是相当随意的：B 树的所有逻辑都连线到访问方法
中，而其他一些方法可能只提供主要框架，将所有执行细节留给特定的操作符类。同一种数据类型通常由多个运算符类支持，用户可
以选择行为最合适的运算符类。

以下是总体情况的一小部分：

[[./images/xqKGdi.png]]

** 操作类和系列

操作类

访问方法接口由操作符类实现，操作符类是访问方法应用于特定数据类型的操作符和支持函数的集合。

操作符类别存储在系统目录的 pg_opclass 表中。下面的查询将返回上述示例的完整数据：

#+begin_src sql
  select amname, opcname, opcintype::regtype
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
#+end_src

在大多数情况下，我们不需要了解运算符类。我们只需创建一个默认使用某个操作符类的索引。

例如，下面是支持文本类型的 B 树操作符类。其中一个类始终被标记为默认类：

#+begin_src sql
  select opcname, opcdefault
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  where amname='btree'
  and opcintype='text'::regtype;
#+end_src

创建索引的典型命令如下：

#+begin_src sql
  create index on aircrafts(model, range);
#+end_src

但这只是一种速记符号，可扩展为以下语法：

#+begin_src sql
  create index on aircrafts
  using btree -- the default access method
  (
    model text_ops, -- the default operator class for text
    range int4_ops  -- the default operator class for integer
  );
#+end_src

如果想使用不同类型的索引或实现某些自定义行为，则必须明确指定所需的访问方法或操作符类。

为特定访问方法和数据类型定义的每个运算符类都必须包含一组运算符，这些运算符接受该类型的参数并实现该访问方法的语义。

例如，btree 访问方法定义了五个强制比较运算符。任何 btree 运算符类都必须包含这五个运算符：

#+begin_src sql
  select opcname, amopstrategy, amopopr::regoperator
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_opclass opc on opcfamily=opf.oid
  join pg_amop amop on amopfamily=opcfamily
  where amname='btree'
  and opcname in ('text_ops', 'text_pattern_ops')
  and amoplefttype='text'::regtype
  and amoprighttype='text'::regtype
  order by opcname, amopstrategy;
#+end_src

访问方法中隐含的运算符的语义由显示为 amopstrategy 的策略编号来反映。例如，btree 的策略 1 表示小于，2 表示小于
或等于，以此类推。运算符本身可以有任意的名称。

上例显示了两种运算符。普通运算符与带转折号的运算符的区别在于，后者不考虑校对，而是对字符串进行位比较。不过，这两种
运算符实现了相同的逻辑比较操作。

text_pattern_ops 操作符类旨在解决 ~~ 操作符（对应于 LIKE 操作符）的支持限制问题。在使用 C 以外的任何校对方式
的数据库中，该操作符不能在文本字段上使用正则表达式索引：

#+begin_src sql
  show lc_collate;
  create index on tickets(passenger_name);
  explain (costs off)
  select * from tickets where passenger_name like 'ELENA%';
#+end_src

使用 text_pattern_ops 操作符类的索引行为不同：

#+begin_src sql
  create index tickets_passenger_name_pattern_id
  on tickets(passenger_name text_pattern_ops);
  explain (costs off)
  select * from tickets where passenger_name like 'ELENA%';
#+end_src

请注意索引条件中过滤表达式的变化。现在搜索只使用 % 之前的模板前缀，而假阳性命中则会在基于过滤条件的重新检查中被过
滤掉。btree 访问方法的操作符类没有提供用于比较模板的操作符，因此在此应用 B-tree 的唯一方法是使用比较操作符重写此
条件。text_pattern_ops 类的运算符不考虑校对，这为我们提供了使用等价条件的机会。

如果满足以下两个前提条件，就可以使用索引来加快过滤条件的访问速度：

1. 条件的写法是 "索引列运算符表达式"（如果运算符指定了换算对应运算符，条件的写法也可以是 "索引列运算符表达式"）。
2. 且操作符属于索引声明中为索引列指定的操作符类。

例如，下面的查询可以使用索引：

#+begin_src sql
  explain (costs off)
  select * from tickets where 'ELENA BELOVA'=passenger_name;
#+end_src

注意索引条件中参数的位置：在执行阶段，索引字段必须在左边。当参数被置换时，运算符会被换元运算符取代；在这种特殊情况
下，运算符是相同的，因为相等关系是换元关系。

在下一个查询中，从技术上讲不可能使用常规索引，因为条件中的列名被函数调用所替代：

#+begin_src sql
  explain (costs off)
  select * from tickets where initcap(passenger_name)='Elena Belova''
#+end_src

这里可以使用表达式索引，它在声明中指定了一个任意表达式，而不是列：

#+begin_src sql
  create index on tickets((initcap(passenger_name)));
  explain (costs off)
  select * from tickets where initcap(passenger_name)='Elean Belova';
#+end_src

索引表达式只能依赖于堆元组值，且不得受数据库中存储的其他数据或配置参数（如本地设置）的影响。换句话说，如果表达式包
含任何函数调用，这些函数必须是 IMMUTABLE 的，而且必须遵守这一波动性类别。否则，对于同一查询，索引扫描和堆扫描可能
会返回不同的结果。

除常规操作符外，操作符类还可以提供访问方法所需的支持函数。例如，btree 访问方法定义了五个支持函数；第一个（比较两个
值）是必须的，其余的都可以不提供：

#+begin_src sql
  select amprocnum, amproc::regproc
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_opclass opc on opcfamily=opf.oid
  join pg_amproc amproc on amprocfamily=opcfamily
  where amname='btree'
  and opcname='text_ops'
  and amproclefttype='text'::regtype
  and amprocrighttype='text'::regtype
  order by amprocnum;
#+end_src

操作符族

每个操作符类总是属于某个操作符族（列在系统目录的 pg_opfamily 表中）。一个系列可以由多个以相同方式处理类似数据类
型的类组成。

例如，integer_ops 系列包括多个用于积分数据类型的类，这些类的语义相同，但大小不同：

#+begin_src sql
  select opcname, opcintype::regtype
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_opclass opc on opcfamily=opf.oid
  where amname='btree'
  and opfname='integer_ops';
#+end_src

datetime_ops 系列包括处理日期的操作符类：

#+begin_src sql
  select opcname, opcinttype::regtype
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_opclass opc on opcfamily=opf.oid
  where amname='btree'
  and opfname='datetime_ops';
#+end_src

虽然每个运算符类只支持一种数据类型，但一个系列可以包含不同数据类型的运算符类：

#+begin_src sql
  select opcname, amopopr::regoperator
  from pg_am am
  join pg_opfamily opf opfmethod=am.oid
  join pg_opclass opc on opcfamily=opf.oid
  join pg_amop amop on amopfamily=opfamily
  where amname='btree'
  and opfname='integer_ops'
  and amoplefttype='integer'::regtype
  and amopstrategy=1
  order opcname;
#+end_src

由于将各种运算符归类为一个系列，当索引用于涉及不同类型值的条件时，规划器可以不进行类型转换。

** 索引引擎接口

与表格访问方法一样，pg_am 表中的 amhandler 列包含实现接口的函数名称：

#+begin_src sql
  select amname, amhandler from pg_am where amtype='i';
  #+end_src

该函数用实际值填充接口结构中的占位符。其中一些是负责与索引访问相关的独立任务的函数（例如，它们可以执行索引扫描并返
回堆元组 ID），而另一些则是索引引擎必须了解的索引方法属性。

所有的属性分成三组

+ 访问方法属性
+ 特定索引的属性
+ 索引的列级属性

访问方法和索引级属性之间的区别是着眼于未来的：目前，基于特定访问方法的所有索引在这两个级别上总是具有相同的属性。

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ]) p(name)
  where a.amname='btree';
#+end_src

*CAN ORDER* 接收排序数据的能力。目前只有 B 树支持这一属性。

要按要求的顺序获取结果，可以先扫描表格，然后对获取的数据进行排序：

#+begin_src sql
  explain (costs off)
  select * from seats order seat_no;
#+end_src

但如果有支持该属性的索引，数据就可以按照所需的顺序一次性返回：

#+begin_src sql
  explain (costs off)
  select * from seats order by aircraft_code;
#+end_src

*CAN UNIQUE* 支持唯一和主键约束。此属性仅适用于 B 树。

每次声明唯一或主键约束时，PostgreSQL 都会自动创建一个唯一索引来支持该约束。

#+begin_src sql
  insert into bookings(book_ref, book_date, total_amount)
  values('000004', now(), 100.00);
#+end_src

尽管如此，如果只是创建唯一索引，而不明确声明完整性约束，效果似乎是完全一样的：索引列不允许重复。那么，区别在哪里呢？

完整性约束定义了绝不能违反的属性，而索引只是保证该属性的一种机制。从理论上讲，约束可以通过其他方式施加。

例如，PostgreSQL 不支持分区表的全局索引，但可以在此类表上创建唯一约束（如果其中包含分区键）。在这种情况下，全局唯
一性由每个分区的本地唯一索引来确保，因为不同的分区不能拥有相同的分区键。

*CAN MULTI COL* 能够建立多列索引。

多列索引可以通过对不同表列施加多个条件来加快搜索速度。例如，ticket_flights 表有一个复合主键，因此要在不止一列上
建立相应的索引：

#+begin_src sql
  \d ticket_flights_pkey
#+end_src

使用索引可通过票号和航班 ID 进行航班搜索：

#+begin_src sql
  explain (costs off)
  select * from ticket_flights
  where ticket_no='0005432001355'
  and flight_id=51618;
#+end_src

通常情况下，即使过滤条件只涉及索引中的部分列，多列索引也能加快搜索速度。在 B 树的情况下，如果过滤条件跨越了在索引声
明中首先出现的列的范围，那么搜索效率就会很高：

#+begin_src sql
  explain (costs off)
  select *
  from ticket_flights
  where ticket_no='0005432001355';
#+end_src

在所有其他情况下（例如，如果条件只包括 flights_id），搜索实际上仅限于初始列（如果查询包括相应的条件），而其他条件
仅用于过滤返回的结果。其他类型的索引可能会有不同的表现。

*CAN EXCLUDE* 支持 EXCLUDE 约束。

EXCLUDE 约束保证操作符定义的条件不会满足任何一对表行。要施加这种约束，PostgreSQL 会自动创建一个索引；必须有一个
操作符类，其中包含约束条件中使用的操作符。

通常是交集运算符 && 来实现这一目的。例如，您可以用它来明确声明会议室不能在同一时间被预订两次，或者地图上的建筑物不
能重叠。

有了相等运算符，排除约束就有了唯一性的含义：禁止表中有两条具有相同键值的记录。不过，它与 UNIQUE 约束不同：特别是，
排除约束键不能被外键引用，也不能在 ON CONFLICT 子句中使用。

*CAN INCLUDE* 在索引中添加非键列的功能，使该索引具有覆盖性。

使用该属性，可以用附加列扩展唯一索引。这样的索引仍能保证所有关键列的值都是唯一的，同时从包含的列中检索数据不会产生堆
访问：

#+begin_src sql
  create unique index on flights(flight_id) include(status);
  explain (costs off)
  select status from flights
  where flight_id=51618;
#+end_src

索引级属性

以下是与索引相关的属性（显示的是现有索引）：

#+begin_src sql
  select p.name, pg_index_has_property('seats_pkey', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backword_scan'
  ]) p(name);
#+end_src

*CLUSTERABLE* 根据索引扫描所返回 ID 的顺序物理移动堆元组的能力。

该属性显示是否支持 CLUSTER 命令。

*INDEX SCAN* 索引扫描支持

该属性意味着访问方法可以逐个返回 TID。奇怪的是，有些索引并不提供这种功能。

*BACKWARD SCAN* 能够以与创建索引时指定的顺序相反的顺序返回结果。

只有当访问方法支持索引扫描时，该属性才有意义。

列级属性

最后，让我们来看看列属性：

#+begin_src sql
  select p.name,
  pg_index_column_has_property('seats_pkey', 1, p.name)
  from unnest(array[
  'asc', 'desc', 'nulls_first', 'nulls_last', 'orderable',
  'distance_orderable', 'returnable', 'search_array', 'search_nulls'
  ]) p(name);
#+end_src

*ASC, DESC, NULLS FRIST, NULLS LAST* 列值排序

这些属性定义了列值应按升序还是降序存储，以及 NULL 值应出现在常规值之前还是之后。所有这些属性只适用于 B 树。

*ORDERABLE* 使用 ORDER BY 子句对列值进行排序的功能。

该属性仅适用于 B 树。

*DISTANCE ORDERABLE* 支持排序操作

与返回逻辑值的常规索引操作符不同，排序操作符返回的是一个实数，表示一个参数与另一个参数之间的 "距离"。索引支持在查询
的 ORDER BY 子句中指定此类操作符。

例如，排序运算符 <-> 可以找到与指定点距离最短的机场：

#+begin_src sql
  create index on airports_data using gist(coordinates);
  explain (costs off)
  select * from airports
  order by coordinates <-> point(43.578, 57.593)
  limit 3;
#+end_src

*RETURNABLE* 无需访问表即可返回数据（支持仅索引扫描）。

该属性定义了索引结构是否允许检索索引值。但这并不总是可行的：例如，某些索引可能存储哈希代码而非实际值。在这种情况下，
CAN INCLUDE 属性也不可用。

*SEARCH ARRAY* 支持搜索数组中的多个元素。
明确使用数组并不是唯一必要的情况。例如，规划器会将 IN（列表）表达式转换为数组扫描：

#+begin_src sql
  explain (costs off)
  select * from bookings
  where book_ref in ('C7C821', 'A5D060', 'DDE1BB');
#+end_src

如果索引方法不支持此类操作符，执行器可能需要执行多次迭代才能找到特定值（这会降低索引扫描的效率）。

*SEARCH NULLS* 搜索 IS NULL 和 IS NOT NULL 条件。

我们是否应该为 NULL 值建立索引？一方面，它允许我们对 IS [NOT] NULL 等条件执行索引扫描，以及在没有提供过滤条件的
情况下将索引用作覆盖索引（在这种情况下，索引必须返回所有堆元组的数据，包括包含 NULL 值的数据）。但另一方面，跳过
NULL 值可以减少索引的大小。

访问方法开发人员可以自行决定，但通常情况下，NULL 值确实会被索引。

如果不需要索引中的 NULL 值，可以通过建立部分索引来排除 NULL 值，该部分索引只覆盖需要的记录。例如

#+begin_src sql
  create index on flights(actual_arrival)
  where actual_arrival is not null;
  explain (costs off)
  select * from flights
  where actual_arrival='2017-16-13 10:33:00+03';
#+end_src

部分索引比完整索引要小，而且只有在修改的记录被索引时才会更新，这有时会带来明显的性能提升。显然，除了 NULL 检查外，
WHERE 子句还可以提供任何条件（可与不可变函数一起使用）。

建立部分索引的功能由索引引擎提供，因此不依赖于访问方法。

当然，该接口只包括那些必须事先知道才能做出正确决定的索引方法属性。例如，它并没有列出支持谓词锁或非阻塞索引创建
（CONCURRENTLY）等功能的任何属性。这些属性是在实现接口的函数代码中定义的。

* 索引扫描

** 定期索引扫描(Regular Index Scans)

访问索引提供的 TID 有两种基本方法。第一种是执行索引扫描。大多数索引访问方法（但不是所有方法）都有 INDEX SCAN 属
性来支持这种操作。

索引扫描在计划中由INDEX SCAN节点表示：

#+begin_src sql
  explain select * from bookings
  where book_ref='9AC0C6' and total_amount=48500.00;
#+end_src

在索引扫描过程中，访问方法会逐个返回 TID。收到 TID 后，索引引擎会访问该 TID 所指向的堆页面，获取相应的元组，并在
满足可见性规则的情况下，返回该元组所请求的字段集。这个过程一直持续到访问方法用完与查询匹配的 TID。

Index Cond（索引条件）行只包括可使用索引检查的过滤条件。其他必须在堆中重新检查的条件则单独列在过滤器一行中。

正如本例所示，索引和堆访问操作都由一个共同的 Index Scan 节点来处理，而不是由两个不同的节点来处理。但还有一个单独的
Tid Scan 节点，如果预先知道元组的 ID，它就会从堆中获取元组：

#+begin_src sql
  explain select * from bookings where ctid='(0, 1)'::tid;
#+end_src


代价估算

索引扫描的成本估算包括索引访问操作和堆页面读取的估算成本。

显然，与索引相关的估算部分完全取决于特定的访问方法。对于 B 树，代价主要来自于获取索引页和处理其条目。需要读取的页
数和行数可由数据总量和应用过滤器的选择性决定。索引页的访问是随机的（逻辑结构中相互跟随的页在磁盘上是物理分散的）。
从根节点到叶节点以及计算所需的所有表达式所耗费的 CPU 资源会进一步增加估算量。

与堆相关的估算部分包括访问堆页面的成本，以及处理所有获取的图元所需的 CPU 时间。值得注意的是，I/O 估算既取决于索引
扫描的选择性，也取决于磁盘上元组的物理顺序与访问方法返回其 ID 的顺序之间的相关性。

良好方案：高相关性

如果磁盘上元组的物理顺序与索引中 TID 的逻辑顺序完全相关，那么每个页面将只被访问一次：索引扫描节点将按顺序从一个页面
到另一个页面，逐个读取元组。

[[./images/G8UkYR.png]]

PostgreSQL 收集相关性统计数据：

#+begin_src sql
  select attname, correlation
  from pg_stats where tablename='bookings'
  order by abs(correlation) desc;
#+end_src

如果相应的绝对值接近于 1，则相关性较高（如 book_ref 的情况）；如果绝对值接近于 0，则表明数据分布混乱。

#+begin_comment
  在这种特殊情况下，book_ref 列的高相关性当然是由于数据已经根据这一列以升序加载到表中，而且还没有更新。如果我们对
  在这一列上创建的索引执行 CLUSTER 命令，也会看到同样的情况。

  然而，完美的相关性并不能保证所有查询都会按 book_ref 值的升序返回结果。首先，任何行更新都会将结果元组移动到表的
  末尾。其次，依赖于基于其他列的索引扫描的计划会以不同的顺序返回结果。即使是顺序扫描，也不一定从表的开头开始。因此，
  如果需要特定顺序，应在 ORDER BY 子句中明确定义。
#+end_comment

下面是一个处理大量记录的索引扫描示例：

#+begin_src sql
  explain select * from bookings where book_ref < '100000';
#+end_src

该条件的选择率估计如下：

#+begin_src sql
  select round(132999::numeric/reltuples::numeric, 4)
  from pg_class where relname='bookings';
#+end_src

这个值接近 $$ \frac{1}{16} $$，我们可以猜到，book_ref 的值范围是 000000 到 FFFFFF。

对于 B 树，I/O 成本估算中与索引相关的部分包括读取所有所需页面的成本。满足 B 树支持的任何条件的索引条目都存储在绑
定到有序列表中的页面中，因此需要读取的索引页面数估计为索引大小乘以选择性。但由于这些页面在物理上并不是有序的，因此
读取会以随机的方式进行。

CPU 资源用于处理所有读取的索引条目（处理单个条目的成本按 cpu_index_tuple_cost 值估算），以及计算每个条目的条件
（在本例中，条件包含一个运算符；其成本按 cpu_operator_cost 值估算）。

表访问被视为对所需页数的顺序读取。在完全相关的情况下，堆元组会在磁盘上相互跟随，因此页数是以表的大小乘以选择性来估
算的。

元组处理产生的费用进一步扩大了 I/O 成本；这些费用按每个元组的 cpu_tuple_cost 值估算

#+begin_src sql
  with costs(idx_cost, tbl_cost) as (
  select
  (
  select round(
  current_setting('random_page_cost')::real * pages +
  current_setting('cpu_index_tuple_cost')::real * tuples +
  current_setting('cpu_operator_cost')::real * tuples
  )
  from (
  select relpages * 0.0630 as pages, reltuples * 0.0630 as tuples
  from pg_class where relname='bookings_pkey'
  ) c
  ),
  (
  select round(
  current_setting('seq_page_cost')::real * pages +
  current_setting('cpu_tuple_cost')::real * tuples
  )
  from (
  select relpages*0.0630 as pages, reltuples * 0.0630 as tuples
  from pg_class where relname='bookings'
  )c
  )
  )
  select idx_cost, tbl_cost, idx_cost+tbl_cost as total
  from costs;
#+end_src

这些计算说明了成本估算背后的逻辑，因此结果与规划师提供的估算结果一致，即使是近似值。要获得精确值，还需要考虑其他细
节，在此不做讨论。

糟糕的情况 低相关性

如果相关性很低，一切都会改变。让我们在 book_date 列上创建一个索引，该列与该索引的相关性几乎为零，然后看一下查询，
它选择的行数与上一个示例中几乎相同。结果表明，索引访问的成本非常高，只有在所有其他选择都被明确禁止的情况下，规划器
才会选择索引访问：

如果相关性很低，一切都会改变。让我们在 book_date 列上创建一个索引，该列与该索引的相关性几乎为零，然后看一下查询，
它选择的行数与上一个示例中几乎相同。结果表明，索引访问的成本非常高，只有在所有其他选择都被明确禁止的情况下，规划器才
会选择索引访问：

#+begin_src sql
  create index on bookings(book_date);
  set enable_seqscan=off;
  set enable_bitmapscan=off;
  explain select * from bookings
  where book_date < '2016-08-23 12:00:00+03';
#+end_src

问题在于，低相关性会增加访问方法返回的下一个元组位于不同页面的可能性。因此，索引扫描节点必须在页面之间跳转，而不是
按顺序读取页面；在最糟糕的情况下，页面访问次数可能达到获取的元组数。

[[./images/tiCx1l.png]]

但是，在良好方案计算中，我们不能简单地用 random_page_cost 替换 seq_page_cost，用 reltuples 替换 relpages。
我们在计划中看到的成本要比这样估算出的值低得多：

#+begin_src sql
  with costs(idx_cost, tbl_cost) as (
  select
  ( select round(
  current_setting('random_page_cost')::real * pages +
  current_setting('cpu_index_tuple_cost')::real * tuples +
  current_setting('cpu_operator_cost')::real * tuples
  )
  from (
  select relpages * 0.0630 as pages, reltuples * 0.0630 as tuples +
  from pg_class where relname='bookings_pkey'
  ) c
  ),
  ( select round(
  current_setting('random_page_cost')::real * tuples +
  current_setting('cpu_tuple_cost')::real * tuples
  )
  from (
  select relpages * 0.0630 as pages, reltuples * 0.0630 as tuples
  from pg_class where relname='bookings'
  ) c
  )
  )
  select idx_cost, tbl_cost, idx_cost + tbl_cost as total from costs;
#+end_src

原因在于该模型考虑到了缓存。经常使用的页面保存在缓冲缓存（和 os 缓存）中，因此缓存大小越大，在其中找到所需页面的机
会就越多，从而避免了额外的磁盘访问操作。为便于规划，缓存大小由effective_cache_size参数定义。其值越小，预计读
取的页面就越多。

下图显示了需要读取的页数估算与表格大小之间的关系（选择性为 $$ \frac{1}{2} $$，页面包含 10 行）。虚线表示最佳情
况下的访问次数（如果相关性完美，则为页数的一半）和最差情况下的访问次数（如果相关性为零且无缓存，则为行数的一半）。

[[./images/kqz6y6.png]]

假设 effective_cache_size 值表示可用于缓存的内存总量（包括 PostgreSQL 缓冲区缓存和操作系统缓存）。但由于该参
数仅用于估算目的，并不影响内存分配本身，因此在更改该设置时不必考虑实际数据。

如果将 effective_cache_size 减少到最小，计划估算结果将接近上表中无缓存情况下的低端值：

#+begin_src sql
  set effective_cache_size='8kB';
  explain select * from bookings
  where book_date < '2016-08-23 12:00:00+03';
  reset effective_cache_size;
  reset enable_seqscan;
  reset enable_bitmapscan;
#+end_src

规划器会计算最坏情况和最好情况下的表格 I/O 成本，然后根据实际相关性取一个中间值。

因此，如果只需要读取部分行，索引扫描是一个不错的选择。如果堆元组与访问方法返回其 ID 的顺序相关，那么这一部分就可能
相当可观。然而，如果相关性较低，那么对于选择性较低的查询来说，索引扫描的吸引力就会大大降低。



** 仅索引扫描(Index-Only Scan)

如果一个索引包含了查询所需的所有堆数据，那么它就被称为该特定查询的覆盖索引。如果有这样的索引，就可以避免额外的表访
问：访问方法可以直接返回实际数据，而不是 TID。这种类型的索引扫描称为仅索引扫描。支持 RETURNABLE 属性的访问方法可
以使用它。

在计划中，该操作由仅索引扫描节点表示：

#+begin_src sql
  explain select book_ref from bookings where book_ref < '1000000';
#+end_src

顾名思义，这个节点永远不需要访问堆，但事实并非如此。在 PostgreSQL 中，索引不包含元组可见性信息，因此访问方法会返
回满足过滤条件的所有堆元组的数据，即使当前事务看不到它们。索引引擎会检查它们的可见性。

仅索引扫描的成本估算取决于堆中所有可见页面的比例。PostgreSQL 会收集此类统计数据：

#+begin_src sql
  select relpages, relallvisible
  from pg_class where relname='bookings';
#+end_src

仅索引扫描的成本估算与普通索引扫描不同：其与表访问相关的 I/O 成本与未出现在可见性映射中的页面比例成正比。(元组处
理的成本估算是一样的）。

由于在这个特定的例子中，所有页面只包含全部可见的元组，因此堆 I/O 的成本实际上不包括在成本估算中：

#+begin_src sql
  with costs(idx_cost, tbl_cost) as (
  select
  (
  select round(
  current_setting('roundom_page_cost')::real * pages +
  current_setting('cpu_index_tuple_cost')::real * tuples +
  current_setting('cpu_operator_cost')::real * tuples
  )
  from (
  select relpages * 0.0630 as pages,
  reltuples * 0.0634 as tuples
  from pg_class where relname='bookings_pkey'
  ) c
  ) as idx_cost,
  (
  select round(
  (1-frac_visible) *
  current_setting('seq_page_cost')::real * pages +
  current_setting('cpu_tuple_cost')::real * tuples
  )
  from (
  select relpages * 0.0630 as pages,
  reltuples * 0.0630 as tuples,
  relallvisible::real/relpages::real as frac_visible
  from pg_class where relname='bookings'
  ) c
  ) as tbl_cost
  )
  select idx_cost, tbl_cost, idx_cost + tbl_cost as total
  from costs;
#+end_src

任何尚未消失在数据库范围内的未真空变更都会增加计划的估计成本（从而降低该计划对优化器的吸引力）。EXPLAIN ANALYZE
命令可以显示实际的堆访问次数。

在新创建的表中，PostgreSQL 必须检查所有元组的可见性：

#+begin_src sql
  create temp table bookings_tmp
  with (autovaccum_enable=off) as
  select * from bookings
  order by book_ref;
  alter table bookings_tmp add primary key (book_ref);
  analyze bookings_tmp;
  explain (analyze, timing off, summary off)
  select book_ref from bookings_tmp where book_ref < '100000';
#+end_src

但是，一旦表格被清空，这种检查就变得多余了，只要所有页面仍然是全可见的，就不会执行这种检查。

#+begin_src sql
  vaccum bookings_tmp;
  explain (analyze, timing off, summary off)
  select book_ref from bookings_tmp where book_ref < '100000';
#+end_src

使用包含子句的索引

并非总能用查询所需的所有列来扩展索引：

+ 对于唯一索引，添加新列会影响原始键列的唯一性。
+ 索引访问方法可能没有为要添加的列的数据类型提供操作符类。

在这种情况下，您仍然可以将列包含到索引中，而不将其作为索引键的一部分。当然，我们不可能根据包含的列执行索引扫描，但
如果查询引用了这些列，索引就会起到覆盖列的作用。

下面的示例展示了如何用另一个包含列的索引替换自动创建的主键索引：

#+begin_src sql
  create unique index on bookings(book_ref) include (book_date);

  begin;
  alter table bookings drop constraint bookings_pkey cascade;

  alter table bookings add constraint bookings_pkey primary key
  using index bookings_book_ref_book_date_idx; -- a new index

  alter table tickets
  add foreign key(book_ref) references bookings(book_ref);

  commit;

  explain select book_ref, book_date
  from bookings where book_ref < '100000';
#+end_src

#+begin_comment
  这类索引通常被称为覆盖索引，但其实并不完全正确。如果索引的列集涵盖了特定查询所需的所有列，那么该索引就被认为是覆
  盖索引。至于是否涉及 INCLUDE 子句添加的任何列，或者是否只使用关键列，这并不重要。此外，同一个索引可以覆盖一个查
  询，但不能覆盖另一个查询。
#+end_comment

** 位图扫描

索引扫描的效率是有限的：随着相关性的降低，对堆页面的访问次数也会增加，扫描就会变成随机的，而不是顺序的。 为了克服这
一限制，PostgreSQL 可以在访问表之前获取所有 TID，并根据页码按升序排序。这正是位图扫描的工作原理，也是处理 TID 的
另一种常用方法。支持 BITMAP SCAN 属性的访问方法可以使用这种方法。

与常规索引扫描不同，该操作在查询计划中由两个节点表示：

#+begin_src sql
  create index on bookings(total_amount);
  explain
  select * from bookings where total_amount=48500.00;
#+end_src

位图索引扫描节点从访问方法中获取所有 TID 的位图。

位图由独立的段组成，每个段对应一个堆页面。所有这些段的大小相同，无论有多少个元组，都足以容纳所有页面元组。这个数量是
有限的，因为元组头相当大；一个标准大小的页面最多可容纳 256 个元组，相当于 32 个字节。

然后，位图堆扫描逐段遍历位图，读取相应的页，并检查所有标记为全可见的元组。因此，页面会根据其编号按升序读取，而且每
个页面都会被精确读取一次。

尽管如此，这一过程与顺序扫描并不相同，因为访问的页面很少彼此相随。因此，位图堆扫描节点通过异步读取
effective_io_concurrency 页面来实现自己的预取，而且它是唯一一个这样做的节点。这种机制依赖于某些操作系统实现的
posix_fadvise 函数。如果系统支持该功能，则应根据硬件能力在表空间级别配置 effective_io_concurrency 参数。

#+begin_comment
  其他一些内部进程也使用异步预取：
  + 为索引页删除堆记录时
  + 分析期间的堆页面 ( ANALYZE)
  预取深度由 maintenance_io_concurrency 定义。
#+end_comment

位图精度

满足查询过滤条件的元组页面越多，位图就越大。位图建立在后端本地内存中，其大小受 work_mem 参数的限制。一旦达到允许
的最大大小，某些位图段就会变成有损段：有损段的每个比特对应一整页，而段本身则包含一系列页面。因此，位图的大小会变小，
但精度会降低。

EXPLAIN ANALYZE 命令会显示所构建位图的精度：

#+begin_src sql
  select (analyze, costs off, timing off, summary off)
  select * from bookings where total_amount > 150000.00;
#+end_src

在这里，我们有足够的内存来绘制精确的位图。

如果我们降低 work_mem 值，部分位图段就会变得有损：

#+begin_src sql
  set work_mem='512kB';
  explain (analyze, costs off, timing off, summary off)
  select * from bookings where total_amount > 150000.00;
  reset work_mem;
#+end_src

读取与有损位图段相对应的堆页面时，PostgreSQL 必须重新检查页面中每个元组的过滤条件。要重新检查的条件在计划中总是显
示为重新检查条件（Recheck Cond），即使没有执行重新检查。在重新检查过程中被过滤掉的图元数量会单独显示（如通过索引
重新检查删除的行数）。

#+begin_comment
  如果结果集的大小过大，位图可能无法容纳 work_mem 内存块，即使其所有段都是有损的。那么这个限制将被忽略，位图将占
  用所需的空间。PostgreSQL 既不会进一步降低位图的精度，也不会将其任何段刷新到磁盘。
#+end_comment

位图操作

如果查询对多个表列应用了条件，而这些表列上又分别创建了索引，那么位图扫描就可以同时使用多个索引。所有这些索引都有自
己的位图；然后使用逻辑连接（如果表达式通过 AND 连接）或逻辑析取（如果表达式通过 OR 连接）将这些位图逐位组合在一
起。例如

#+begin_src sql
  explain (costs off)
  select * from bookings
  where book_date < '2016-08-28'
  and total_amount > 250000;
#+end_src

在这里，BitmapAnd 节点使用比特 AND 运算将两个位图组合在一起。

在将两个位图合并为一个位图时，如果新的位图适合 work_mem 内存块，则合并后的精确线段仍然是精确的，但如果两个位图中
的任何一个线段是有损的，则合并后的线段也将是有损的。

代价估算

让我们看看使用位图扫描的查询：

#+begin_src sql
  explain
  select * from bookings where total_amount=28000.00;
#+end_src

规划器使用的条件的近似选择性等于

#+begin_src sql
  select round(31878::numeric/reltuples::numeric, 4)
  from pg_class where relname='bookings';
#+end_src

位图索引扫描节点总成本的估算方法与不考虑堆访问的常规索引扫描成本相同：

#+begin_src sql
  select round(
  current_setting('random_page_cost')::real * pages +
  current_setting('cpu_index_tuple_cost')::real * tuples +
  current_setting('cpu_operator_cost')::real * tuples
  )
  from (
  select relpages * 0.0151 as pages, reltuples * 0.0151 as tuples
  from pg_class where relname='bookings_total_amount_idx'
  )c ;
#+end_src

位图堆扫描节点的 I/O 成本估算与常规索引扫描的完全相关情况不同。位图允许根据页码按升序读取堆页面，而不会返回到同一
个页面，但满足过滤条件的元组不会再相互跟随。PostgreSQL 可能要访问更多的页面，而不是读取相当紧凑的严格按顺序排列的
页面范围。

[[./images/zhFbbq.png]]

待读页数按以下公式估算：

$$ min(\frac{2relpages*reltupes*sel}{2relpages+reltuples*sel},relpages) $$
  
读取单个页面的估计成本介于 seq_page_cost 和 random_page_cost 之间，具体取决于获取的页面数与表中页面总数的比率：

#+begin_src sql
  with t as (
  select relpages,
  least(
  (2*relpages*reltuples*0.0151)/
  (2*relpages+reltuples*0.0151),
  relpages
  ) as pages_fetched,
  round(reltuples*0.0151) as tuples_fetched,
  current_setting('random_page_cost')::real as rnd_cost,
  current_setting('seq_page_cost')::real as seq_cost
  from pg_class where relname='bookings'
  )
  select pages_fetched,
  rnd_cost-(rnd_cost-seq_cost)*
  sqrt(pages_fetched/relpages) as cost_per_page,
  tuples_fetched
  from t;
#+end_src

与往常一样，I/O 估算值会因处理每个获取的元组的成本而增加。如果使用的是精确的位图，那么元组数量的估计值就是表中元组
的总数乘以过滤条件的选择性。但是，如果任何位图段是有损的，PostgreSQL 就必须访问相应页面，重新检查所有图元。

[[./images/DnKGkF.png]]

因此，估算时要考虑到有损位图段的预期比例（可根据所选行的总数和 work_mem 定义的位图大小限制来计算）。

[[./images/BSNoQR.png]]


这里的位图是精确的，成本估算大致如下：

#+begin_src sql
  with t as (
  select 1 as cost_per_page,
          13447 as pages_fetched,
          31878 as tuples_fetched
  ),
  costs(startup_cost, run_cost) as (
    select
      ( select round(
          589 /* cost estimation for the child node*/ +
          0.1 * current_setting('cpu_operator_cost')::real *
          reltuples * 0.0151
      ),
      ( select round(
           cost_per_page * page_fetched +
           current_setting('cpu_tuple_cost')::real * tuples_fetched +
           current_setting('cpu_operator_cost')::real * tuples_fetched
      )
      from t
    )
  )
  select startup_cost, run_cost,
       startup_cost + run_cost as total_cost
  from costs;
#+end_src

如果查询计划合并了多个位图，则单独索引扫描的成本总和会因合并这些位图而增加（很小的）成本。

** 并行索引扫描

所有索引扫描模式--常规索引扫描、仅索引扫描和位图扫描--都有各自的并行计划。

并行执行成本的估算方法与顺序执行成本的估算方法相同，但（就像并行顺序扫描一样）CPU 资源会在所有并行进程之间分配，
从而降低总成本。成本中的 I/O 部分不会被分配，因为进程会同步按顺序执行页面访问。

现在，让我向大家展示几个并行计划的例子，但不对其成本估算进行细分。

一个并行索引扫描：

#+begin_src sql
  explain select sum(total_amount)
  from bookings where book_ref<'400000';
#+end_src

在对 B 树进行并行扫描时，当前索引页的 ID 会保存在服务器的共享内存中。初始值由开始扫描的进程设定：它从树根遍历到第
一个合适的叶页，并保存其 ID。工作进程根据需要访问后续索引页，替换保存的 ID。获取页面后，工作进程会遍历所有合适的条
目，并读取相应的堆元组。当 Worker 读取完满足查询过滤器要求的所有值时，扫描结束。

一个仅索引的并行扫描：

#+begin_src sql
  explain select sum(total_amount)
  from bookings where total_amount < 50000.00;
#+end_src

只对索引进行的并行扫描会跳过对所有可见页面的堆访问，这是它与并行索引扫描的唯一区别。

一个位图并行扫描:

#+begin_src sql
  explain select sum(total_amount)
  from bookings where book_date<'2016-10-01';
#+end_src

位图扫描意味着位图总是由单个领导进程按顺序创建；因此，位图索引扫描节点的名称不包含 Parallel（并行）字样。位图准备
就绪后，并行位图堆扫描节点开始并行堆扫描。工作进程会访问后续的堆页面，并同时处理它们。

** 各种接入方法的比较

下图显示了各种访问方法的成本如何取决于过滤条件的选择性：

[[./images/rYdlmq.png]]

这是一个定性图表；实际数字当然取决于特定的表格和服务器配置。

顺序扫描不依赖于选择性，而且从选定行的某一部分开始扫描，通常比其他方法更有效。

索引扫描的成本受元组物理顺序与访问方法返回的 ID 顺序之间的相关性影响。如果相关性是完美的，那么即使被选中行的比例很
高，索引扫描的效率也会很高。但是，如果相关性较低（这种情况更为常见），索引扫描很快就会变得比顺序扫描更加昂贵。尽管
如此，在使用索引（通常是唯一索引）选择单行时，索引扫描仍然是绝对的领导者。

如果适用，纯索引扫描可以显示出很高的性能，即使所有行都被选中，也能击败顺序扫描。不过，它们的性能在很大程度上取决于
可见性映射，在最坏的情况下，纯索引扫描可能会退化为普通索引扫描。

位图扫描的成本受可用内存大小的影响，但比索引扫描成本受相关性的影响要小得多。如果相关性低，位图扫描的成本就会低得多。

每种访问方法都有自己完美的使用场景；没有一种方法总是优于其他方法。规划人员必须进行大量计算，才能估算出每种方法在每
种特定情况下的效率。显然，这些估算的准确性在很大程度上取决于收集到的统计数据的准确性。


* 嵌套循环

** 连接类型和方法

连接是 SQL 语言的一个关键特征；它是 SQL 语言强大和灵活的基础。记录集（可以直接从表中获取，也可以通过其他操作接收）
总是成对连接的。

有如下类型的连接

*Inner joins* 内连接（指定为 INNER JOIN，或简称 JOIN）包括满足特定连接条件的两组记录对。连接条件将一组行的某
些列与另一组行的某些列结合起来；所有涉及的列构成连接键。

如果连接条件要求两个集合的连接键相等，这样的连接称为等连接；这是最常见的连接类型。

两个集合的笛卡尔积（交叉连接）包括这些集合中所有可能的行对--它是带有真实条件的内部连接的一种特殊情况。

*Outer joins* 左外连接（指定为 LEFT OUTER JOIN，或简称为 LEFT JOIN）通过左集合中在右集合中没有匹配的记录（
相应的右侧列用 NULL 值填充）来扩展内连接的结果。

右外连接（RIGHT JOIN）也是如此，直到集合的排列。

全外连接（指定为 FULL JOIN）包括左外连接和右外连接，同时添加未找到匹配的右侧和左侧记录。

*Anti-Joins and Semi-Joins* 半连接看起来很像内连接，但它只包括左集合中与右集合匹配的记录（即使有多个匹配记录，
也只包括一次）。

反连接包括一个集合中在另一个集合中没有匹配的行。

SQL 语言没有明确的半连接和反连接，但使用 EXISTS 和 NOT EXISTS 等谓词也能达到同样的效果。

所有这些连接都是逻辑运算。例如，内连接通常被描述为清除了不满足连接条件的记录的笛卡尔积。但在物理层面上，内连接通常是
通过成本较低的方式实现的。

PostgreSQl提供几种连接方法

+ 嵌套循环连接
+ 哈希连接
+ 归并连接

连接方法是实现 SQL 连接逻辑运算的算法。尽管这些基本算法可能只支持其中的一些类型，但它们通常都有为特定连接类型量身
定制的特殊功能。例如，嵌套循环支持内连接（在计划中以嵌套循环节点表示）和左外连接（以嵌套循环左连接节点表示），但不
能用于全连接。

同样算法的某些功能也可用于其他操作，如聚合。

不同的连接方法在不同的条件下效果最佳；规划器的工作就是选择成本效益最高的方法。

**  嵌套循环连接

嵌套循环连接功能的基本算法如下。外循环遍历第一个数据集中的所有行（称为外集）。对于其中的每一条记录，嵌套循环都会遍
历第二个数据集（称为内集）中的记录，找出满足连接条件的记录。找到的每一对记录都会作为查询结果的一部分立即返回。

算法访问内集的次数与外集中的行数相同。因此，嵌套循环连接的效率取决于多个因素：

+ 外集行数的Cardinality
+ 是否有一种访问方法可以高效地获取内集所需的行数
+ 同时访问内集的相同行

笛卡尔积

无论集合中有多少行，嵌套循环连接都是查找笛卡尔积的最有效方法：

#+begin_src sql
  explain select * from aircrafts_data a1
  cross join aircrafts_data a2
  where a2.range > 5000;
#+end_src

[[./images/lyZkrf.png]]

嵌套循环节点使用上述算法执行连接。它总是有两个子节点：在计划中显示较高的节点对应外层行集，而较低的节点代表内层行集。

在本例中，内集由 Materialize 节点表示。该节点返回从子节点接收到的记录，并将其保存起来以备将来使用（记录在内存中
累积，直到其总大小达到 4MB work_mem，然后 PostgreSQL 开始将其溢出到磁盘上的临时文件中）。如果再次访问，节点会
读取累积的行，而不会调用子节点。因此，执行者可以避免再次扫描整个表，而只读取满足条件的行。

对于使用常规等连接的查询，也可以建立类似的计划：

#+begin_src sql :engine postgres 
  explain select *
  from tickets t
  join ticket_flights tf on tf.ticket_no=t.ticket_no
  where t.ticket_no='0005432000284';
#+end_src

在确认两个值相等后，计划器用 tf.ticket_no = 常量条件替换了连接条件 tf.ticket_no = t.ticket_no，实际上将等
连接简化为笛卡尔乘积。

Cardinality 估算  笛卡尔积的Cardinality是根据连接数据集的Cardinality的乘积估算的： 3 = 1 × 3.

代价估算  连接操作的启动成本综合了所有子节点的启动成本。

连接操作的全部代价包括以下部分：

+ 获取外集所有记录的成本
+ 单次检索内集所有行的成本（因为外集的Cardinality估计值等于 1）
+ 每返回一行的处理成本

以下是成本估算的依赖关系图：

[[./images/YmXPiI.png]]

连接操作的代价计算如下所示

#+begin_src sql
  select 0.43+0.56 as startup_cost,
  round((
      8.45+16.57+
      3*current_setting('cpu_tuple_cost')::real
      )::numeric, 2) as total_cost;
#+end_src

回到上一个示例

#+begin_src sql
  explain select *
  from aircrafts_data a1
  cross join aircrafts_data a2
  where a2.range > 5000;
#+end_src

现在，计划中包含了 Materialize 节点；在累积了从其子节点接收到的记录后，Materialize 会在所有后续调用中更快地返
回这些记录。

一般来说，连接总成本包括以下：

+ 获取外集所有行的成本
+ 初始获取内集所有行的成本（在此期间将执行具体化操作）
+ 重复获取内集行的 (N-1)- 倍成本（此处 N 为外集的行数）
+ 每返回一行的处理成本

这里的依赖关系图如下

[[./images/xd10tS.png]]

在本例中，物化减少了重复数据获取的成本。计划中显示了第一次 Materialize 调用的成本，但没有列出所有后续调用。我不会
在此提供任何计算结果，但在这个特定案例中，估算值为 0.0125。

因此，本例中的连接成本计算如下：

#+begin_src sql
  select 0.00+0.00 as startup_cost,
  round((
      1.09+(1.14+8*0.0125)+
      45*current_setting('cpu_tuple_cost')::real
      )::numeric, 2) as total_cost;
#+end_src

参数化连接

现在让我们来看一个更常见的例子，它并不归结为笛卡尔积：

#+begin_src sql
  create index on tickets(book_ref);
  explain select *
  from tickets t
  join ticket_flights tf on tf.ticket_no=t.ticket_no
  where t.book_ref='03A76D';
#+end_src

在这里，嵌套循环节点遍历外层集合（tickets）的行，并为其中的每一行搜索内层集合（flights）的相应行，同时将机票号码
(t.ticket_no) 作为参数传递给条件。当调用内部节点（Index Scan）时，它必须处理 ticket_no = 常量这一条件。

Cardinality估算。 规划器估计，外集的两行（rows=2）满足预订号的筛选条件，其中每行平均匹配内集的三行（rows=3）。

连接选择性是连接后两个集合的笛卡尔乘积的一部分。很明显，我们必须排除两个集合中那些在连接键中包含 NULL 值的记录，
因为它们永远不会满足相等条件。

估计的Cardinality等于笛卡尔积的万有引力（即两个集合的Cardinality）乘以选择性。

在这里，第一个（外）集合的估计Cardinality为两行。由于除了连接条件本身外，第二个（内部）数据集没有应用任何条件，
因此第二个数据集的Cardinality就是 ticket_flights 表的Cardinality。

由于连接的表是通过外键连接的，因此选择性的估算依赖于子表中的每一条记录在父表中都有一条完全匹配的记录这一事实。因此，
选择性是外键所指表大小的倒数。

因此，在 ticket_no 列不包含 NULL 值的情况下，估算结果如下：

#+begin_src sql
  select round(2*tf.reltuples*(1.0/t.reltuples)) as rows
  from pg_class t, pg_class tf
  where t.relname='tickets'
  and tf.relname='ticket_flights';
#+end_src

显然，也可以不使用外键来连接表。那么选择性将被视为特定连接条件的估计选择性。

对于本例中的等连接，假设值分布均匀的选择性估计通用公式如下：min ($$ \frac{1}{nd_2}, \frac{1}{nd_2 $$)，其
中 $ nd_1 $ 和 $ nd_2 $ 分别代表连接键在第一组和第二组中不同值的个数。

对不同值的统计显示，机票表中的机票号码是唯一的（这是意料之中的，因为 ticket_no 列是主键），而 ticket_flights
表中每张机票大约有三条匹配行：

#+begin_src sql
  select t.n_distinct, tf.n_distinct
  from pg_stats t, pg_stats tf
  where t.tablename='tickets' and t.attname='ticket_no'
  and tf.tablename='ticket_flights' and tf.attname='ticket_no';
#+end_src

结果将与外键连接的估计值相匹配：

#+begin_src sql
  select round(2*tf.reltuples*
  least(1.0/t.reltuples, 1.0/tf.reltuples/0.30362356)
  ) as rows
  from pg_class t, pg_class tf
  where t.relname='tickets' and tf.relname='ticket_flights';
#+end_src

规划器会尽可能地完善基线估计。规划器目前无法使用直方图，但如果在两个表的连接键上收集了 MCV 列表统计信息，规划器就
会将其考虑在内。这样就能更准确地估算出列表中出现的行的选择性，只有剩余的行需要依赖基于均匀分布的计算。

一般来说，如果定义了外键，联接选择性估计可能会更准确。对于复合连接键来说尤其如此，因为在这种情况下，选择性通常会被
大大低估。

使用 EXPLAIN ANALYZE 命令，不仅可以查看实际行数，还可以查看内循环的执行次数：

#+begin_src sql
  explain (analyze, timing off, summary off) select *
  from tickets t
  join ticet_flights tf on tf.ticket_no=t.ticket_no
  where t.book_ref='03A76D';
#+end_src

外集包含两行（实际行数=2）；估计正确。因此索引扫描节点执行了两次（循环次数=2），每次平均选择四条记录（实际记录数=
4）。因此，找到的记录总数为：实际行数=8。

#+begin_comment
  为了适应有限的页面宽度，我没有在输出中显示计划每个阶段的执行时间（定时关闭）；此外，在某些平台上，启用定时的输出
  会大大降低查询的执行速度。不过，如果我们将其包括在内，PostgreSQL 将显示一个平均值，就像显示行计数一样。要获得总
  的执行时间，你应该用这个值乘以迭代次数（循环）。
#+end_comment

*代价估算* 这里的成本估算公式与前面的例子相同。

回顾一下查询计划

#+begin_src sql
  explain select *
   from tickets t
   join ticket_flights tf on tf.ticket_no=t.ticket_no
   where t.book_ref='03A76D';
#+end_src

在这种情况下，以后每次扫描内集的成本与第一次扫描的成本相同。因此，我们最终会得到以下数字：

#+begin_src sql
  select 0.43+0.56 as startup_cost,
  round((
  12.46+2*16.57+
  6*current_setting('cpu_tuple_cost')::real
  )::numeric, 2) as total_cost;
#+end_src

行缓存(Memoization)

如果用相同的参数值重复扫描内集（从而得到相同的结果），那么缓存内集的行可能会有好处。

这种缓存由 Memoize 节点执行。Memoize 节点与 Materialize 节点类似，都是为了处理参数化连接而设计的，其实现要复
杂得多：

+ Materialize 节点只是将其子节点返回的所有记录具体化，而 Memoize 则确保不同参数值返回的记录分开保存。
+ 如果出现溢出，Materialize 存储会开始将行溢出到磁盘，而 Memoize 会将所有行保留在内存中（否则就没有缓存的意义了）

下面是一个使用 Memoize 的查询示例：

#+begin_src sql
  explain select *
  from flights f
  join aircrafts_data a on f.aircraft_code=a.aircraft_code
  where f.flight_no='PG0003';
#+end_src

用于存储缓存行的内存块大小等于 work_mem × × hash_mem_multiplier。正如第二个参数的名称所暗示的，缓存行存储在
哈希表中（开放寻址）。哈希键（在计划中显示为 "缓存键"）是参数值（如果有多个参数，则为多个值）

所有哈希键都被绑定到一个列表中；其中一端被视为冷键（因为它包含长期未使用的键），而另一端则是热键（它存储最近使用的
键）。

如果对 Memoize 节点的调用显示所传递的参数值与已缓存的行相对应，这些行将被传递到父节点（嵌套循环），而无需检查子节
点。然后，使用过的哈希键会被移到列表的热端。

如果缓存中不包含所需的行，Memoize 节点会从其子节点中提取这些行，将其缓存并传递给上一级节点。相应的哈希键也会变成热
键。

随着新数据的缓存，它可能会占满所有可用内存。为了释放空间，冷键对应的行会被驱逐。这种驱逐算法与缓冲缓存中使用的算法不
同，但目的相同。

有些参数值可能有很多匹配行，以至于无法放入分配的内存块中，即使所有其他行都已被驱逐。这样的参数会被跳过--只缓存部分记
录是没有意义的，因为下一次调用仍需从子节点获取所有记录。

*成本和Cardinality的估算。* 这些计算结果与我们上面看到的结果非常相似。我们只需记住，计划中显示的 Memoize 节点
的成本与其实际成本无关：它只是其子节点的成本增加了 cpu_tuple_cost 值。

我们已经遇到过 Materialize 节点的类似情况：它的成本只在后续扫描中计算，不会反映在计划中。

显然，只有当 Memoize 的成本低于其子节点时，使用 Memoize 才有意义。每次后续 Memoize 扫描的成本取决于预期的缓存
访问情况和可用于缓存的内存块大小。计算值在很大程度上取决于对内部行集扫描中使用的不同参数值数量的准确估计。根据这个
数字，可以权衡出要缓存的行和要从缓存中剔除的行的概率。预期的命中率会降低估计成本，而潜在的剔除率会增加估计成本。这
里我们将跳过这些计算的细节。

要了解查询执行过程中的实际情况，我们将像往常一样使用 EXPLAIN ANALYZE 命令：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from flights f
  join aircrafts_data a on f.aircraft_code=a.aircraft_code
  where f.flight_no='PG0003';
#+end_src

该查询选择了由特定类型飞机执行的相同航线航班，因此对 Memoize 节点的所有调用都使用了相同的哈希键。第一行必须从表中
获取（Misses：1），但随后的所有行都能在缓存中找到（Hits：112）。整个操作仅占用 1 KB 内存。

另外两个显示值为零：它们分别代表当无法缓存与特定参数集相关的所有行时，缓存溢出的次数和缓存驱逐的次数。数字过大表明
分配的缓存太小，这可能是由于对不同参数值的数量估计不准确造成的。这样一来，使用 Memoize 节点的成本就会很高。在极端
情况下，可以关闭启用 Memoize 参数，禁止规划器使用缓存。

外连接

嵌套循环连接可用于执行左外连接：

#+begin_src sql
  explain select *
  from ticket_flights tf
  left join boarding_passes bp on bp.ticket_no=tf.ticket_no
            and bp.flight_id=tf.flight_id
  where tf.ticket_no='0005434026720';
#+end_src

这里的连接操作由Nested Loop Left Join节点表示。规划器选择了带筛选器的非参数化连接：它对内部记录集执行相同的扫
描（因此该记录集隐藏在 Materialize 节点后面），并返回满足筛选条件（Join Filter）的记录。

外连接的Cardinality估算与内连接的Cardinality估算一样，只是将计算出的估算值与外部行集的卡入度进行比较，并将
较大的值作为最终结果。换句话说，外连接不会减少记录数（但可以增加）。

成本估算与内部连接类似。

我们还必须记住，规划器可以为内连接和外连接选择不同的计划。如果规划器被迫使用嵌套循环连接，即使是这个简单的示例也会有
不同的连接过滤器：

#+begin_src sql
  set enable_mergejoin=off;
  explain select *
  from ticket_flights tf
  join boarding_passes bp on bp.ticket_no=tf.ticket_no
                        and bp.flight_id=tf.flight_id
  where tf.ticket_no='0005434026720';
  reset enable_mergejoin;
#+end_src

由于外连接还必须检查票号，以便在外层行中没有匹配的情况下得到正确的结果，因此总成本略有不同。

由于嵌套循环算法对内集和外集的处理方式不同，因此不支持右连接。外层集会被全部扫描；至于内层集，索引访问只允许读取满
足连接条件的记录，因此其中一些记录可能会被完全跳过。

出于同样的原因，不支持完全连接。

反连接和半连接

反连接和半连接的相似之处在于，对于第一（外）集合中的每一行，只需在第二（内）集合中找到一个匹配行即可。

反连接仅在第一数据集中的记录在第二数据集中没有匹配记录的情况下才会返回：只要执行器在第二数据集中找到第一条匹配记录，
就可以退出当前循环：第一数据集中的相应记录必须从结果中排除。

反连接可用于计算 NOT EXISTS 谓词。

例如，让我们查找未定义机舱配置的飞机模型。相应的计划包含;Nested Loop Anti Join节点：

#+begin_src sql
  explain select *
  from aircrafts a
  where not exists (
      select * from seats s where s.aircrafts_code=a.aircrafts_code
  );
#+end_src

不使用 NOT EXISTS 谓词的其他查询将具有相同的计划：

#+begin_src sql
  explain select a.*
  from aircrafts a
  left join seats s on a.aircraft_code=s.aircraft_code
  where s.aircraft_code is null ;
#+end_src

半连接会返回第一数据集中至少有一条匹配记录在第二数据集中的行列（同样，无需检查数据集中是否有其他匹配记录--结果已经
知道了）。

半连接可用于计算 EXISTS 谓词。让我们查找机舱内安装有座椅的飞机型号：

#+begin_src sql
  explain select *
  from aircrafts a
  where exists (
     select * from seats s
     where s.aircraft_code=a.aircraft_code
  );
#+end_src

Nested Loop Semi Join节点表示同名连接方法。该计划（就像上面的反连接计划一样）提供了座位表（rows=149）中行数
的基本估计，尽管只检索其中一条就足够了。当然，实际查询执行会在获取第一行后停止：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from aircrafts a
  where exists(
     select * from aircrafts a
     where s.aircraft_code=a.aircraft_code
  );
#+end_src

*Cardinality估算。* 半连接的选择性是按照通常的方式估算的，只是内集的卡方数取为 1。对于反连接，估计的选择性会从
1 减去，就像否定一样。

*代价估算。* 对于反连接和半连接，成本估算反映了这样一个事实，即一旦找到第一个匹配行，第二组的扫描就会停止。

不等值连接

嵌套循环算法允许根据任何连接条件连接记录集。

显然，如果内集是一个基表，并在其上创建了索引，而连接条件使用的操作符属于该索引的操作符类，那么对内集的访问就会非常
高效。但是，我们总是可以通过计算由某些条件过滤的记录的笛卡尔乘积来执行连接--在这种情况下，条件可以是绝对任意的。就
像下面的查询，它选择的是一对相互靠近的机场：

#+begin_src sql
  create extension earthdistance cascade;
  explain (costs off) select *
  from airports a1
  join airports a2 on a1.airport_code!=a.airport_code
                   and a1.coordinates <@> a2.coordinates<100;
#+end_src

并行模式

嵌套循环连接可参与并行计划执行。

只有外集可以并行处理，因为它可以由多个工作者同时扫描。获取外层行后，每个Worker都要在内集中搜索匹配的行，这需要按
顺序完成。

下图中的查询包括几个连接；它搜索的是持有特定航班机票的乘客：

#+begin_src sql
  explain (costs off) select t.passenger_name
  from tickets t
  join ticket_flights tf on tf.ticket_no=t.ticket_no
  join flights f on f.flight_id=tf.flight_id
  where f.flight_id=12345;
#+end_src

在上层，嵌套循环连接是按顺序执行的。外层集由航班表中通过唯一键获取的单行组成，因此即使内层行数较多，嵌套循环的使用
也是合理的。

使用并行计划检索内集。每个工作员扫描自己在 ticket_flights 表中所占的行，并使用嵌套循环算法将它们与机票连接起来。




* 哈希

** 哈希连接

单程哈希连接

散列连接使用预先建立的散列表搜索匹配的记录。下面是一个使用这种连接的计划示例：

#+begin_src sql
  explain (costs off) select *
  from tickets t
  join ticket_flights tf on tf.ticket_no=t.ticket_no;
#+end_src

在第一阶段，Hash Join节点会调用Hash节点，后者会从其子节点中提取整个内部行集，并将其放入哈希表中。

散列表存储的是散列键和值对，可以通过键快速访问值；搜索时间与散列表的大小无关，因为散列键或多或少地均匀分布在数量有
限的桶中。给定密钥所属的散列桶由散列密钥的散列函数决定；由于散列桶的数量总是 2 的幂次，因此只需提取计算值所需的比
特数即可。

与缓冲存储器缓存一样，这种实现方式也使用可动态扩展的哈希表，通过链式连接解决哈希碰撞问题。

在连接操作的第一阶段，会扫描内集，并为其每一行计算哈希函数。连接条件（Hash Cond）中引用的列作为哈希键，而哈希表本
身则存储内集的所有查询字段。

如果整个哈希表都能在内存中容纳，那么哈希连接的效率就会最高，因为在这种情况下，执行器可以一次性处理数据。为此分配的
内存块大小受 work_mem × hash_mem_multiplier 值的限制。

[[./images/20MXNo.png]]

让我们运行 EXPLAIN ANALYZE 来统计查询的内存使用情况：

#+begin_src sql
  set work_mem='256MB';
  explain (analyze, costs off, timing off, summary off)
  select * from bookings b
  join tickets j on b.book_ref=t.book_ref;
#+end_src

嵌套循环连接会区别对待内集和外集，而散列连接则不同，它可以交换内集和外集。较小的集合通常被用作内部集合，因为这样可
以得到更小的哈希表。

在本例中，整个表都可以放入分配的缓存中：占用大约 143MB（Memory Usage），包含 $$ 4M = 2^{32} $$ 个数据桶。
因此，连接是一次性完成的（Batches）。

但如果查询只涉及一列，哈希表的容量将达到 111MB：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select b.book_ref
  from bookings b
  join tickets t on b.book_ref=t.book_ref;
  reset work_mem;
#+end_src

这也是避免在查询中引用多余字段的另一个原因（举例来说，如果使用星号，就会出现这种情况）。

所选的桶数应能保证在哈希表完全被数据填满时，每个桶平均只容纳一条记录。密度越大，散列碰撞率越高，搜索效率越低，而密
度越小，散列表占用的内存就越大。估计的哈希表桶数会增加到最接近的 2 的幂次。

(如果根据单行平均宽度估算的哈希表大小超过内存限制，则将采用两次散列）。

在哈希表完全建立之前，哈希连接不能开始返回结果。

在第二阶段（此时哈希表已经建立），哈希连接节点会调用它的第二个子节点来获取外层行集。对于扫描的每一行，哈希表都会搜
索匹配项。这需要计算外集中包含在连接条件中的列的哈希键。

[[./images/yMmJms.png]]

找到的匹配结果会返回到父节点。

*代价估算。* 我们已经介绍过Cardinality估计；由于它不依赖于连接方法，我现在将重点介绍成本估计。

Hash节点的成本由其子节点的总成本表示。它是一个虚数，只是用来填补计划中的空位。所有实际估算都包含在Hash Join节
点的成本中。

如下示例

#+begin_src sql
  explain (analyze, timing off, summary off)
  select * from flights f
  join seats s on s.aircraft_code=t.aircraft_code;
#+end_src

连接的启动成本主要是创建哈希表的成本，包括以下部分：

+ 获取内集的总成本，这是建立哈希表所必需的
+ 计算连接键中包含的所有列的哈希函数的成本，针对内集的每一行（按每次操作的 cpu_operator_cost 估算）
+ 将所有内层行插入哈希表的成本（按每插入一行的 cpu_tuple_cost 估算）
+ 获取外层记录集的启动成本，这是启动连接操作所必需的

总成本包括启动成本和连接本身的成本，即

+ 计算外集每一行中包含在连接键中的所有列的哈希函数的成本（cpu_operator_cost）
+ 连接条件重新检查的成本，这是处理可能的哈希碰撞所必需的（按每个被检查运算符的 cpu_operator_cost 估算）
+ 每一行的处理成本 ( cpu_tuple_cost)

所需重新检查的次数是最难估算的。计算方法是将外集的行数乘以内集（存储在哈希表中）的某个分数。为了估算这个分数，规划
者必须考虑到数据分布可能不均匀。我就不详细介绍这些计算方法了；在本例中，这个分数估计为 0.150112。

因此，我们的查询成本估计如下：

#+begin_src sql
  with cost(startup) as (
  select round((
  21.39+
  current_setting('cpu_operator_cost')::real*1339+
  current_setting('cpu_tuple_cost')::real*1339+
  0.00
  )::numeric, 2)
  )
#+end_src

#+begin_src sql
  select startup,
  startup+round((
  4772.67+
  current_setting('cpu_operator_cost')::real*214867+
  current_setting('cpu_operator_cost')::real*214867*1339*
  0.150112+
  current_setting('cpu_tuple_cost')::real*16518865
  )::numeric, 2) as total
  from cost;
#+end_src

[[./images/wFQmaw.png]]

两次哈希连接

如果规划器的估算结果表明哈希表无法满足分配的内存，那么内部行集就会被分割成多个批次，分别处理。批次的数量（就像桶的
数量一样）总是 2 的幂次；使用的批次由散列键的相应位数决定。

任何两个匹配的记录都属于同一个批次：不同批次的记录不能有相同的哈希代码。

所有批次都持有相同数量的哈希键。如果数据分布均匀，批次大小也会大致相同。规划器可以通过选择适当数量的批次来控制内存
消耗。

在第一阶段，执行器会扫描内部行集，以建立哈希表。如果扫描到的行属于第一批，则将其添加到哈希表中并保存在 RAM 中。否
则，它将被写入一个临时文件（每个批次都有一个单独的文件）。

#+begin_comment
  会话在磁盘上可存储的临时文件总量受 temp_file_limit 参数限制（临时表不包括在此限制内）。一旦会话达到这个值，查
  询就会中止
#+end_comment

[[./images/VLYiI5.png]]

在第二阶段，对外部集合进行扫描。如果该行属于第一批，则与哈希表进行匹配，哈希表中包含内集的第一批行（反正其他批次的
行也不可能匹配）。

如果该行属于不同的批次，它将被存储在一个临时文件中，而该临时文件又是为每个批次单独创建的。因此，N 个批次可以使用
2(N - 1) 个文件（如果某些批次是空的，则使用的文件数会更少）。

第二阶段完成后，为哈希表分配的内存将被释放。此时，我们已经有了其中一个批次的连接结果。

[[./images/9CSqza.png]]

对于保存在磁盘上的每个批次，这两个阶段都要重复：内集的行从临时文件转移到哈希表；然后从另一个临时文件读取与同一批次
相关的外集的行，并与哈希表进行匹配。处理完成后，临时文件将被删除。

[[./images/qDncCu.png]]

与一阶段连接的类似输出不同，双程连接的 EXPLAIN 命令输出包含多个批次。如果使用 BUFFERS 选项运行，该命令还会显示磁
盘访问的统计数据：

#+begin_src sql
  explain (analyze, buffers, costs off, timing off, summary off)
  select *
  from bookings b
  join tickets t on b.book_ref=t.book_ref;
  
#+end_src

我已经在上文展示了增加 work_mem 设置后的查询。 默认值 4MB 太小，整个哈希表无法容纳在 RAM 中；在本例中，数据被
分成 64 个批次，哈希表使用 $$ 64K = 2^16 $$ 个桶。在建立哈希表时（哈希节点），数据会被写入临时文件
（temp written）；在连接阶段（哈希连接节点），临时文件会被读取和写入（temp read, written）。

要收集更多有关临时文件的统计数据，可以将 log_temp_files 参数设置为零。这样服务器日志就会列出所有临时文件及其大小
（如删除时的大小）。

动态调整

计划中的事件进程可能会受到两个问题的干扰：不准确的统计数据和不均匀的数据分布。

如果连接键列中的值分布不均匀，不同批次的大小就会不同。

如果某个批次（第一个批次除外）的数据量太大，就必须将其所有行写入磁盘，然后再从磁盘读取。最麻烦的是外层集，因为它通
常比较大。因此，如果外集的 MCVS 存在有规律的、非多变量统计（即外集由表代表，而连接由单列执行），则具有与 MCVS 相
对应的哈希代码的行将被视为第一批的一部分。这种技术（称为偏斜优化）可以在一定程度上减少两次连接的 I/O 开销。

由于这两个因素，部分（或全部）批次的大小可能会超出估计值。这样，相应的哈希表就无法容纳所分配的内存块，并会超出所定义
的限制。

因此，如果建立的哈希表过大，批次数量就会立即增加（翻倍）。每个批次实际上被分成两个新的批次：大约一半的行（假设分布均
匀）留在哈希表中，另一半保存到一个新的临时文件中。

即使最初计划的是一阶段连接，也可能发生这种分割。事实上，一阶段连接和两阶段连接使用的是同一种算法，由相同的代码实现；
我在这里将它们单独列出，只是为了叙述得更流畅。

批次数量不能减少。如果发现规划器高估了数据大小，批次将不会合并在一起。

在分布不均匀的情况下，增加批次数量可能无济于事。例如，如果键列的所有行中都包含一个相同的值，那么它们就会被放入同一
个批次，因为哈希函数会重复返回相同的值。不幸的是，在这种情况下，哈希表将继续增长，而不管施加了什么限制。

#+begin_comment
  理论上，这个问题可以通过多路连接来解决，多路连接会对批次执行部分扫描，但目前还不支持多路连接。
#+end_comment

为了证明批次数量的动态增加，我们首先要进行一些操作：

#+begin_src sql
  create table bookings_copy (like bookings including indexes)
  with (autovacuum_enable=off);
  insert into bookings_copy select * from bookings;
#+end_src

#+begin_src sql
  delete from bookings_copy where random()<0.9;
  analyze bookings_copy;
  insert into bookings_copy select * from bookings
  on conflict do nothing;
  select reltuples from pg_class where relname='bookings_copy';
#+end_src

结果，我们得到了一个名为 bookings_copy 的新表。它是预订表的精确副本，但规划器将其中的行数低估了 10 倍。如果哈希
表是为另一个连接操作产生的记录集生成的，因此没有可靠的统计数据，也会出现类似情况。

这一计算错误使规划器认为 8 个水桶就足够了，但在执行连接时，水桶数却增加到了 32 个：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select *
  from bookings_copy b
  join tickets t on b.book_ref=t.book_ref;
#+end_src

*代价估算。* 我已经用这个示例演示了一次连接的成本估算，但现在我要将可用内存的大小减小到最小，因此规划器将不得不使
用两个批次。这会增加连接的成本：

#+begin_src sql
  set work_mem='64KB';
  explain (analyze, timing off, summary off)
  select * from flights f
  join seats s on s.aircraft_code=f.aircraft_code;
  reset work_mem;
#+end_src

第二遍的成本来自于将数据行溢出到临时文件中，以及从这些文件中读取数据行。

两次连接的启动成本是以一次连接的启动成本为基础，再加上为存储内集所有行的所有必要字段而写入尽可能多页面的估计成本。
虽然在建立哈希表时，第一批数据并没有写入磁盘，但估算时并没有将其考虑在内，因此并不取决于批次的数量。

总成本则包括一次连接的总成本、读取先前存储在磁盘上的内集记录的估计成本，以及读取和写入外集记录的估计成本。

写入和读取均按每页 seq_page_cost 估算，因为 I/O 操作被假定为顺序操作。

在这种特殊情况下，内层数据集所需的页数估计为 7 页，而外层数据集的数据预计可容纳 2309 页。将这些估计值与上面计算
的单程连接成本相加后，我们得到了与查询计划中显示的相同的数字：

#+begin_src sql
  select 38.13 + -- startup cost of a one-pass join
  current_setting('seq_page_cost')::real*7
  as startup,
  278597.28+ -- total cost of a one-pass join
  current_setting('seq_page_cost')::real*2*(7+2309)
  as total;
#+end_src

因此，如果内存不足，连接会分两次进行，效率就会降低。因此，必须注意以下几点：

+ 查询的组成方式必须排除哈希表中的冗余字段。
+ 规划器在建立哈希表时，必须选择两组行中较小的一组。

在并行计划中使用哈希连接

上述散列连接算法也可用于并行计划。首先，几个并行进程为内集建立各自的（绝对相同的）哈希表，互不影响；然后，它们开始
并发处理外集。这里的性能提升是由于每个进程只扫描自己的外层行。

下面的计划使用常规的一阶段哈希连接：

#+begin_src sql
  set work_mem='128MB';
  set enable_parallel_hash=off;
  explain (analyze, costs off, timing off, summary off)
  select count(*)
  from bookings b
  join tickets t on t.book_ref=b.book_ref;
  reset enable_parallel_hash;
#+end_src

在这里，每个进程对bookings表进行散列，然后通过Parallel Index Only Scan节点检索自己的外层行份额，并将这
些行与生成的散列表进行匹配。

哈希表内存限制分别适用于每个并行进程，因此为此目的分配的内存总大小将比计划（内存使用情况）中显示的大三倍。

并行一阶段哈希连接

尽管普通的哈希连接在并行计划中效率很高（尤其是对于小型内集，并行处理对其意义不大），但大型数据集最好使用特殊的并行
哈希连接算法来处理。

并行版算法的一个重要区别是，哈希表是在共享内存中创建的，共享内存是动态分配的，所有参与连接操作的并行进程都可以访问。
使用所有参与进程的专用内存总量，而不是多个单独的哈希表，建立了一个单一的公共哈希表。这增加了一次性完成连接的机会。

在第一阶段（在计划中由Parallel Hash节点表示），所有并行进程利用并行访问内集的优势，建立一个共同的散列表。

[[./images/IKaSna.png]]

要继续前进，每个并行进程都必须完成其在第一阶段的处理份额。

在第二阶段（Parallel Hash Join节点），进程再次并行运行，将其在外集行中所占的份额与此时已经建立的散列表进行匹配

[[./images/d0ylLZ.png]]

下面就是这样一个计划的例子：

#+begin_src sql
  set work_mem='64MB';
  explain (analyze, costs off, timing off, summary off)
  select count(*)
  from bookings b
  join tickets t on t.book_ref=b.book_ref;
  reset work_meme;
#+end_src

这与我在上一节中展示的查询相同，但当时使用 enable_parallel_hash 参数关闭了并行散列连接。

虽然与之前演示的普通散列连接相比，可用内存减少了一半，但由于使用的是为所有并行进程分配的内存（Memory Usage），因此
操作仍能一次性完成。哈希表变大了一些，但由于现在只有一个哈希表，所以总内存使用量有所减少。


并行二阶段哈希连接

所有并行进程的合并内存可能仍然不足以容纳整个哈希表。这一点在规划阶段或之后的查询执行过程中都会很明显。在这种情况下
采用的两阶段算法与我们迄今为止看到的算法截然不同。

这种算法的主要区别在于，它创建的是多个较小的哈希表，而不是一个大表。每个进程都有自己的表，并独立处理自己的批次。(但
由于独立的哈希表仍位于共享内存中，因此任何进程都可以访问这些表中的任何一个）。如果计划显示需要不止一个批次，则会立即
为每个进程建立一个单独的哈希表。如果在执行阶段做出决定，则会重建哈希表。

因此，在第一阶段，进程会并行扫描内集，将其分成多个批次并写入临时文件。由于每个进程只读取自己在内集中的份额，因此它们
都不会为任何批次（即使是第一个批次）建立完整的哈希表。只有所有并行进程以同步方式写入的文件中才会累积任何批次的全行
集。因此，与该算法的非并行版和一阶段并行版不同，并行二阶段哈希连接会将所有批次（包括第一个批次）写入磁盘。

[[./images/GEVCXk.png]]

所有进程完成内集散列后，第二阶段开始。

如果采用非并行版算法，外集中属于第一批的行会立即与哈希表进行匹配。但在并行版本中，内存中还不包含哈希表，因此工作进
程会独立处理批次。因此，第二阶段首先对外部集进行并行扫描，将其行分成若干批次，每批写入一个单独的临时文件。扫描的行
不会插入哈希表（如第一阶段一样），因此批次的数量永远不会增加。

如果采用非并行版算法，外集中属于第一批的行会立即与哈希表进行匹配。但在并行版本中，内存中还不包含哈希表，因此工作进
程会独立处理批次。因此，第二阶段首先对外部集进行并行扫描，将其行分成若干批次，每批写入一个单独的临时文件。扫描的行
不会插入哈希表（如第一阶段一样），因此批次的数量永远不会增加。

一旦所有进程都完成了对外部数据集的扫描，我们就会在磁盘上得到 2N 个临时文件，其中包含内外部数据集的批次。

[[./images/dCJJyU.png]]

然后，每个进程选择其中一个批次并执行连接：将内层数据集的行加载到内存中的哈希表中，扫描外层数据集的行，并与哈希表进
行匹配。当批次连接完成后，进程会选择下一个尚未处理的批次。

[[./images/yIi0Im.png]]

如果没有未处理的批次了，完成自己批次的进程就会开始处理另一个进程正在处理的批次；由于所有哈希表都位于共享内存中，因此
这种并发处理是可能的。

[[./images/AO8301.png]]

这种方法比为所有进程使用一个大散列表更有效：更容易设置并行处理，同步也更便宜。

修改

哈希连接算法支持任何类型的连接：除了内连接，它还可以处理左连接、右连接和全外连接，以及半连接和反连接。但如前所述，
连接条件仅限于相等运算符。

在处理嵌套循环连接时，我们已经观察到了其中的一些操作。下面是右外部连接的示例：

#+begin_src sql
  explain (costs off) select *
  from bookings b
  left outer join tickets t on t.book_ref=b.book_ref;
#+end_src

请注意，SQL 查询中指定的逻辑左连接已在执行计划中转化为右连接的物理操作。

在逻辑层面上，预订表是外层表（构成连接操作的左侧），而机票表是内层表。因此，连接结果中也必须包括没有门票的预订表。

在物理层面上，内集和外集的分配是基于连接的成本，而不是它们在查询文本中的位置。这通常意味着，哈希表较小的集合将被用
作内集合。这里的情况正是如此：预订表被用作内集，左连接被改为右连接。

反之亦然，如果查询指定了右外部连接（显示与任何预订无关的机票），则执行计划使用左连接：

#+begin_src sql
  explain (costs off) select *
  from bookings b
  right outer join tickets t on t.book_ref=b.book_ref;
#+end_src

为了更全面地了解情况，我将提供一个使用完全外连接的查询计划示例：

#+begin_src sql
  explain (costs off) select *
  from bookings b
  full outer join tickets t on t.book_ref=b.book_ref;
#+end_src

并行哈希连接目前不支持右连接和全连接。

请注意，下一个示例使用预订表作为外层集，但如果支持右连接，规划器会更喜欢右连接：

#+begin_src sql
  explain (costs off) select sum(b.total_amount)
  from bookings b
  left outer join tickets t on t.book_ref=b.book_ref;
#+end_src

** 唯一值和分组

将值分组进行聚合并删除重复值的算法与连接算法非常相似。它们可以使用的方法之一是在所需列上建立一个哈希表。只有在哈希
表中还不包含此类值时，才会将这些值纳入哈希表。因此，哈希表会累积所有不同的值。

执行哈希聚合的节点称为 HashAggregate。

让我们来考虑一些可能需要这个节点的情况。

每个舱位的座位数（GROUP BY）：

#+begin_src sql
  explain (costs off) select fare_conditions, count(*)
  from seats
  group by fare_conditions;
#+end_src

旅行舱位列表 (DISTINCT)：

#+begin_src sql
  explain (costs off) select distinct fare_condintions
  from seats;
#+end_src

旅行类别与另一个值（UNION）相结合：

#+begin_src sql
  explain (costs off) select fare_conditions
  from seats
  union
  select null;
#+end_src

Append 节点会合并两个集合，但不会删除任何重复数据，因为这些重复数据一定不会出现在 UNION 结果中。它们必须由
HashAggregate 节点单独删除。

为散列表分配的内存块受 work_mem × hash_mem_multiplier 值的限制，就像散列连接一样。

如果哈希表适合分配的内存，则聚合使用单个批次：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select distinct amount from ticket_flights;
#+end_src

金额字段中没有那么多不同的值，因此哈希表只占用 61KB 内存。

一旦哈希表填满了分配的内存，所有其他的值都会溢出到临时文件中，并根据其哈希值的几个比特分成几个分区。分区的数量是 2
的幂次，选择时要确保每个分区的哈希表都符合分配的内存。当然，估算的准确性取决于收集到的统计数据的质量，因此接收到的数
字会乘以 1.5，以进一步缩小分区大小，提高一次性处理每个分区的机会。

扫描整个数据集后，节点会返回进入哈希表的值的聚合结果。

然后清空哈希表，对上一阶段保存到临时文件中的每个分区进行扫描，并像处理其他行集一样进行处理。如果哈希表仍然超出分配
的内存，则会再次对溢出的行进行分区，并写入磁盘进行进一步处理。

为了避免过多的 I/O，两次哈希连接算法会将 MCV 移入第一批。然而，聚合不需要这种优化：那些适合分配内存的行不会被分割
成分区，而且 MCV 很可能在足够早的时候出现，从而进入 RAM。

#+begin_src sql
  explain(analyze, costs off, timing off, summary off)
  select distinct flight_id from ticket_flights;
#+end_src

在本例中，不同 ID 的数量相对较多，因此哈希表无法满足分配的内存。执行查询需要五个批次：一个用于初始数据集，四个用于
写入磁盘的分区。

* 排序和归并

** 归并连接

合并连接处理按连接键排序的数据集，并返回以类似方式排序的结果。输入集可以在索引扫描后预先排序；否则，执行器必须在实际
合并开始前对它们进行排序。

合并排序集合

让我们来看一个合并连接的示例；在执行计划中，合并连接节点表示合并连接：

#+begin_src sql
  explain (costs off) select *
  from tickets t
  join ticket_flights tf on tf.ticket_no=ticket_no
  order by t.ticket_no;
#+end_src

优化器更喜欢这种连接方法，因为它返回的是由 ORDER BY 子句定义的排序结果。在选择计划时，优化器会注意数据集的排序顺
序，除非确实需要，否则不会执行任何排序。例如，如果合并连接产生的数据集已具有适当的排序顺序，则可在随后的合并连接中按
原样使用：

#+begin_src sql
  explain (costs off) select *
  from tickets t
  join ticket_flight tf on t.ticket_no=tf.ticket_no
  join boarding_passes bp on bp.ticket_no=tf.ticket_no
                             and bp.flight_id=tf.flight_id
  order by t.ticket_no;
#+end_src

首先要连接的表是 ticket_flights 和 boarding_passes；这两个表都有一个复合主键（ticket_no、flight_id），结果
按这两列排序。然后将生成的记录集与 ticket 表连接，后者按 ticket_no 列排序。

连接只需对两个数据集进行一次传递，不占用任何额外内存。它使用两个指针指向内部和外部数据集的当前行（最初是第一行）。

如果当前行的键不匹配，其中一个指针（引用键较小的一行）将前进到下一行，直到找到匹配为止。连接的行被返回到上节点，内部
集合的指针前进一位。该操作一直持续到其中一个集合结束为止。

这种算法可以处理内集的重复数据，但外集也可能包含重复数据。因此，必须改进算法：如果在外层指针前进后，键值保持不变，内
层指针就会回到第一个匹配行。这样，外集的每一行都将与内集所有具有相同键的行匹配。

对于外部连接，算法做了一些调整，但仍基于相同的原理。

合并连接条件只能使用相等运算符，这意味着只支持相等连接（尽管目前也在支持其他条件类型）。

*代价估算。* 让我们仔细看看前面的例子：

#+begin_src sql
  explain select *
  from tickets t
  join ticket_flights tf on tf.ticket_no=t.ticket_no
  order by t.ticket_no;
#+end_src

连接的启动成本至少包括所有子节点的启动成本。

一般来说，在找到第一个匹配之前，可能需要扫描外集或内集的一部分。可以通过比较（基于直方图）两个集合中最小的连接键来
估计这一部分。但在这种特殊情况下，两个表中的票号范围是相同的。

总成本包括从子节点获取数据的成本和计算成本。

由于一旦其中一个集合结束，连接算法就会停止（当然，除非执行外部连接），因此另一个集合可能只扫描了一部分。为了估算扫描
部分的大小，我们可以比较两个集合中的最大键值。在本例中，两个集合都将被全部读取，因此连接的总成本包括两个子节点的总成
本之和。

此外，如果存在重复数据，内集的某些行可能会被扫描多次。重复扫描的估计次数等于连接结果和内集的Cardinality值之差。
在本查询中，这些Cardinality是相同的，这意味着这两个集合不包含重复行。

该算法会比较两个数据集的连接键。一次比较的成本按 cpu_operator_cost 值估算，而估计的比较次数可视为两个集合的行数
总和（增加了重复读取的次数）。与往常一样，结果中包含的每一行的处理成本都是按照 cpu_tuple_cost 值估算的。

因此，在本例中，连接的成本估算如下：

#+begin_src sql
  select 0.43+0.56 as startup,
  round((
  139110.29+570972.46+
  current_setting('cpu_tuple_cost')::real*8391852+
  current_setting('cpu_operator_cost')::real*(2949857+8391852)
  )::numeric, 2) as total;
#+end_src

并行模式

虽然合并连接不具有并行性，但仍可用于并行计划中。

外集可以由多个工作者并行扫描，但内集始终由每个工作者完整扫描。

由于并行哈希连接几乎总是更便宜，我将暂时关闭它

#+begin_src sql
  set enable_hashjoin=off;
#+end_src

下面是一个使用合并连接的并行计划示例：

#+begin_src sql
  explain (costs off)
  select count(*), sum(tf.amount)
  from tickets t
  join ticket_flights tf on tf.ticket_no=t.ticet_no;
#+end_src

并行计划中不允许全连接和右外层合并连接。

修改

合并连接算法可用于任何类型的连接。唯一的限制是全连接和右外部连接的连接条件必须包含与合并兼容的表达式（"outer-column
equals inner-column "或 "column equals constant"）。

下面是一个使用合并算法的全连接示例：

#+begin_src sql
  explain (costs off) select *
  from tickets t
  full join ticket_flights on tf.ticket_no=t.ticket_no
  order by t.ticket_no;
#+end_src

内连接和左合并连接可以保持排序顺序。然而，全连接和右外连接则不能保证排序顺序，因为 NULL 值可能被夹在外集的有序值之
间，从而破坏排序顺序。为了恢复所需的顺序，规划器在这里引入了Sort节点。当然，这会增加计划的成本，使散列连接更有吸
引力，所以计划器选择这个计划只是因为散列连接目前是禁用的。

但是，下一个示例却离不开散列连接：嵌套循环根本不允许完全连接，而由于不支持连接条件，因此无法使用合并。因此，无论参数
enable_hashjoin 的值如何，都要使用哈希连接：

#+begin_src sql
  explain (costs off) select *
  from tickets t
  full join ticket_flights tf on tf.ticket_no=t.ticket_no
                              and tf.amount>0
  order by t.ticket_no;
#+end_src

让我们恢复之前禁用的哈希连接功能：

#+begin_src sql
  reset enable_hashjoin;
#+end_src

** 排序
如果其中一个集合（也可能是两个集合）没有按连接键排序，则必须在连接操作开始前重新排序。这种排序操作在计划中由Sort
节点表示：

#+begin_src sql
  explain (costs off)
  select * from flights f
  join airports_data dep on f.depatrue_airport=dep.airports_code
  order by dep.airport_code;
#+end_src

如果在常规查询和窗口函数中指定 ORDER BY 子句，这种排序也可以在连接之外使用：

#+begin_src sql
  explain (costs off)
  select flight_id,
  row_number() over (partition by flight_no order by flight_id)
  from flights f;
#+end_src

在这里，WindowAgg 节点对Sort节点预先排序过的数据集计算窗口函数。

规划器的工具箱中有多种排序方法。我已经展示的示例使用了其中的两种（排序方法）。这些详细信息可以像往常一样通过
EXPLAIN ANALYZE 命令显示出来：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from flights f
  join airports_data dep on f.departure_aiport=dep.airport_code
  order by dep.airport_code;
#+end_src

快速排序

如果要排序的数据集符合 work_mem 块的大小，就会使用经典的 quicksort 方法。这种算法在所有教科书中都有介绍，我就
不在这里解释了。

至于执行，排序由一个专用组件执行，该组件根据可用内存量和其他一些因素选择最合适的算法。

*代价估算。* 让我们来看看一个小表是如何排序的。在这种情况下，使用 quicksort 算法在内存中进行排序：

#+begin_src sql
  explain select *
  from airports_data
  order by airport_code;
#+end_src

众所周知，对 n 个值进行排序的计算复杂度为 O(nlog2n)。单次比较操作的估算值是 cpu_operator_cost 的两倍。由于
在检索结果之前，必须对整个数据集进行扫描和排序，因此排序的启动成本包括子节点的总成本和所有比较操作的费用。

排序的总成本还包括处理要返回的每一行的成本，该成本按 cpu_operator_cost 估算（而不是通常的 cpu_tuple_cost 值，
因为Sort节点产生的开销微不足道）。

在本例中，代价计算如下：

#+begin_src sql
  with costs(startup) as (
  select 4.04+round((
  current_setting('cpu_operator_cost')::real*2*
  104*log(2, 104)
  )::numeric, 2)
  )
  select startup,
  startup+round((
  current_setting('cpu_operator_cost')::real*104
  )::numeric, 2) as total
  from costs;
#+end_src

Top-N堆排序

如果数据集只需要部分排序（由 LIMIT 子句定义），则可以使用堆排序方法（在计划中表示为 top-N 堆排序）。更确切地说，
如果排序至少减少了一半的行数，或者分配的内存无法容纳整个输入集（而输出集却能容纳），就可以使用这种算法。

#+begin_src sql
  explain (analyze, timing off, summary off)
  select * from seats
  order by seat_no limit 100;
#+end_src

为了从 n 个值中找出 k 个最高（或最低）值，执行器会将前 k 行添加到一个名为堆的数据结构中。然后逐一添加其余的行，每
次迭代后都会从堆中删除最小（或最大）的值。处理完所有行后，堆中就会包含 k 个所需值。

#+begin_comment
  这里的 "堆 "指的是一种众所周知的数据结构，与通常同名的数据库表无关。
#+end_comment

*代价估算。* 该算法的计算复杂度估计为 O(n log2 k)，但与 quicksort 算法相比，每个特定操作的成本都更高。因此，公
式使用 $ nlog_{2}2K $

#+begin_src sql
  with costs(startup)
  as (
    select 21.39+round((
      current_setting('cpu_operator_cost')::real*2*
        1339*log(2,2*100)
    )::numeric,2)
  )
  select startup,
    startup+round((
      current_setting('cpu_operator_cost')::real*100
  )::numeric,2) as total
  from costs;
#+end_src

外部排序

如果扫描结果显示数据集过大，无法在内存中排序，排序节点就会切换到外部合并排序（在计划中标记为外部合并）。

已经扫描过的行在内存中通过 quicksort（快速排序） 算法进行排序，并写入临时文件。

[[./images/tCJmSE.png]]

然后将随后的行读入释放的内存，如此反复，直到将所有数据写入几个预先排序的文件。

[[./images/fco5bk.png]]

然后，这些文件被合并成一个文件。这一操作的算法与合并连接的算法大致相同，主要区别在于它可以同时处理两个以上的文件。

合并操作不需要太多内存。事实上，每个文件只需容纳一条记录就足够了。从每个文件中读取第一行，值最小的一行（或值最大的
一行，取决于排序顺序）作为部分结果返回，腾出的内存将填充从同一文件中获取的下一行。

在实际操作中，行是以 32 页为一批次读取的，而不是逐条读取，这就减少了 I/O 操作的次数。单次迭代中合并的文件数量取决
于可用内存，但绝不会少于 6 个。由于文件过多会影响效率，因此上限也有限制（500）。

#+begin_comment
  排序算法的术语由来已久。外部排序最初是使用磁带进行的，PostgreSQL 也为控制临时文件的组件保留了类似的名称。部分排
  序的数据集称为 "运行"。参与合并的运行数称为 "合并顺序"。我没有使用这些术语，但如果你想理解 PostgreSQL 代码和注
  释，它们还是值得了解的。
#+end_comment

如果排序后的临时文件无法一次性合并，就必须分几次处理，并将部分结果写入新的临时文件。每次迭代都会增加需要读写的数据
量，因此可用内存越多，完成外部排序的速度就越快。

[[./images/lTdHu1.png]]

下一次迭代将合并新创建的临时文件。

[[./images/UKZJ5N.png]]

最后的合并通常会推迟，在上层节点提取数据时即时执行。

让我们运行 EXPLAIN ANALYZE 命令，看看外部排序占用了多少磁盘空间。BUFFERS 选项显示临时文件（临时读取和写入）的
缓冲区使用统计。写入缓冲区的数量（大致）与读取缓冲区的数量相同；转换成千字节后，该值在计划中显示为 Disk：

#+begin_src sql
  explain (analyze, buffers, costs off, timing off, summary off)
  select * from flights
  order by scheduled_departure;
#+end_src

要在服务器日志中打印使用临时文件的更多详细信息，可以启用 log_temp_files 参数。

*代价估算* 让我们以同一计划的外部排序为例：

#+begin_src sql
  explain select *
  from flights
  order by scheduled_departure;
#+end_src

在这里，比较的常规成本（其数量与内存中的快速排序操作相同）由 I/O 成本扩展而来。 所有输入数据必须先写入磁盘上的临时
文件，然后在合并操作过程中从磁盘读取（如果一次迭代无法合并所有创建的文件，则可能需要多次读取）。

假设四分之三的磁盘操作（包括读取和写入）是顺序操作，四分之一是随机操作。

写入磁盘的数据量取决于要排序的行数和查询中使用的列数。在本例中，查询显示了航班表的所有列，因此如果不考虑元组和页元
数据，写入磁盘的数据量几乎与整个表的数据量相同（2309 页，而不是 2624 页）。

在这里，排序一次完成。

因此，本计划对排序成本的估算如下：

#+begin_src sql
  with costs(startup) as (
  select 4772.67+round((
    current_setting('cpu_operator_cost')::real*2*214867*log(2, 214867)+
    (current_setting('seq_page_cost')::real*0.75+current_setting('random_page_cost')::real*0.25)
    ,*2*2309*1 -- one iteraton
  
  )::numeric, 2)
  )
  select startup,
    startup+round((
    current_setting('cpu_operator_cost')::real*214867
    )::numeric, 2) as total
  from costs;
#+end_src

增量排序

如果数据集必须按照键 $ K_{1} ... ... K_{m} ... K_{m} $，而已知该数据集已按前 m 个键排序，则不必从头开始重新
排序。取而代之的是，可以用相同的前键 $ K_{1} ... K_{m} $ 将数据集分成若干组（这些组中的值已经排序过）。$K_{m}$
（这些组中的值已经按照定义的顺序排列），然后按照剩余的 $K_{m+1} ... $ 分别对这些组进行排序。$ K_{n} $键进行排
序。这种方法称为增量排序。

与其他排序算法相比，增量排序占用的内存较少，因为它会将数据集分成几个较小的组，此外，它还允许执行器在处理完第一组后
开始返回结果，而无需等待整个数据集排序完毕。

在 PostgreSQL 中，实现方式要更微妙一些：相对较大的记录组会单独处理，而较小的记录组则会合并在一起并进行全面排序。
这减少了调用排序程序所产生的开销。

执行计划通过Incremental Sort节点表示增量排序：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from bookings
  order by total_amount, book_date;
#+end_src

如计划所示，数据集是按 total_amount 字段预排序的，因为它是在该列（预排序键）上运行索引扫描的结果。EXPLAIN
ANALYZE 命令还会显示运行时统计信息。Full-sort Groups（全排序组）行与统一进行全排序的小型组有关，而 Presorted
Groups（预排序组）行显示的是具有部分排序数据的大型组的数据，这些数据只需要通过 book_date 列进行增量排序。在这两
种情况下，都采用了内存中快速排序方法。组大小的差异是由于预订费用分布不均匀造成的。

增量排序也可用于计算窗口函数

#+begin_src sql
  explain (costs off)
  select row_number() over (order by total_amount, book_date)
  from bookings;
#+end_src

*代价估算* 增量排序的成本计算基于预期的组数和平均规模组的估计排序成本（我们已经审查过）。

启动成本反映的是对第一组进行排序的成本估算，它允许节点开始返回已排序的行；总成本包括所有组的排序成本。

在此，我们不打算进一步探讨这些计算。

并行模式

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select *
  from flights
  order by scheduled_departure
  limit 10;
#+end_src

Gather Merge节点使用二进制堆来调整多个工作进程获取的行的顺序。它实际上是合并几组已排序的行，就像外部排序一样，但
设计用途不同： Gather Merge 通常处理固定数量的少量数据源，并逐条而不是逐块获取记录。

*代价估算* Gather Merge 节点的启动成本基于其子节点的启动成本。与 "收集 "节点的启动成本一样，该值也会因并行进程
的启动成本（按 parallel_setup_cost 估算）而增加。

然后，建立二进制堆的成本（需要对 n 个值进行排序，其中 n 是并行工作者的数量（即 $ n log_{2}n $））进一步扩展了
接收值。单次比较操作的 cpu_operator_cost 估计为两倍，由于 n 非常小，因此此类操作的总份额通常可以忽略不计。

总成本包括执行计划并行部分的多个进程获取所有数据所产生的费用，以及将这些数据传输给领导者的成本。单行数据传输的估计
成本为 parallel_tuple_cost 增加 5%，以补偿获取下一个值时可能出现的等待。

在计算总成本时，还必须考虑二进制堆更新所产生的费用：每个输入行需要 $ log_{2}n $ 次比较操作和某些附加操作（按
cpu_operator_cost 估算）。

我们再来看看另一个使用 "Gather Merge "节点的计划。请注意，这里的工作进程首先通过散列执行部分聚合，然后Sort节点
对收到的结果进行排序（排序成本低，因为聚合后剩下的行数很少），再将结果传递给领导进程，由领导进程在 "Gather Merge"
节点中收集全部结果。至于最后的聚合，则是在已排序的值列表上进行的：

#+begin_src sql
  explain select amount, count(*)
  from ticket_flights
  group by amount;
#+end_src

在这里，我们有三个并行进程（包括领导进程），"Gather Merge"节点的成本计算如下：

#+begin_src sql
  with costs(startup, run) as (
    select round((
    -- launching process
    current_setting('parallel_setup_cost')::real+
    -- building the heap
    current_setting('cpu_operator_cost')::real*2*3*log(2,3)
  )::numeric, 2),
  round((
    -- passing row
    current_setting('parallel_tuple_cost')::real*1.05*674+
    -- updating the heap
    current_setting('cpu_operator_cost')::real*2*674*log(2,3)+
    current_setting('cpu_operator_cost')::real*674
  )::numeric, 2)
  )
  select 122399.59+startup as startup,
    122400.44+startup+run as total
  from costs;
#+end_src

** 唯一值和分组

正如我们刚才看到的，不仅可以通过散列，还可以通过排序对值进行分组以执行聚合（以及消除重复值）。在排序后的列表中，重
复值组可以一次性剔除。

从排序列表中检索不同的值在计划中由一个名为 Unique 的非常简单的节点表示：

#+begin_src sql
  explain (costs off) select distinct book_ref
  from bookings
  order by book_ref;
#+end_src

聚合在 GroupAggregate 节点中进行：

#+begin_src sql
  explain (costs off) select book_ref, count(*)
  from bookings
  group by book_ref
  order by book_ref
#+end_src

在并行计划中，该节点称为 "Partial GroupAggregate"，而完成聚合的节点称为 "Finalize GroupAggregate"。

如果按多个列集（在 GROUPING SETS、CUBE 或 ROLLUP 子句中指定）进行分组，则散列和排序策略可以在单个节点中结合使
用。在此，我不再赘述这一算法的复杂细节，我将简单举例说明在内存不足的情况下，如何对三个不同的列进行分组：

#+begin_src sql
  set work_mem='64kB';
  explain (costs off) select count(*)
  from flights
  group by grouping sets (aircraft_code, flight_no, departure_airport);
  reset work_mem;
#+end_src

下面是执行该查询时发生的情况。聚合节点（在计划中显示为 MixedAggregate）接收按 aircraft_code 列排序的数据集。

首先，对该集合进行扫描，然后按aircraft_code列（组键）对值进行分组。随着扫描的进行，这些行会按 flight_no 列重
新排序（就像普通排序节点所做的那样：如果内存足够，可以通过 quicksort 方法，或者使用磁盘上的外部排序）；同时，执行
器会将这些行放入一个以 departure_airport 作为键的哈希表（就像哈希聚合所做的那样：可以在内存中，也可以使用临时文
件）。

在第二阶段，执行器会扫描刚刚按 flight_no 列排序的数据集，并按同一列（排序键和嵌套的组键节点）对值进行分组。如果需
要按另一列对行进行分组，则将根据需要再次进行排序。

最后，扫描第一阶段编制的哈希表，并按照 departure_airport 列（哈希键）对值进行分组。


** join方法的比较

正如我们所看到的，可以使用三种不同的方法来连接两个数据集，而每种方法都各有利弊。

嵌套循环连接没有任何先决条件，可以立即开始返回结果集的第一行。它是唯一一种无需完全扫描内集的连接方法（只要索引访问
可用）。这些特性使得嵌套循环算法（与索引相结合）成为处理较小行集的简短 OLTP 查询的理想选择。

随着数据量的增加，嵌套循环的弱点就显现出来了。对于笛卡尔积，该算法的复杂度为二次方--成本与被连接数据集的大小乘积成
正比。然而，笛卡尔积在实际应用中并不常见；对于外集的每一行，执行者通常会使用索引访问内集的一定数量的行，而这一平均
数量并不取决于数据集的总大小（例如，订票中机票的平均数量不会随着订票和购票数量的增长而变化）。因此，嵌套循环算法的
复杂度通常是线性增长而不是二次方增长，即使线性系数很高。

嵌套循环算法的一个重要特点是它的普遍适用性：它支持所有连接条件，而其他方法只能处理等连接。它允许使用任何类型的条件
运行查询（完全连接除外，嵌套循环不能使用完全连接），但必须记住，大型数据集的非等连接执行速度很可能比预期的慢。

哈希连接最适合大型数据集。如果 RAM 足够大，它只需要对两个数据集进行一次传递，因此其复杂性是线性的。这种算法与顺序
表扫描相结合，通常用于 OLAP 查询，这种查询根据大量数据计算结果。

但是，如果响应时间比吞吐量更重要，散列连接就不是最佳选择：在整个散列表建立之前，散列连接不会开始返回结果行。

散列连接算法只适用于等价连接。另一个限制是，连接键的数据类型必须支持散列（但几乎所有数据类型都支持）。

嵌套循环连接有时可以击败散列连接，因为它可以利用 Memoize 节点（也是基于散列表）中缓存内集行的优势。哈希连接总是会
完整地扫描内集，而嵌套循环算法则不需要，这可能会降低一些成本。

合并连接可以完美地处理短的 OLTP 查询和长的 OLAP 查询。它具有线性复杂性（只需对要连接的数据集扫描一次），不需要太
多内存，并且无需任何预处理即可返回结果；但是，数据集必须已经具有所需的排序顺序。成本效益最高的方法是通过索引扫描获
取数据。如果行数较少，这自然是个不错的选择；对于较大的数据集，索引扫描仍然很高效，但前提是堆访问量很小或根本不会发
生堆访问。

如果没有合适的索引，则必须对集合进行排序，但这一操作需要大量内存，其复杂度高于线性： $O(nlog_{2}n)$。在这种情况
下，哈希连接几乎总是比合并连接代价更低--除非结果必须排序。

合并连接的一个额外优势是内外集的等价性。嵌套循环和散列连接的效率在很大程度上取决于规划器能否正确分配内集和外集。

合并连接仅限于等连接。此外，数据类型必须有一个 B 树操作符类。

下图说明了各种连接方法的成本与需要连接的行数之间的近似关系。

[[./images/alUSTi.png]]

如果选择性很高，嵌套循环连接会对两张表使用索引访问；然后，规划器会切换到对外表的全扫描，这反映在图的线性部分。

在这里，哈希连接对两个表都进行了全扫描。图中的 "一步 "对应的是哈希表填满整个内存，批次开始溢出到磁盘的时刻。

如果使用索引扫描，合并连接的成本会出现小幅线性增长。如果 work_mem 的大小足够大，哈希连接通常会更有效，但在临时文
件方面，合并连接会更胜一筹。

排序-合并连接的上图显示，当索引不可用且数据必须排序时，成本会上升。与哈希连接的情况一样，图中的 "台阶 "是由于内存
不足造成的，因为它导致使用临时文件进行排序。

这只是一个例子，在每个具体情况下，代价之间的比例都会不同。


* HASH索引
** 概览
散列索引提供了通过特定索引键快速查找元组ID(TID)的能力。粗略地说，它只是一个存储在磁盘上的哈希表。散列索引所支持的
唯一操作是通过平等条件进行搜索。

当一个值被插入到一个索引中时，索引键的哈希函数被计算出来。在PostgreSQL中，哈希函数返回32位或64位的整数；这
些值的几个最低位被用作相应的桶的编号。键的TID和哈希代码被添加到选择的桶中。密钥本身并不存储在索引中，因为处理小的
固定长度的值更方便。

一个索引的哈希表是动态扩展的。集群的最小数量是两个。随着索引元组数量的增加，其中一个桶会被拆成两个。这个操作多用了一
个哈希代码的位，所以元素只在分割后的两个桶之间重新分配；哈希表的其他桶的组成保持不变。

索引搜索操作会计算索引键的哈希函数和相应的桶号。在所有桶的内容中，搜索将只返回那些与键的哈希代码相对应的TID。由于
桶中的元素是按键的哈希代码排序的，二进制搜索可以相当有效地返回匹配的TID。

由于键没有存储在哈希表中，索引访问方法可能因为哈希碰撞而返回多余的TID。因此，索引引擎必须重新检查由访问方法获取的
所有结果。由于同样的原因，不支持仅有索引的扫描。
** 页面布局

与普通的哈希表不同，哈希索引是存储在磁盘上的。因此，所有的数据必须被排列成页，最好是使索引操作（搜索、插入、删除）需
要访问尽可能少的页。

一个哈希索引有以下四种页面

+ 元页－提供索引的目录
+ 桶页－索引的主要页面
+ 溢出页－当前主桶页不能容纳所有的元素时使用的附加页
+ 位图页－包含位数组的页，用于跟踪已经释放并可重复使用的溢出页

可以使用pageinspect扩展来查看索引页面

创建一个空的表

#+begin_src sql
  create extension pageinspect;
  create table t(n integer);
  analyze t;
  create index on t using hash(n);
#+end_src

对表进行了分析，所以创建的索引将具有尽可能小的尺寸；否则，将根据表包含10个页面的假设来选择桶的数量。索引包含四
个页面：元页面、两个桶页面和一个位图页面（一次性创建，供将来使用）：

#+begin_src sql
  select page, hash_page_type(get_raw_page('t_n_idx', page))
  from generate_series(0, 3) page;
#+end_src

[[./images/hySCnE.png]]

元页包含所有关于索引的控制信息。我们目前只对几个值感兴趣：

#+begin_src sql
  select ntuples, ffactor, maxbucket
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

每个桶的估计行数显示在ffactor字段。这个值是根据块的大小和fillfactor存储参数值计算的。通过绝对均匀的数据分布
和没有哈希碰撞，你可以使用一个更高的fillfactor值，但在现实生活中的数据库，它增加了页面溢出的风险。

对于散列索引来说，最糟糕的情况是数据分布有很大的偏斜，当一个键重复多次时。由于散列函数将返回一个相同的值，所有的数据
都将被放入同一个桶中，增加桶的数量将无济于事。

现在索引是空的，如ntuples字段所示。让我们通过插入多条具有相同索引键值的行来引起一个桶状页溢出。一个溢出的页面出
现在索引中：


#+begin_src sql
  insert into t(n)
  select 0 from generate_series(1, 500);
  select page, hash_page_type(get_raw_page('t_n_idx', page))
  from generate_series(0, 4) page;
#+end_src

[[./images/RSwyo0.png]]

对所有页面的综合统计显示，桶0是空的，而所有的值都被放入桶1：其中一些位于主页面，而那些不适合它的值可以在溢出页面
找到。

#+begin_src sql
  select page, live_items, free_size, hasho_bucket
  from (values (1), (2), (4)) p(page),
  hash_page_stats(get_raw_page('t_n_idx', page));
#+end_src

很明显，如果一个相同的桶的元素分布在几个页面上，性能会受到影响。如果数据分布均匀，散列索引显示出最好的结果。

现在让我们来看看一个桶是如何被分割的。当索引中的行数超过可用桶的估计ffactor值时，它就会发生。这里我们有两个桶，
ffactor是307，所以当第615行被插入到索引中时，它就会发生：

#+begin_src sql
  select ntuples, ffactor, maxbucket, ovflpoint
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
  insert into t(n)
  select n from generate_series(1, 115) n;
  select nutples, ffactor, maxbucket, ovflpoint
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

最大bucket值已经增加到两个：现在我们有三个bucket，编号从0到2。 但是，尽管我们只增加了一个bucket，页面
的数量却增加了一倍：

#+begin_src sql
  select page, hash_page_type(get_raw_page('t_n_idx', page))
  from generate_series(0, 6) page;
#+end_src

[[./images/tNA8od.png]]

其中一个新页面被桶2使用，而另一个保持空闲，一旦出现就会被桶3使用。



#+begin_src sql
  select page, live_items, free_size, hasho_bucket
  from (values(1), (2), (4), (5)) p(page),
  hash_page_stats(get_raw_page('t_n_idx', page));
#+end_src

因此，从操作系统的角度来看，哈希指数是呈井喷式增长的，尽管从逻辑的角度来看，哈希表显示的是逐步增长。

为了在一定程度上平衡这种增长，并避免一次分配太多的页面，从第十次增加开始，页面将分四批平均分配，而不是一次全部分配。

元页的另外两个字段，实际上是位掩码，提供了关于bucket地址的细节：

#+begin_src sql
  select maxbucket, highmask::bit(4), lowmask::bit(4)
  from hash_metapage_info(get_raw_page('t_n_idx' , 0));
#+end_src

一个桶号是由对应于高掩码的哈希码位定义的。但如果收到的桶号不存在（超过了maxbucket），就会取低掩码位。1 在这种特
殊情况下，我们取两个最低位，这样就有了0到3的值；但如果我们得到3，我们就只取一个最低位，也就是用桶1而不是
桶3。

每次大小翻倍时，新的bucket页被分配为一个连续的chunk，而溢出页和位图页根据需要被插入这些片段之间。元页在备用数
组中保留了插入每个块的页数，这让我们有机会根据桶的数量用简单的算术来计算其主页的数量。

在这个特殊的案例中，第一次增加后插入了两个页面（一个位图页和一个溢出页），但第二次增加后还没有发生新的增加：

#+begin_src sql
  select spares[2], spares[3]
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

元页还存储了一个指向位图页的指针数组：

#+begin_src sql
  select mapp[1]
  from hash_metapage_info(get_raw_page('t_n_idx', 0));
#+end_src

[[./images/xr92tr.png]]

当指向死元组的指针被移除时，索引页内的空间被释放出来。这发生在修剪页面的过程中（这是由试图将一个元素插入到一个完全
填充的页面中所引发的）1，或者是在进行常规回收的时候。

然而，散列索引不能缩减：一旦分配，索引页将不会返回到操作系统。主页面被永久地分配给它们的桶，即使它们根本不包含任何
元素；被清除的溢出页面在位图中被跟踪，可以被重新使用（可能被另一个桶使用）。减少索引的物理尺寸的唯一方法是使用
REINDEX或VACCUM FULL命令重建它

查询计划中没有显示索引类型：

#+begin_src sql
  create index on flights using hash(flight_no);
  explain (costs off)
  select * from flights where flight_no = 'PG0001';
#+end_src

** 操作类

在Postgre 10之前，哈希索引是没有记录的，也就是说，它们既没有对故障的保护，也没有复制，因此，不建议使用它们。但
即使如此，它们也有自己的价值。事情是这样的，散列算法被广泛使用（特别是执行散列连接和分组），系统必须知道哪种散列函数
可以用于某种数据类型。然而，这种对应关系不是静态的：它不能被一劳永逸地定义，因为Postgre 10允许在运行中添加新的数
据类型。因此，它是由散列索引和特定数据类型的运算器类来维护的。散列函数本身由该类的支持函数来表示：

#+begin_src sql
  select opfname as opfamily_name,
  amproc::regproc as opfamily_procedure
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_amproc amproc on amprocfamily=opf.oid
  where amname='hash'
  and amprocnum=1
  order by opfamily_name, opfamily_procedure;
#+end_src

这些函数返回32位整数。尽管它们没有被记录下来，但它们可以用来计算相应类型的值的哈希代码。

例如，text_ops系列使用hashtext函数：

#+begin_src sql
  select hashtext('one'), hashtext('two');
#+end_src

散列索引的运算符类只提供等于运算符：

#+begin_src sql
  select opfname as opfamily_name
  left(amopopr::regoperator::text, 20) as opfamily_operator
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_amop amop on amopfamily=opf.oid
  where amname='hash'
  order by opfamily_name, opfamily_operator;
#+end_src


** 属性

让我们看一下哈希访问方法赋予系统的索引级属性

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ])p(name)
  where a.amname = 'hash';
#+end_src

很明显，哈希索引不能用于行排序：哈希函数或多或少地随机混合了数据。

唯一性约束也不被支持。然而，哈希索引可以执行排除性约束，由于唯一支持的函数是等于，这种排除性达到了唯一性的含义：

#+begin_src sql
  alter table aircrafts_data
  add constraint unique_range exclude using hash(range with =);
  insert into aircrafts_data
  values('744', '{"ru":"Boeing 747-400"}', 11100);
#+end_src

多列索引和额外的INCLUDE列也不被支持。

索引级属性

#+begin_src sql
  select p.name, pg_index_has_property('flights_flight_no_idx', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backward_scan'
  ]) p(name);
#+end_src

散列索引同时支持常规的索引扫描和位图扫描。

不支持通过哈希索引进行表的聚类。这很符合逻辑，因为很难想象为什么可能需要根据哈希函数值对堆数据进行物理排序。

列级属性

#+begin_src sql
  select p.name,
  pg_index_column_has_property('flights_flight_no_idx', 1, p.name)
  from unnest(arrary[
  'asc', 'desc', 'nulls_first', 'nulls_last', 'orderable',
  'distance_orderable', 'returnable', 'search_array', 'search_nulls'
  ]) p(name);
#+end_src

由于散列函数不保留值的顺序，所有与排序有关的属性都不适用于散列索引。

散列索引不能参与仅有索引的扫描，因为它不存储索引键，需要堆访问。

散列索引不支持NULL值，因为等于操作对它们不适用。

对数组中的元素的搜索也没有实现。



* B-tree索引

** 概览
B树（实现为btree访问方法）是一种数据结构，它可以使你从树的根部往下走，快速找到树的叶子节点中的所需元素。为了使
搜索路径能够被明确地确定，所有的树元素必须是有序的。B树是为有序数数据类型设计的，其数值可以被比较和排序。
以下是代码上建立索引的示意图，内部节点是水平的矩形；叶子节点是垂直排列的。

[[./images/1nM4AH.png]]

每个树节点包含几个元素，这些元素由一个索引键和一个指针组成。内部节点元素引用下一级的节点；叶子节点元素引用堆图元
（图示中没有显示这些引用）。

B树具有以下重要特性：
+ 它们是平衡的，这意味着一棵树的所有叶子结点都位于相同的深度。因此，它们保证所有数值的搜索时间相等。
+ 在这个过程中，每个节点都有大量的分支，也就是说，每个节点都包含许多元素，通常是数百个（图中显示的是三元素节点，只
  是为了清晰起见）。因此，B树的深度总是很小，即使是非常大的表。
  #+begin_comment
  我们不能绝对肯定地说这种结构的名称中的字母B代表什么。平衡型和灌木型都同样适合。令人惊讶的是，你经常可以看到它被
  解释为二进制，这当然是不正确的。
  #+end_comment
+ 索引中的数据是按升序或降序排序的，在每个节点内和同一级别的所有节点中都是如此。对等节点被绑定到一个双向的列表中，因
  此可以通过简单地扫描列表来获得一个有序的数据集，而不必每次都从根部开始。


** 搜索和插入
*** 等值搜索
让我们来看看我们如何通过条件 "indexedcolumn = expression "在树中搜索一个值。我们将尝试找到KJA机场

搜索从根节点开始，访问方法必须确定要下降到哪个子节点。它选择Ki键，对于Ki⩽表达式<Ki+1是满足的。

根节点包含键AER和OVB。 条件AER⩽ KJA < OVB成立，所以我们需要下降到有AER键的元素所引用的子节点。

[[./images/jQgP3H.png]]


这个过程是递归重复的，直到我们到达包含所需元组ID的叶节点。在这种特殊情况下，子节点满足条件DME⩽ KJA < KZN，
所以我们必须下降到有DME键的元素所引用的叶节点。

你可以注意到，树的内部节点中最左边的键是多余的：要选择根的子节点，只要满足条件KJA < OVB就可以了。B树并不存储这
样的键，所以在接下来的插图中，我将把相应的元素留空。

叶子节点中的所需元素可以通过二进制搜索快速找到。

然而，搜索过程并不像它看起来那么简单。必须考虑到，索引中数据的排序顺序可以是升序，如上图所示，也可以是降序。即使是
一个唯一的索引也可以有几个匹配的值，而所有这些值都必须被返回。此外，可能会有很多重复的数据，以至于它们不适合一个节
点，所以邻近的叶子节点也要被处理。

由于一个索引可以包含非唯一的值，将其顺序称为非降序而不是升序（非升序而不是降序）会更准确。但我将坚持使用一个更简单
的术语。此外，元组ID是索引键的一部分，这让我们认为索引条目是唯一的，即使这些值实际上是相同的。

除此之外，在搜索过程中，其他进程可能会修改数据，页面可能会被分割成两个，树状结构可能会改变。所有的算法都是为了尽可能
地减少这些并发操作之间的争夺，避免过多的锁，但我们在这里不打算讨论这些技术问题。

*** 不等值搜索
如果按条件 "索引列⩽表达式"（或 "索引列⩾表达式"）进行搜索，我们必须首先在索引中搜索满足平等条件的值，然后按要求的
方向遍历其叶子节点，直到到达树的末端。

这张图说明了搜索小于或等于DME的机场代码。

[[./images/V61w6w.png]]

对于小于和大于运算符，过程是相同的，只是必须排除第一个发现的值。

*** 范围搜索

当按范围 "expression1 ⩽ 索引列 ⩽ expression2 "搜索时，我们必须首先找到expression1，然后沿正确方向遍历叶
子节点，直到找到expression2。这张图说明了在LED和ROV之间（含）搜索的过程。

[[./images/wgP1TQ.png]]


*** 插入
新元素的插入位置是由键的顺序明确定义的。例如，如果你在表中插入RTW机场代码（萨拉托夫），新元素将出现在最后一个
叶子节点，在ROV和SGC之间。

但是，如果叶子节点没有足够的空间容纳新的元素呢？例如（假设一个节点最多可以容纳三个元素），如果我们插入TJM机场代
码，最后一个叶子节点将被过度填充。在这种情况下，节点会被分成两个，旧节点的一些元素被移到新节点中，而新的子节点的
指针会被添加到父节点中。很明显，父节点也会被填满。然后它也被分割成两个节点，以此类推。如果要拆分根节点，则在产生
的节点上方再创建一个节点，成为树的新根。在这种情况下，树的深度会增加一级。

在这个例子中，TJM机场代码的插入导致了两个节点的分裂；由此产生的新节点在下图中被突出显示。为了确保任何节点都能被
拆分，双向列表绑定了所有级别的节点，而不仅仅是最低级别的节点。

[[./images/Mkersy.png]]

所描述的插入和拆分程序保证了树保持平衡，由于一个节点可以容纳的元素数量通常相当大，所以树的深度很少增加。

问题是，一旦被分割，节点就不能被合并在一起，即使它们在清理回收后只包含很少的元素。这个限制不是与树形数据结构本身有
关，而是与它的Postgre实现有关。因此，如果在尝试插入时，节点被证明是满的，访问方法首先尝试修剪多余的数据，以清
除一些空间，避免额外的分裂。

** 页布局
B树的每个节点需要一个页面。该页的大小定义了节点的容量。

由于页面的分割，树的根部在不同的时间可以由不同的页面来代表。但是搜索算法必须总是从根开始扫描。它在零索引页（称为
metapage）中找到当前根页的ID。metapage还包含一些其他的元数据。

[[./images/Zikz1R.png]]

索引页中的数据布局与我们到目前为止所看到的有点不同。所有的页面，除了每一级的最右边，都包含一个额外的 "高键"，它保
证不比这一页的任何键小。在上图中，高键被突出显示。

让我们使用pageinspect扩展来看看一个建立在六位数的预订参考上的真实索引的一个页面。metapage列出了根页面ID和
树的深度（级别编号从叶子节点开始，以0为基础）：

#+begin_src sql
  select root, level
  from bt_metap('bookings_pkey')
#+end_src

存储在索引项中的键被显示为字节序列，这其实并不方便：

#+begin_src sql
  select data
  from bt_page_items('bookings_pkey', 290)
  where itemoffset=2;
#+end_src

为了破译这些值，我们将不得不写一个特设的函数。它不支持所有的平台，也可能对某些特定的场景不起作用，但它对本章的例子
来说是可行的：

#+begin_src sql
  create function data_to_text(data text)
  returns text
  as $$
  declare
  raw bytea := ('\x' || replace(data, ' ', ''))::bytea;
  pos integer := 0;
  len integer;
  res text := '';
  begin
  while(octet_length(raw) > pos)
  loop
  len := (get_byte(raw, pos)-3)/2;
  exit when len<=0;
  if pos>0 then
  res := res || ', ';
  end if;
  res := res || (
  select string_agg( chr(get_byte(raw, i)), '')
  from generate_series(pos+1, pos+len) i
  );
  pos := pos+len+1;
  end loop;
  return res;
  end;
  $$ LANGUAGE plpgsql
#+end_src

现在我们可以看一下根页面的内容了：

#+begin_src sql
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('bookings_pkey', 5135);
#+end_src

正如我所说的，第一个条目不包含键。ctid列提供了指向子页面的链接。

需要在booking查找E2D725.在这个例子中，必须选择19到页5135

#+begin_src sql
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('bookings_pkey', 5135);
#+end_src

本页的第一个条目包含了高调，这可能看起来有点出乎意料。从逻辑上讲，它应该被放在页面的末尾，但从实现的角度来看，把它
放在开头更方便，以避免每次页面内容发生变化时移动它。这里我们选择条目3，然后下到页面11919。

#+begin_src sql
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('bookings_pkey', 5133);
#+end_src

它是索引的一个叶子页。第一个条目是高键；所有其他条目都指向堆元组

这是bookings元组数据

#+begin_src sql
  select * from bookings
  where ctid='(11919, 77)'
#+end_src

这是bookings表中搜索，低层次执行的操作

#+begin_src sql
  explain (costs off)
  select * from bookings
  where book_ref='E2D725';
#+end_src

重复数据删除

非唯一的索引可能包含很多重复的键，这些键指向不同的堆元组。由于非唯一的键会出现不止一次，因此会占用很多空间，重复的
键会被折叠成一个索引条目，其中包含键和相应元组ID的列表。在某些情况下，这个程序（被称为重复数据删除）可以大大
减少索引的大小。

然而，由于MVCC的原因，唯一索引也可能包含重复的内容：一个索引会保留对表行所有版本的引用。HOT更新的机制可以帮助
你回收因引用过时的、通常是很短的行版本而导致的索引膨胀，但有时它可能并不适用。在这种情况下，重复数据删除可以争取一
些时间来删除多余的堆元组，并避免额外的页面分割。

为了避免在重复数据删除没有带来直接好处的情况下浪费资源，只有在叶子页没有足够的空间来容纳一个更多的元组时才会进行折
叠。然后页面修剪和重复数据删除可以释放一些空间，并防止不希望的页面分割。然而，如果重复的情况很少，你可以通过关闭
deduplicate_items存储参数来停用重复数据删除功能。

一些索引不支持重复数据删除。主要的限制是，键的相等必须通过简单的二进制比较它们的内部表示来检查。到目前为止，并非
所有的数据类型都可以通过这种方式进行比较。例如，浮点数（浮点数和双精度）对零有两种不同的表示。任意精度的数字
（numeric）可以用不同的尺度表示一个相同的数字，而jsonb类型可以使用这样的数字。如果你使用非确定性排序4，允许
相同的符号由不同的字节序列来表示，那么文本类型也不可能进行重复数据删除（标准排序是确定性的）。

此外，对于复合类型、范围和数组，以及用INCLUDE子句声明的索引，目前不支持重复数据删除。

要检查一个特定的索引是否可以使用重复数据删除，你可以看一下其metapage中的allequalimage字段：

#+begin_src sql 
  create index on tickets(book_ref);
  select allequalimage from bt_metap('tickets_book_ref_idx');
#+end_src

在这种情况下，重复数据删除得到了支持。而事实上，我们可以看到，其中一个叶子页既包含有单一元组ID( htid)的索引条目，
也包含有IDS(tids)的列表：

#+begin_src sql
  select itemoffset, htid, left(tids::text, 27) tids,
  data_to_text(data) as data
  from bt_page_items('tickets_book_ref_idx', 1)
  where itemoffset > 1;
#+end_src

内部索引条目的存储

重复数据删除能够在索引的叶子页中容纳更多的条目。但是，即使叶子页构成了索引的大部分，在内部页中进行的数据压缩以防止额
外的分裂也同样重要，因为搜索效率直接取决于树的深度。

内部索引条目包含索引键，但是它们的值只用来确定搜索时要下到的子树。在多列索引中，通常取第一个关键属性（或几个第一属
性）就足够了。其他属性可以被截断以节省页面空间。这种后缀截断发生在一个叶子页被分割，而内部页必须容纳一个新的指针的
时候。

#+begin_comment
  理论上，我们甚至可以更进一步，只保留属性的有意义的部分，例如，一行的前几个符号足以区分子树。但是现在还没有实现：
  一个索引条目要么包含整个属性，要么完全排除这个属性。
#+end_comment

例如，这里是建立在机票表上的索引的根页面的几个条目，包含booking引用的passenger_name列：

#+begin_src sql
  create index tickets_bref_name_idx
  on tickets(book_ref, passenger_name);
  select itemoffset, ctid, data_to_text(data)
  from bt_page_items('tickets_bref_name_idx', 229)
  where itemoffset between 8 and 13;
#+end_src

我们可以看到，一些索引条目没有第二个属性。

当然，叶子页必须保留所有的键属性和INCLUDE列值（如果有的话）。否则，就不可能进行仅有索引的扫描了。唯一的例外是
高键；它们可以被部分保留。

** 操作类

比较语义

除了散列值之外，系统还必须知道如何对各种类型的值进行排序，包括自定义的值。这对于排序、分组、合并连接和其他一些操作来
说是不可缺少的。而就像散列的情况一样，特定数据类型的比较运算符是由运算符类定义的。

操作符类允许我们从名称中抽象出来（如>、<、=），甚至可以提供几种方法来排列同一类型的值。

下面是必须在btree方法的任何运算符类中定义的强制性比较运算符（所示为bool_ops系列）：

#+begin_src sql
  select amopopr::regoperator as opfamily_operator,
  amopstrategy
  from pg_am am
  join pg_opfamily opf on opfmethod=am.oid
  join pg_amop amop on amopfamily=opf.oid
  where amname='btree' and opfname='bool_ops'
  order by amopstrategy;
#+end_src

这五个比较运算符中的每一个都对应于一个策略，这就定义了它们的语义：

1. 小于
2. 小于或等于
3. 等于
4. 大于或等于
5. 大于

一个B-树操作符类还包括几个支持函数。3 第一个必须返回1，如果它的第一个参数大于第二个参数，-1，如果它小于第二个参
数，0，如果参数相等。其他支持函数是可选的，但它们可以提高访问方法的性能。

为了更好地理解这一机制，我们可以定义一个具有非默认排序的新数据类型。文档中给出了一个关于复数的例子，1但它是用C语
言写的。幸运的是，B-树操作符类也可以用解释语言来实现，所以我将利用它，做一个尽可能简单的例子（即使是明知效率低下）。

让我们为信息单元定义一个新的复合类型：

#+begin_src sql
  create type capacity_unit as enum (
   'B', 'kB', 'MB','GB', 'TB','PB'
   );
   create type capacity as (
   amount integer,
   unit capacity_unit
   );
#+end_src

现在创建一个带有新类型的列的表，并用随机值填充它：

#+begin_src sql
  create table test as
  select ((random()*1023)::integer, u.unit)::capacity as cap
  from generate_series(1,100),
     unnest(enum_range(NULL::capacity_units)) as u(unit);
#+end_src

默认情况下，复合类型的值是按词汇表顺序排序的，这与这种特定情况下的自然顺序不一样：

#+begin_src sql
  select * from test order by cap;
#+end_src

现在让我们开始创建我们的操作者类。我们将首先定义一个将体积转换为字节的函数：

#+begin_src sql
  create function capacity_to_bytes(a capacity) returns numeric
  as $$
  select a.amount::numeric *
  1024::numeric ^ (array_position(enum_range(a.unit), a.unit) -1 );
  $$ language sql strict immutable;
  select capacity_to_bytes((1, kB)::capacity);
#+end_src

为该数据类型创建一个操作者函数

#+begin_src sql
  create function capacity_cmp(a capacity, b capacity)
  returns integer
  as $$
  select sign(capacity_to_bytes(a)-capacity_to_bytes(b));
  $$ language sql strict immutable;
#+end_src

现在，使用这个支持函数来定义比较运算符是很容易的。我故意使用奇特的名字来证明它们可以是任意的：

#+begin_src sql
  create function capacity_lt(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b)<0;
  end;
  $$ language plpgsql immutable strict;

  create operator #<# (
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_lt
  );
#+end_src

其他四个运算符的定义与此类似。

#+begin_src sql
  create function capacity_le(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b) <= 0;
  end;
  $$  language plpgsql immutable strict;
  create operator #<=# (
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_le
  );
#+end_src

#+begin_src sql
  create function capaity_eq(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b) = 0;
  end;
  $$ language plpgsql immutable strict;
  create operator #=#(
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_eq,
  merges -- can be used in merge joins
  );
#+end_src

#+begin_src sql
  create function capacity_ge(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a, b) >= 0;
  end;
  $$ language plpgsql immutable strict;
  create operator #>=#(
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_ge
  );
#+end_src

#+begin_src sql
  create function capacity_gt(a capacity, b capacity) returns boolean
  as $$
  begin
  return capacity_cmp(a,b) > 0;
  end;
  $$ language plpgsql immutable strict;
  create operator #>#(
  leftarg=capacity,
  rightarg=capacity,
  function=capacity_gt
  );
#+end_src

在这个阶段，我们已经可以进行比较:

#+begin_src sql
  select (1, 'MB')::capacity #># (512, 'KB')::capacity
#+end_src

一旦操作者类被创建，排序也将按预期开始工作：

#+begin_src sql
  create operator class capacity_ops
  default for type capacity -- to be used by default
  using btree as
  operator 1 #<#,
  operator 2 #<=#,
  operator 3 #=#,
  operator 4 #>=#,
  operator 5 #>#,
  function 1 capacity_cmp(capacity, capacity);
  select * from test order by cap;
#+end_src

当一个新的索引被创建时，我们的操作者类被默认使用，这个索引以正确的顺序返回结果：

#+begin_src sql
  create index on test(cap);
  select * from test where cap #<# (100, 'B')::capacity
  order by cap;
  explain (consts off) select *
  from test where cap #<# (100, 'B')::capacity order by cap;
#+end_src

在平等运算符声明中指定的MERGE子句可以对该数据类型进行合并连接。

多列索引和排序

让我们仔细看看多列索引的排序问题。

首先，在声明索引时，选择最佳的列序是非常重要的：页面内的数据排序将从第一列开始，然后转到第二列，以此类推。多列索引
只有在所提供的过滤条件从第一列开始跨越一个连续的序列时才能保证高效的搜索：第一列、前两列、第一列和第三列之间的范围，
等等。其他类型的条件只能用于过滤掉根据其他标准获取的多余的值。

下面是在tickets表上创建的索引的第一叶页中的索引条目顺序，其中包括tickets引用的乘客姓名：

#+begin_src sql
  select itemoffset, data_to_text(data)
  from bt_page_items('tickets_bref_name_idx', 1)
  where itemoffset > 1;
#+end_src

在这种情况下，只有通过订票信息和乘客姓名，或仅通过订票信息，才能有效地搜索到票。

#+begin_src sql
  explain (costs off) select *
  from tickets
  where book_ref = '000010';
#+end_src

#+begin_src sql
  explain (costs off) select *
  from tickets
  where book_ref='000010' and passenger_name='LYUDMILA BOGDANOVA';
#+end_src

但如果我们决定寻找一个乘客的名字，我们必须扫描所有的行：

#+begin_src sql
  explain (costs off) select *
  from tickets
  where passenger_name='LYUDMILA BOGDANOVA';
#+end_src

即使规划器选择执行索引扫描，所有的索引条目仍然要被遍历。不幸的是，规划器不会显示条件实际上只用于过滤结果。

#+begin_comment
如果第一列没有太多不同的值v1, v2, ... vn，那么在相应的子树上执行几次就会有好处，实际上就是用一系列的搜索条件
"col2 = value "来代替一次搜索：col1 = v1 and col2 = value col1 = v2 and col2 = value ⋯ col1 = vn
and col2 = value 这种类型的索引访问被称为跳过扫描，但是它还没有实现。
#+end_comment

反之亦然，如果在乘客姓名和订票号码上创建索引，它将更适合通过乘客姓名单独查询，或者同时查询乘客姓名和订票参考：

#+begin_src sql
  create index tickets_name_bref_idx
  on tickets(passenger_name, book_ref);
  select itemoffset, data_to_text(data)
  from bt_page_items('tickets_name_bref_idx', 1)
  where itemoffset > 1;
  explain (costs off) select * from tickets
  where passenger_name='LYUDMILA BOGDANOVA';
#+end_src

除了列的顺序之外，在创建新的索引时，你还应该注意排序顺序。默认情况下，数值是按升序排序的（ASC），但如果需要的话，你
可以把它倒过来（DESC）。如果一个索引是在单列上建立的，这并不重要，因为它可以在任何方向上被扫描。但是在一个多列索引
中，顺序就变得很重要了。

我们新创建的索引可以用来检索按两列升序或降序排序的数据：

#+begin_src sql
  explain(costs off) select *
  from tickets
  order by passenger_name, book_ref;
  explain (costs off) select *
  from tickets order by passenger_name desc, book_ref desc;
#+end_src

但是，如果需要同时按一列升序排序和按另一列降序排序，这个索引就不能马上返回数据。在这种情况下，索引提供的是部分排序
的数据，必须按第二个属性进一步排序：

#+begin_src sql
  explain (costs off) select *
  from tickets order by passenger_name asc, book_ref desc;
#+end_src

NULL值的位置也会影响到使用索引进行排序的能力。默认情况下，NULL值在排序时被认为比普通值 "大"，也就是说，如果排序
顺序是升序，它们就位于树的右侧，如果排序顺序是降序，它们就位于左侧。NULL值的位置可以通过NULL LAST和NULL
FIRST子句来改变。

在下一个例子中，索引不满足ORDER BY子句，所以必须对结果进行排序：

#+begin_src sql
  explain (costs off) select *
  form tickets order by passenger_name nulls first, book_ref desc;
#+end_src

但是，如果我们创建一个遵循所需顺序的索引，它将被使用：

#+begin_src sql
  create index tickets_name_bref_idx2
  on tickets(passenger_name nulls first, book_ref desc);
  explain (costs off) select *
  from tickets order by passenger_name nulls first, book_ref desc;
#+end_src

** 属性
让我们来看看B树的接口属性。

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include']) p(name)
  where a.amname='btree';
#+end_src

B树可以对数据进行排序并确保其唯一性。它是唯一具有这种特性的访问方法。

许多访问方法都支持多列索引，但由于B树中的值是有序的，所以你必须密切注意索引中各列的顺序。

从形式上看，支持排除式约束，但它们仅限于平等条件，这使得它们类似于唯一约束。使用成熟的唯一约束更为可取。

B树索引也可以用额外的不参与搜索的INCLUDE列来扩展。

索引级的属性

#+begin_src sql
  select p.name, pg_index_has_property('flights_pkey', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backward_scan'
  ])p(name)
#+end_src

B树索引可用于集群化。

索引扫描和位图扫描都被支持。由于叶子页被绑定成一个双向的列表，一个索引也可以被反向遍历，这将导致反向的排序顺序：

#+begin_src sql
  explain (costs off) select *
  from bookings order by book_ref desc;
#+end_src

列级属性

#+begin_src sql
  select p.name
  pg_index_column_has_property('flight_pkey', 1, p.name)
  from unnest(array[
  'asc', 'desc', 'nulls_first', 'nulls_last', 'orderable',
  'distance_orderable', 'returnable', 'search_array', 'search_nulls'
  ])p(name);
#+end_src

ORDERABLE 属性表示存储在 B 树中的数据是有序的，而前四个属性（ASC 和 DESC、NULLS FIRST 和 NULLS LAST）定义
了特定列中的实际顺序。在这个例子中，列值是按升序排序的，NULL值列在最后。

SEARCH NULLS 属性指示是否可以搜索 NULL 值。

B树不支持排序运算符（DISTANCE ORDERABLE），尽管已经试图实现它们。

B-树支持在一个数组中搜索多个元素（SEARCH ARRAY属性），并且可以在不访问堆的情况下返回结果数据（RETURNABLE）。



* GiST

** 概要
GiST(广义搜索树)是一种访问方法，它实际上是平衡搜索树的广义化，适用于支持值的相对定位的数据类型。B-树的适用性仅限于
允许比较操作的序数类型（但为此类类型提供的支持极为高效）。至于GiST，它的操作符类允许为数据在树中的分布定义任意的标
准。GiST索引可以容纳空间数据的R树、集合的RD树以及任何数据类型（包括文本和图像）的签名树。

得益于可扩展性，你可以通过实现索引引擎的接口，在 PostgreSQL 中从头开始创建一个新的访问方法。然而，除了设计索引逻
辑，您还必须定义页面布局、有效的锁定策略和WAL支持。这一切都需要强大的编程能力和大量的实施工作。GiST简化了这一任
务，解决了所有底层技术问题，并为搜索算法提供了基础。要在新的数据类型中使用GiST方法，只需添加一个新的运算符类，其
中包括十几个支持函数。与为B树提供的琐碎的操作符类不同，这样的类包含了大部分的索引逻辑。在这方面，GiST可以被视为
构建新访问方法的框架。

一般来说，属于叶子节点的每个条目（叶子条目）都包含一个谓词（逻辑条件）和一个堆元组 ID。索引关键字必须满足谓词的要
求；至于关键字本身是否属于该条目，则无关紧要。

内叶中的每个条目（内条目）也包含一个谓词和一个指向子节点的引用；子子树的所有索引数据都必须满足这个谓词。换句话说，内
部条目的谓词是其所有子条目谓词的联合。GiST的这一重要特性为B树的简单排序提供了服务。

GiST树搜索依赖于一致性函数，这是运算符类定义的支持函数之一。

一致性函数在索引条目上调用，以确定该条目谓词是否与搜索条件（"索引列运算符表达式"）"一致"。对于内条目，它显示我们是
否必须进入相应的子树；对于叶条目，它检查其索引键是否满足条件。

搜索从根节点开始，这是典型的树形搜索。一致性函数决定了哪些子节点必须遍历，哪些可以跳过。与B树不同，GiST索引可能
有多个这样的节点。由一致性函数选择的叶节点条目将作为结果返回。

搜索总是深度优先的：算法试图尽快进入叶页。因此，它可以立即开始返回结果，如果用户只需要得到前几行，这就非常有意义了。

要在 GiST树中插入一个新值，不可能使用一致性函数，因为我们需要选择一个节点作为下行节点。

就像在 B 树中一样，被选中的节点可能没有空闲空间，从而导致拆分。这一操作还需要两个函数，其中一个在新旧节点之间分配条
目；另一个形成两个谓词的联合，以更新父节点的谓词。

随着新值的不断增加，现有的谓词也在不断扩充，通常只有在拆分页面或重建整个索引时才会缩小谓词的范围。因此，GiST索引的
频繁更新会导致其性能下降。

由于所有这些理论讨论可能显得过于空泛，而且确切的逻辑大多取决于特定的运算符类，因此我将提供几个具体的例子。

** 积分R树

第一个示例涉及平面上点（或其他几何图形）的索引。常规的B树不能用于这种数据类型，因为没有为点定义比较运算符。显然，
我们可以自己实现这样的运算符，但几何图形需要索引支持完全不同的运算。我将只介绍其中的两种：搜索特定区域内的对象和最近
邻搜索。

B-树在平面上绘制矩形，这些矩形必须覆盖所有索引点。索引项存储了边界框，谓词可定义如下：点位于此边界框内。

B型树的根节点包含几个大矩形（也可能重叠）。子节点包含与其父节点相匹配的较小矩形，它们共同覆盖所有底层点。

叶节点应包含索引点本身，但GiST要求所有条目具有相同的数据类型；因此，叶条目也用矩形表示，矩形被简单地简化为点。

为了更直观地展示这种结构，让我们来看一看在机场坐标上建立的三层 B 树。在这个示例中，我将演示数据库中的机场表扩展到了
五千行。此外，我还降低了填充因子值，以使树更深；默认值将为我们提供一个单层树。

#+begin_src sql
  create table airports_big as
  select * from airports_big;
  copy airports_big from
  '/home/student/internals/airports/extra_airports.copy';
  create index airports_gist_idx on airports_big
  using gist(coordinates) with (fillfactor=10);
#+end_src

在上层，所有的点都包含在几个（部分重叠的）边界框中：

[[./images/kKZ3ML.png]]

在下一层，大矩形被分割成小矩形：

[[./images/Poc8It.png]]


最后，在树的内层，每个边界框包含的点数与单页所能容纳的点数相同：

[[./images/zboFkn.png]]


该索引使用point_ops运算符类，这是唯一可用的点运算符类。

矩形和任何其他几何图形都可以用同样的方式进行索引，但索引必须存储对象的边界框，而不是对象本身。

页面布局

可以使用pageinspect扩展来研究GiST页面。

与B树索引不同，GiST没有元页，零页总是树的根。如果根页面被拆分，旧的根页面将被移至一个单独的页面，而新的根页面将
取而代之。

以下是根页面的内容：

#+begin_src sql
  select ctid, keys
  from gist_page_items(
   get_raw_page('airports_gist_idx', 0), 'airports_gist_idx'
   );
#+end_src


这四行对应于第一幅图中上层的四个矩形。遗憾的是，这里的键是以点的形式显示的（这对叶页来说是合理的），而不是以矩形的形
式显示的（这对内页来说更合理）。但我们可以随时获取原始数据并自行解释。

#+begin_comment
  要提取更详细的信息，可以使用gevel扩展，它不包含在标准的PostgreSQL发行版中。
#+end_comment

操作类

下面的查询返回实现树的搜索和插入操作逻辑的支持函数列表：

#+begin_src sql
  select amprocnum, amproc::regproc
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amproc amop on amprocfamily=opcfamily
  where amname='gist'
  and opcname='point_ops'
  order by amprocnum;
#+end_src


上面已经列出了必须具备的功能：

1. 在搜索过程中用于遍历树的一致性函数
2. union函数合并矩形
3. penalty函数，用于在插入条目时选择下行子树
4. picksplit函数，用于在页面分割后在新页面之间分配条目
5. same函数检查两个键是否相等

point_ops运算符类包括以下运算符：

#+begin_src sql
  select amopopr::regoperator, amopstrategy as st, oprcode::regproc,
  left(obj_description(opr.oid, 'pg_operator'), 19) descrioption
  from pg_am am
  join pg_opclass opc on opcmethod = am.oid
  join pg_amop amop on amopfamily = opcfaimly
  join pg_operator opr on opr.oid = amopopr
  where amname = 'gist'
  and opcname = 'point_ops'
  order by amopstrategy;
#+end_src

运算符名称通常不会告诉我们太多关于运算符的语义，因此该查询也会显示底层函数的名称及其描述。所有运算符都以这种或那种
方式处理几何图形的相对位置（左侧、右侧、上方、下方、包含、被包含）以及它们之间的距离。

与 B 树相比，GiST 提供了更多的策略。有些策略编号是几种索引1 的共用编号，而有些则是通过公式计算得出的（例如，28、
48和68实际上代表了同一种策略：矩形、多边形和圆形都包含这种策略）。此外，GiST还支持一些过时的运算符名称
（<<| 和 |>>）。

操作符类可能只实现部分可用策略。例如，点的运算器类不支持包含策略，但是在为具有可测量面积的几何体定义的类（box_ops、
poly_ops 和 circle_ops）中可以使用包含策略。

容器元素的搜索

一个典型的查询可以通过索引加快速度，返回指定区域内的所有点。

例如，我们可以找到所有距离莫斯科市中心1度以内的机场：

#+begin_src sql
  select airport_code, airport_name->>'en'
  from airports_big
  where coordinates <@ '<(37.622513, 55.753220), 1.0>'::circle;

  expalin (costs off) select airport_code
  from airports_big
  where coordinates <@ '<(37.622513, 55.753220), 1.0>'::circle;
#+end_src

我们可以通过下图中的一个微不足道的例子来详细了解这个运算符：

[[./images/h0GqE7.png]]


如果以这种方式选择边界框，索引结构将如下所示：

[[./images/anbOi7.png]]

包含运算符 <@ 确定特定点是否位于指定的矩形内。如果索引项的矩形与该矩形有公共点，则该操作符的一致性函数返回 "yes"。
这意味着，对于叶节点条目（存储简化为点的矩形），该函数确定点是否包含在指定的矩形中。

例如，让我们找出矩形(1,2)-(4,7)的内点，如下图所示：

[[./images/Hka1hm.png]]


[[./images/F4qXea.png]]


搜索从根节点开始。边界框与(0,0)-(3,4)重叠，但与(5,3)-(9,9)不重叠。这意味着我们不必进入第二个子树。

在下一层，边界框与 (0,3)-(3,4) 重叠，并触及 (0,0)-(3,2) ，因此我们必须检查这两个子树。

一旦我们到达叶节点，我们只需遍历其包含的所有点，并返回满足一致性函数的点。

B树搜索总是选择一个子节点。然而，GiST搜索可能需要扫描多个子树，特别是当它们的边界框重叠时。

最近邻搜索

索引支持的大多数操作符（如前面示例中的=或<@）通常被称为搜索操作符，因为它们定义了查询中的搜索条件。这些操作符是谓词，
也就是说，它们返回一个逻辑值。

但是还有一组排序操作符，它们返回参数之间的距离。此类操作符在ORDER BY子句中使用，通常由具有DISTANCE ORDERABLE
属性的索引支持，它能够快速查找指定数量的近邻。这种类型的搜索被称为k-NN或k-近邻搜索。

例如，我们可以找到离科斯特罗马最近的10个机场：

#+begin_src sql
  select airport_code, airport_name->>'en'
  from airports_big
  order by coordinates <-> '(40.926780, 57.767943)'::point
  limit 10;

  explain (costs off) select airport_code
  from airports_big
  order by coordinates <-> '(40.926780, 57.767943)'::point
  limit 5;
#+end_src

由于索引扫描会逐个返回结果，并且可以随时停止，因此可以很快找到几个首值。

#+begin_comment
 如果没有索引支持，很难实现高效搜索。我们必须找到特定区域内出现的所有点，然后逐步扩大该区域，直到返回所需的结果数。
 这将需要多次索引扫描，更不用说选择原始区域大小及其增量的问题了。
#+end_comment

您可以在系统目录中看到运算符类型（"s "表示搜索，"o "表示排序运算符）：

#+begin_src sql 
        select amopopr::regoperator, amoppurpose, amopstrategy 
      from pg_am am 
      join pg_opclass opc on opcmethod=am.oid 
      join pg_amop amop on amopfamily=opcfamily 
      where amname='gist' 
      and opcname='point_ops'  
  order by amopstrategy;
#+end_src

为了支持这种查询，操作符类必须定义一个额外的支持函数：它是距离函数，在索引条目上调用它来计算从存储在这个条目中的值
到其他值的距离。

对于表示索引值的叶元素，该函数必须返回与该值的距离。在点的情况下，它是一个常规的欧几里得距离，等于
#+begin_export latex
\sqrt((x_{2}-x_{1})^{2}-(y_{2}-y_{1})^{2}
#+end_export

对于一个内部元素，函数必须返回它与其子叶元素之间所有可能距离的最小值。由于扫描所有子元素的成本很高，函数可以乐观地
低估距离（牺牲效率），但绝不能返回更大的值--这会影响搜索的正确性。

因此，对于由边界框表示的内部元素，点到点的距离可以从常规数学意义上理解：要么是点到矩形之间的最小距离，要么如果点在
矩形内部则距离为零。这个值很容易计算，不需要遍历矩形的所有子点，并且保证不大于到这些点中任何一点的距离。

让我们考虑搜索点(6,8)的三个近邻的算法：

[[./images/AO2UAo.png]]


搜索从根节点开始，根节点包含两个边界框。从指定点到矩形 从指定点到矩形(0,0)-(3,4)的距离为到矩形角(3.4)的距离，等于
5.o。到(5,3)-(9,9)的距离为 0.0。这里所有的值都四舍五入到小数点后第一位；这样的精度在本例中就足够了。对于本例来说，
这样的精度已经足够了）。

我们再次选择右侧子树，进入包含三个点的叶节点：距离为 2.0 的 (6,6)，距离为 2.2 的 (8,9)，以及距离为 3.2 的
(9,7)。

[[./images/xXOaiY.png]]

因此，我们得到了前两个点：(6,6) 和 (8,9)。但是到这个节点的第三个点的距离大于到矩形(5,3)-(8,5)的距离。

因此，现在我们必须进入包含两个点的左侧子节点。到点 (8,5) 的距离是 3.6，而到点 (5,3) 的距离是 5.1。事实证明，前
一个子节点中的点(9,7)比左侧子树的任何一个节点都更靠近点(6,8)，因此我们可以将其作为第三个结果返回。

[[./images/UenfK8.png]]

本例说明了内部条目的距离函数必须满足的要求。由于矩形(5,3)-(8,5)的距离减小（从3.6减小到3.0），多扫描了一个节
点，因此搜索效率下降；但是算法本身仍然是正确的。

插入操作

当一个新的键插入到B树中时，该键所使用的节点由penalty函数决定：边界框的大小必须尽可能小。

例如，点(4,7)将被添加到矩形(5,3)-(9,9)中，因为其面积仅增加 6 个单位，而矩形(0,0)-(3,4)的面积将增加 12 个单位。
在下（叶）层，按照同样的逻辑，该点将添加到矩形(6,6)-(9,9)中。
[[./images/sdy7bb.png]]


假设一个页面最多包含三个元素，则必须将其一分为二，并在新的页面之间分配元素。在这个例子中，结果似乎是显而易见的，但在
一般情况下，数据分配任务并不那么简单。首先，picksplit函数试图最小化边界框之间的重叠，目的是获得更小的矩形和页面之
间点的均匀分布。

[[./images/QpjdZO.png]]


排他性约束

GiST索引也可用于排除约束中。

排除约束保证任意两个堆元组的指定字段在某些操作符的意义上不相互匹配。必须满足以下条件：

+ 排除约束必须由索引方法（CAN Exclude属性）支持。
+ 操作符必须属于该索引方法的操作符类。
+ 运算符必须是交换的，即 "a运算符b = b运算符a "的条件必须为真。

对于上面提到的哈希树和 btree 访问方法，唯一合适的操作符是 equal to。它实际上将一个排除约束变成了唯一约束，这并不
是特别有用。

GiST方法有两种更适用的策略：

+ 重叠：&&运算符
+ djacency: -|- 运算符 (为区间定义)

为了尝试一下，让我们创建一个约束条件，禁止机场之间距离太近。这个条件可以表述为：以机场坐标为圆心的特定半径的圆不能
重叠：

#+begin_src sql
  alter table aiports_data add exclude
  using gist (circle(coordinates, 0.2) with &&);
  insert into aiports_data(
  aiport_code, airport_name, city, coordinates, timezone
  ) values (
   'ZIA', '{}', '{"en":"Moscow"}', point(38.1517, 55.5533),
   'Europe/Moscow'
   );
#+end_src

当定义排除约束时，会自动添加一个用于执行该约束的索引。这里是在表达式上建立的GiST索引。

让我们来看一个更复杂的例子。假设我们需要允许机场之间的距离很近，但前提是它们必须属于同一个城市。一个可能的解决方案
是定义一个新的完整性约束，它可以表述如下：如果圆的中心位于机场坐标处，并且相应的城市名称不同，则禁止存在圆相交(&&)
的行对(!=)。

由于没有文本数据类型的操作符类，尝试创建这样的约束会导致错误：

#+begin_src sql
  alter table aiports_data
  drop constraint aiports_data_circle_excl;
  alter table aiports_data add exclude using gist(
  circle(coordinates, 0.2) with && ,
          (city->>'en') with !=
          );
#+end_src

然而，GiST 确实提供了诸如 strictly left of、 strictly right of 和 same 等策略，这些策略也可以应用于常规的
序数数据类型，例如数字或文本字符串。btree_gist扩展专门用于实现GiST对通常用于B树的操作的支持：

#+begin_src sql
  create extension btree_gist;
  alter table aiports_data add exclude using gist(
   circle(coordinates, 0.2) with &&,
       (city->>'en') with !=
       );
#+end_src

约束条件已创建。现在我们不能添加属于同名城镇的茹科夫斯基机场，因为莫斯科机场太近了：

#+begin_src sql
  insert into aiports_data(
  airport_code, aiport_name, city, coordinates, timezone
  )values (
  'ZIA', '{}', '{"en":"Zhukovskey"}', point(38.1517, 55.5533),
  'Europe/Moscow');
#+end_src

但是，如果我们指定莫斯科为该机场的城市，我们就可以做到这一点：

#+begin_src sql
  insert into aiports_data(
  aiport_code, aiport_name, city, coodrinates, timezone
  ) values (
  'ZIA', '{}', '{"en":"Moscow"}', point(38.1517, 55.5533),
  'Europe/Moscow');
#+end_src

需要记住的是，尽管 GiST 支持大于、小于和等于操作，但 B 树在这方面的效率要高得多，尤其是在访问数值范围时。因此，只
有当GiST索引确实是出于其他合理的原因时，使用上面的btree_gist扩展才是有意义的。

属性

访问方法属性，GiST方法有如下属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ]) p(name)
  where a.amname='gist';
#+end_src

不支持唯一约束和排序。

GiST索引可以创建额外的INCLUDE列

我们知道，我们可以在多个列上建立索引，也可以在完整性约束中使用索引。

索引级属性 这些属性在索引级别上定义：

#+begin_src sql
  select p.name, pg_index_has_property('airports_gist_idx', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backward_scan'
  ])p(name);
#+end_src

GiST索引可用于聚类。

在数据检索方法方面，支持常规（逐行）索引扫描和位图扫描。但是，不允许对GiST索引进行后向扫描。

列级属性

#+begin_src sql
  select p.name,
  pg_index_column_has_property('airports_gist_idx', 1, p.name)
  from unnest(array[
  'orderable', 'search_array', 'search_nulls'
  ])p(name);
#+end_src

禁用所有与排序相关的属性。

NULL值是允许的，但是GiST在处理NULL值时并不有效。我们假定NULL值不会增加边界框；这样的值会被插入到随机子
树中，因此必须在整棵树中进行搜索。

然而，有几个列级属性确实取决于特定的操作符类：

#+begin_src sql
  select p.name,
  pg_index_column_has_property('airports_gist_idx', 1, p.name)
  from unnest(array[
  'returnable', 'distance_orderable'
  ])p(name);
#+end_src

由于叶节点保留完整的索引键，因此允许只对索引进行扫描。

如上所述，该操作符类为近邻搜索提供了距离操作符。到NULL值的距离被认为是NULL；这样的值最后返回（类似于B树中的
NULLS LAST子句）。

但是，对于范围类型（表示线段，即线性几何图形，而不是等值几何图形），没有距离运算符，因此对于为此类类型建立的索引，
该属性是不同的：

#+begin_src sql
  create table reservations(during tsrange);
  create index on reservations using gist(during)

  select p.name,
  pg_index_column_has_property('reservations_during_idx', 1, p.name)
  from unnest(array[
  'returnable', 'distance_orderable'
  ]) p(name);
#+end_src

** 用于全文搜索的RD树

关于全文搜索

全文搜索的目的是从所提供的文档集中选择与搜索查询相匹配的文档。

要进行搜索，需要将文档转换为 tsvector 类型，其中包含词目及其在文档中的位置。词目是转换成适合搜索的格式的单词。默
认情况下，所有单词都被归一化为小写，并截去词尾：

#+begin_src sql
  set default_text_search_config = english;
  select to_tsvector(
   'No one can tell me, nobody knows, ' ||
   'Where the wind comes from, where the wind goes.'
   );
#+end_src

所谓的停顿词（如 "the "或 "from"）会被过滤掉：因为它们出现的频率太高，搜索无法返回任何有意义的结果。当然，所有这
些转换都是可配置的。

搜索查询用另一种类型来表示：tsquery。任何查询都包括一个或多个由逻辑连接词绑定的词素：& (AND)、| (OR)、! (NOT)。
您还可以使用括号定义运算符优先级。

#+begin_src sql
  select to_tsquery('wind & (comes | goes)');
#+end_src

用于全文搜索的唯一操作符是匹配操作符 @@：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gist'
  and opcname='tsvector_ops'
  order by amoostrategy;
#+end_src

该操作符决定文档是否满足查询要求。下面是一个示例：

#+begin_src sql
  select to_tsvector('Where the wind comes from, where the wind goes')
  @@ to_tsvector('wind & coming');
#+end_src

这绝不是对全文搜索的详尽描述，但这些信息应足以让我们了解索引编制的基本原理。

为了快速工作，全文搜索必须有索引支持。由于被索引的不是文档本身，而是 tsvector 值，因此你有两种选择：要么在表达式
上建立索引并执行类型转换，要么为 tsvector 类型添加一个单独的列并为该列建立索引。第一种方法的好处是不会浪费任何空间
来存储 tsvector 值，而实际上并不需要这些值。但它比第二种方法慢，因为索引引擎必须重新检查访问方法返回的所有堆元组。
这意味着，每重新检查一行，tsvector 值都要重新计算一次，而我们很快就会看到，GiST会重新检查所有的行。

让我们举一个简单的例子。我们要创建一个双列表：第一列存储文档，第二列存储 tsvector 值。我们可以使用触发器来更新第二
列 ，但更方便的做法是简单地将这一列声明为已生成：

#+begin_src sql
  create table ts(
   doc text,
   doc_tsv tsvecotr generated always as (
    to_tsvector('pg_catalog.english', doc)
    )stored
    );
    create index ts_gist_idx on ts
    using gist(doc_tsv);
#+end_src

#+begin_comment
 在上面的示例中，我使用了带有单参数的 to_tsvector 函数，并设置了 english default_text_search_config 参数
 来定义全文搜索配置。这个函数的波动类别是 STABLE，因为它隐式地依赖于参数值。但在这里，我应用了另一种明确定义配置
 的变量；这种变量是 IMMUTABLE 的，可以在生成表达式中使用。
#+end_comment

插入一些行
#+begin_src sql
  insert into ts(doc)
  values
  ('Old MacDonald had a farm'),
  ('And on his farm he had some cows'),
  ('Here a moo, there a moo'),
  ('Everywhere a moo moo'),
  ('Old Macdonald had a farm'),
  ('And on his farm he had some chicks'),
  ('Here a cluck, there a cluck'),
  ('Everywhere a cluck cluck'),
  ('Old Macdonald had a farm'),
  ('And on his farm he had some pigs'),
  ('here an oink, there an oink'),
  ('Everywhere an oink oink')
  return doc_tsv;
#+end_src

因此，R 树对于索引文档毫无用处，因为边界框的概念对它们毫无意义。因此，我们使用了 RD 树（俄罗斯娃娃）的改进版。这种
树使用边界集来代替边界框，即包含其子集所有元素的集合。在全文检索中，这种集合包含文档的词目，但在一般情况下，边界集合
可以是任意的。

在索引条目中表示边界集有几种方法。最简单的方法是枚举集合的所有元素。

它可能是这样的

[[./images/vzJXK6.png]]

要找到满足 DOC_TSV @@ TO_TSQUERY('cow')条件的文档，我们需要深入到已知子条目包含 "cow"词素的节点。

这种表示法的问题显而易见。文档中的词目数量可能非常庞大，而页面大小却有限。即使每份特定的文档单独来看没有太多不同的
词目，但在树的上层，它们的联合集仍然可能太大。

[[./images/juU0GL.png]]

全文搜索使用另一种解决方案，即更紧凑的签名树。使用过 Bloom 过滤器的人应该对这种方法不陌生。

每个词素都可以用它的签名来表示：一个特定长度的比特串，其中只有一个比特被置 1。

文档的签名是对该文档中所有词条的签名进行比特 OR 运算的结果。

| Suppose we have        | chick                              | 1000000 |
| assigned the following | cluck                              | 0001000 |
| signatures to our      | cow                                | 0000010 |
| lexemes:               | everywher                          | 0010000 |
|                        | farm                               | 0000100 |
|                        | macdonald                          | 0100000 |
|                        | moo                                | 0000100 |
|                        | oink                               | 0000010 |
|                        | old                                | 0000001 |
|                        | pig                                | 0010000 |
| Then the documents'    | Old MacDonald had a farm           | 0100101 |
| signatures will be as  | And on his farm he had some cows   | 0000110 |
| follows:               | Here a moo, there a moo            | 0000100 |
|                        | Everywhere a moo moo               | 0010100 |
|                        | And on his farm he had some chicks | 1000100 |
|                        | Here a cluck, there a cluck        | 0001000 |
|                        | Everywhere a cluck cluck           | 0011000 |
|                        | And on his farm he had some pigs   | 0010100 |
|                        | Here an oink, there an oink        | 0000010 |
|                        | Everywhere an oink oink            | 0010010 |

索引树可以这样表示

[[./images/5hTISQ.png]]

这种方法的优点显而易见：索引条目大小相同，而且相当小，因此索引相当紧凑。但也有一些缺点。首先，不可能只执行索引扫描，
因为索引不再存储索引键，每个返回的 TID 都必须由表重新检查。准确性也会受到影响：索引可能会返回许多误报，这些误报必
须在重新检查时过滤掉。

让我们再来看看 DIC_TSV @@ TO_TSQYERT(‘cows')条件。查询签名的计算方法与文档签名的计算方法相同；在本例中，查询
签名等于 0000010。一致性函数1必须找到所有在签名中设置了相同位的子节点：

[[./images/cj13sM.png]]

与前面的例子相比，由于存在假阳性命中，这里需要扫描更多的节点。由于签名的容量是有限的，所以在一个大的词集中必然会有
一些词具有相同的签名。在本例中，"cow "和 "oink "就是这样的词素。这意味着同一个签名可以匹配不同的文档；在这里，查
询的签名对应三个文档。

假阳性会降低索引的效率，但丝毫不会影响索引的正确性：因为假阴性是可以保证排除的，所以所需的值不会被漏掉。

显然，签名的大小实际上更大。默认情况下，签名大小为 124 字节（992bits），因此发生碰撞的概率远低于本例。如果需要，
可以使用操作符类参数将签名大小进一步增加到 2000 字节左右：

#+begin_src sql
  create index ... using gist(column tsvector_ops(siglen = size ));
#+end_src

此外，如果值足够小（比页面的十六分之一小一点，一个标准页面大约需要 500 字节），tsvector_ops 运算符类保存在索引叶
页中的是 tsvector 值本身，而不是它们的签名。

为了了解索引是如何在真实数据上运行的，我们可以使用 pgsql-hackers 邮件列表存档。它包含 356125 封电子邮件及其发
送日期、主题、作者姓名和正文。

让我们添加一个 tsvector 类型的列并建立一个索引。在这里，我将三个值（主题、作者和正文）合并为一个向量，以显示文件
可以动态生成，而不必存储在单列中。

#+begin_src sql
  alter table mail_messages add column tsv tsvector
  generated always as ( to_tsvector(
  'pg_catalog.english', subject || ' ' || author || ' ' || body_plain
  )) stored;
#+end_src

#+begin_src sql
  create index mail_gist_idx on mail_message using gist(tsv);
  select pg_size_pertty(pg_relation_size('mail_gist_idx'));
#+end_src

在填充列的过程中，由于词的大小，一定数量的大词被过滤掉了。但索引一旦准备就绪，就可以用于搜索查询：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select *
  from mail_messages
  where tsv @@ to_tsquery('magic & value');
#+end_src

除了满足条件的 898 条记录外，访问方法还返回了 7859 条记录，这些记录将在之后的重新检查中被过滤掉。如果我们增加签名
容量，准确性（以及索引效率）将会提高，但索引大小也会增加：

#+begin_src sql
  drop index mail_message_tsv_idx;
  create index on mail_messages
  using gist(tsv tsvector_ops(siglen=248));

  select pg_size_pretty(pg_relation_size('mail_message_tsv_idx'));

  explain (analyze, costs off, timing off, summary off)
  select *
  from mail_message
  where tsv @@ to_tsquery('magic & value');
#+end_src

属性

我已经介绍了访问方法属性，其中大部分属性对所有操作符类都是一样的。但以下两个列级属性值得一提：

#+begin_src sql
  select p.name
  pg_index_column_has_property('mail_messages_tsv_idx', 1, p.name)
  from unnest(array[
      'returnable', 'distance_orderable'
      ])p(name);
#+end_src

现在只扫描索引是不可能的，因为无法从其签名恢复原始值。在这种特殊情况下完全没问题：tsvector 值只用于搜索，而我们需
要检索文档本身。

tsvector_ops类的排序运算符也没有定义。

** 其他数据类型

我只考虑了两个最突出的例子。它们表明，尽管 GiST 方法是基于平衡树的，但由于不同运算符类中有不同的支持函数实现，它可
以用于各种数据类型。当我们谈论 GiST 索引时，我们必须始终指定操作符类，因为它对索引属性至关重要。

以下是 GiST 访问方法目前支持的其他几种数据类型。

1. 几何数据类型
   除了点之外，GiST 还可以索引其他几何对象：矩形、圆形、多边形。所有这些对象都可以用它们的边界框来表示。
   cube扩展添加了表示多维立方体的同名数据类型。它们使用带有相应维度边框的 R 树进行索引。
2. 范围类型
   PostgreSQL 提供了几种内置的数字和时间范围类型，如 int4range 和 tstzrange。自定义范围类型可使用 CREATE
   TYPE AS RANGE 命令来定义。
   GiST 通过 range_ops 运算符类支持任何范围类型，包括标准范围和自定义范围。对于索引，采用的是一维 R 树：在这种
   情况下，边界框会转换为边界段。
   也支持多范围类型；它们依赖于 multirange_ops 类。边界范围包括作为多范围值一部分的所有范围。
   seg 扩展为区间提供了同名数据类型，其边界定义特别精确。它不被视为区间类型，但实际上是，因此它的索引方式与区间类
   型完全相同。
3. 序数类型
   让我们再次回顾一下 btree_gist 扩展：它为 GiST 方法提供了操作符类，以支持各种序数数据类型，这些数据类型通常由
   B 树建立索引。当其中一列的数据类型不受 B 树支持时，此类操作符类可用于建立多列索引。
4. 网络地址类型
   inet 数据类型内置 GiST 支持，可通过 inet_ops 操作符类实现。
5. 整型数组
   intarray 扩展扩展了整数数组的功能，为其添加了 GiST 支持。有两类操作符。对于小数组，你可以使用 gist__int_ops
   它实现了 RD 树，在索引项中完整地表示了键。对于大型数组，可以使用基于 gist__bigint_ops 运算符类的 RD-tree
   来实现更紧凑但不太精确的签名。
   #+begin_comment
      运算符类名称中多余的下划线属于基本类型数组的名称。例如，除了更常用的 int4[] 符号外，整数数组还可以表示为
      _int4。但没有 _int 和 _bigint 类型。
   #+end_comment
6. Ltree
   ltree 扩展为带有标签的树状结构添加了同名数据类型。GiST 支持通过签名 RD-trees 提供，RD-trees 使用
   gist_ltree_ops 运算符类处理 ltree 值，使用 gist__ltree_ops 运算符类处理 ltree 类型的数组。
7. 键值对存储
   hstore 扩展提供了用于存储键值对的 hstore 数据类型。gist_hstore_ops 运算符类基于签名 RD 树实现了索引支持。
8. Trigrams
   pg_trgm 扩展添加了 gist_trgm_ops 类，该类实现了对比较文本字符串和通配符搜索的索引支持。

* GIN

** 简介
根据其作者的解释，GIN 代表的是一种烈性和不畏艰险的精神，而不是一种酒精饮料。但也有一种正式的解释：这个缩写被扩展为
"Generalized Inverted Index"。

GIN 访问方法专为表示由独立元素组成的非原子值的数据类型而设计（例如，在全文检索中，文档由词条组成）。GiST 将值作为
一个整体进行索引，而 GIN 则不同，它只对其元素进行索引；每个元素都会映射到包含它的所有值。

我们可以把这种方法比作一本书的索引，它包括所有重要的术语，并列出所有提到这些术语的页面。为了方便使用，索引必须按字
母顺序排列，否则就无法快速浏览。类似地，GIN 依靠的是复合值的所有元素都可以排序这一事实；它的主要数据结构是 B 树。

GIN 元素树的实现没有普通 B 树那么复杂：它被设计为包含多次重复的小元素集。

这一假设得出了两个重要结论：
+ 一个元素只能在索引中存储一次。
  每个元素都被映射到一个 TID 列表中，该列表被称为 "posting list"。如果列表较短，则会与元素一起存储；较长的列表
  会被移到单独的过posting tree中，posting tree实际上是一棵 B 树。就像元素树一样，发布列表也是排序的；从用
  户的角度来看，这并不重要，但有助于加快数据访问速度和减少索引大小。

+ 删除树上的元素毫无意义。
  即使某个元素的 TID 列表是空的，同一元素也有可能作为其他值的一部分再次出现。

因此，索引是一棵元素树，其叶条目与平面列表或 TID 树绑定。

与 GiST 和 SP-GiST 访问方法一样，GIN 也可以通过操作符类的简化接口来索引各种数据类型。此类操作符通常会检查索引的
复合值是否与特定元素集相匹配（就像 @@ 操作符会检查文档是否满足全文搜索查询一样）。

要为特定数据类型建立索引，GIN 方法必须能够将复合值分割成元素，对这些元素进行排序，并检查找到的值是否满足查询要求。
这些操作由操作符类的支持函数实现。

** 全文搜索索引

GIN 主要用于加速全文检索，因此我将继续举例说明 GiST 索引。 正如你所猜测的，这里的复合值就是文档，而这些值的元素就
是词条。

让我们在 "Old MacDonald "表上建立一个 GIN 索引：

#+begin_src sql
  create index ts_gin_dx on ts using gin(doc_tsv);
#+end_src

该指数的可能结构如下所示。与前面的插图不同，这里我提供了实际的 TID 值（灰色背景显示），因为它们对于理解算法非常重
要。这些值表明堆元组具有以下 ID：

#+begin_src sql
  select ctid, * from ts;
#+end_src

[[./images/tLm8IB.png]]

请注意这里与普通 B 树索引的一些不同之处。B 树内部节点最左边的键是空的，因为它们实际上是多余的；而在 GIN 索引中，
它们根本不会被存储。因此，对子节点的引用也会被转移。两种索引都使用高键，但在 GIN 索引中，高键位于其合法的最右侧位
置。B 树中的同级节点被绑定到一个双向列表中；而 GIN 使用的是单向列表，因为树的遍历始终只有一个方向。

在这个理论性的例子中，除了 "farm "这个词素外，所有的posting list都适合常规页面。这个词素在多达六个文档中出现，
因此其 ID 被移到了一个单独的树中。

页面布局

GIN 页面布局与 B 树非常相似。我们可以使用 pageinspect 扩展来窥探索引。让我们在存储 pgsql-hackers 邮件列表电
子邮件的表上创建一个 GIN 索引：

#+begin_src sql
  create index mail_gin_idx on mail_messages using gin(tsv);
#+end_src

零页（元页）包含基本统计数据，如元素和其他类型页面的数量：

#+begin_src sql
  select * from gin_metapage_info(get_raw_page('mail_gin_idx', 0));
#+end_src

GIN 使用索引页的特殊空间；例如，该空间存储定义页类型的位：

#+begin_src sql
  select flags, count(*)
  from generate_series(0, 22956) as p,
  gin_page_opaque_info(get_raw_page('mail_gin_idx', p))
  group by flags
  order by 2;
#+end_src

带有元属性的页面当然是元页面。带 data 属性的页面属于posting list，而不带 data 属性的页面则与元素树有关。叶子
页面带有 leaf 属性。

在下一个示例中，另一个 pageinspect 函数会返回存储在树的叶子页中的 TID 信息。这样一棵树的每个条目实际上都是一个
小的 TID 列表，而不是单个 TID：

#+begin_src sql
  select left(tids::text, 60) || '...' tids
  from gin_leafpage_items(get_raw_page('mail_gin_idx', 24));
#+end_src

posting list是有序的，因此可以对其进行压缩（这也是同名属性的由来）。它们存储的不是 6 字节的 TID，而是与前一个
值的差值，差值用可变的字节数表示：1 差值越小，数据占用的空间就越小。

操作类

下面是 GIN 运算符类的支持函数列表：

#+begin_src sql
  select amprocnum, amproc::regproc
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amproc amop on amprocfamily=opfamily
  where amname='gin'
  and opcname='tsvector_ops'
  order by amprocnum;
#+end_src

第一个支持函数比较两个元素（本例中为两个词素）。如果词条是由 B-tree 支持的常规 SQL 类型表示的，那么 GIN 会自动
使用 B-tree 运算符类中定义的比较运算符。

第五个（可选）函数用于部分搜索，检查索引元素是否与搜索关键字部分匹配。在这种特殊情况下，部分搜索包括通过前缀搜索词
目。例如，查询 "c: *"对应于所有以字母 "c "开头的词目。

第二个函数从文档中提取词条，而第三个函数则从搜索查询中提取词条。使用不同的函数是合理的，因为至少文档和查询是由不同
的数据类型表示的，即 tsvector 和 tsquery。此外，搜索查询的函数决定了搜索的执行方式。如果查询要求文档包含特定词
素，那么搜索将仅限于至少包含查询中指定的一个词素的文档。如果没有这样的条件（例如，如果您需要不包含特定词素的文档），
则必须扫描所有文档--当然，这样做的成本要高得多。

#+begin_comment
 如果查询包含任何其他搜索关键字，则首先按这些关键字扫描索引，然后重新检查这些中间结果。因此，无需全面扫描索引。
#+end_comment

第四和第六个函数是一致性函数，用于确定找到的文档是否满足搜索查询。作为输入，第四个函数获取查询中指定的词目在文档中
出现的确切信息。第六个函数是在不确定的情况下运行的，可以在尚不清楚某些词目是否出现在文档中时调用。操作符类不必同时
实现这两个功能：只需提供其中一个即可，但在这种情况下搜索效率可能会受到影响。

tsvector_ops 运算符类只支持一种与搜索查询匹配文档的运算符： @@，它也包含在 GiST 运算符类中。

搜索

让我们来看看 "everywhere | oink "查询的搜索算法，其中两个词项由 OR 运算符连接。首先，支持函数从 tsquery 类型
的搜索字符串中提取词条 "everywher "和 "oink"（搜索键）。

由于查询要求包含特定的词目，因此至少包含一个查询关键字的文档的 TID 会被绑定到一个列表中。为此，与每个搜索关键字相
对应的 TID 会在词条树中被搜索，并被添加到一个公共列表中。索引中存储的所有 TID 都是有序的，因此可以将多个有序的
TID 流合并为一个索引。

请注意，此时键是否通过 AND、OR 或任何其他运算符组合并不重要：搜索引擎处理的是键列表，对搜索查询语义一无所知。

[[./images/T7HZte.png]]

找到的每个与文档相对应的 TID 都要经过一致性函数的检查。正是该功能解释了搜索查询，并只留下满足查询的 TID（或至少可
能满足查询的 TID，且必须由表格重新检查）。

在这种特殊情况下，一致性函数会保留所有 TID：

| TID   | "everywher" | "oink" | consistency function |
|-------+-------------+--------+----------------------|
| (0,4) | ✓           | -      | ✓                    |
| (1,4) | ✓           | -      | ✓                    |
| (2,3) | -           | ✓      | ✓                    |
| (2,4) | ✓           | ✓      | ✓                    |
|-------+-------------+--------+----------------------|

搜索查询可以包含前缀，而不是普通词素。如果应用程序用户在搜索字段中输入单词的首字母，并希望立即得到搜索结果，那么前
缀就非常有用。例如，"pig： *查询将匹配所有包含以 "pig "开头的词素的文档：在这里，我们得到了 "pigs"，如果老麦克
唐纳在他的农场里饲养了鸽子，我们也会得到 "pigeons"。

这种部分搜索使用一个特殊的支持函数将索引词目与搜索关键字进行匹配；除了前缀匹配外，该函数还可以实现其他部分搜索逻辑。

常用词和罕见词

如果搜索的词条在文档中多次出现，创建的 TID 列表就会变得很长，这当然是低效的。幸运的是，如果查询中也包含一些罕见词
目，这种情况通常可以避免。

让我们来看看 "farm & cluck "查询。cluck "词素出现了两次，而 "farm "词素则出现了六次。我们没有将这两个词素同等
对待，也没有根据它们建立完整的 TID 列表，而是将罕见的 "cluck "词素视为必选词素，而将出现频率较高的 "farm "词素
视为可选词素，因为很明显（考虑到查询语义），带有 "farm "词素的文档只有同时包含 "cluck "词素才能满足查询。

因此，我们通过索引扫描确定了第一个包含 "cluck "的文档，其 TID 为 (1,3)。然后，我们必须找出该文档是否也包含
"farm "词素，但可以跳过所有 TID 小于 (1,3) 的文档。由于频繁出现的词素很可能与许多 TID 相对应，它们很有可能被存
储在单独的树中，因此有些页面也可以跳过。在本例中，在 "farm "词条树中的搜索从 (1,3) 开始。

随后的强制词素值将重复这一过程。

显然，这种优化也可以应用于涉及两个以上词性的更复杂搜索场景。该算法按词目出现频率的顺序排列词目，并将其逐一添加到必
选词目列表中，当剩余词目无法保证文档满足查询要求时，算法就会停止。

例如，我们来看看查询 "farm & ( cluck | chick )"。出现频率最低的词素是 "chick"；它被立即添加到必选词素列表中。
为了检查其他词素是否可以被视为可选词素，一致性函数对必选词素取 false，对所有其他词素取 true。函数返回 true AND
(true OR false) = true，这意味着其余词素是 "自给自足 "的，它们中至少有一个必须成为必选词素。

下一个出现频率最低的词素（"cluck"）被添加到列表中，现在一致性函数返回 true AND (false OR false) = false。
因此，"chick "和 "cluck "词素成为必选词素，而 "farm "仍然是可选词素。

[[./images/rc63ga.png]]


posting list 的长度为三，因为必填词目出现了三次：

| TID   | "chick" | "cluck" | "farm" | consistency function |
|-------+---------+---------+--------+----------------------|
| (1,2) | ✓       | -       | ✓      | ✓                    |
| (1,3) | -       | ✓       | -      | -                    |
| (1,4) | -       | ✓       | -      | -                    |
|-------+---------+---------+--------+----------------------|

因此，如果知道词素频率，就可以用最有效的方式合并词素树，从罕见词素开始，跳过那些肯定是多余的频繁词素的页面范围。这
样可以减少调用一致性函数的次数。

为了确保这种优化确实有效，让我们查询一下 pgsql-hackers 档案。我们需要指定两个词目，一个常见词目和一个罕见词目：

#+begin_src sql
  select word, ndoc
  from ts_stat('select tsv frm mail_messages')
  where word in ('wrote', 'tattoo');
#+end_src

事实证明，确实存在一份同时包含这两份内容的文件：

#+begin_src sql
  \timing on
  select count(*) from mail_messages
  where tsv @@ to_tsquery('wrote & tattoo');
#+end_src

该查询的执行速度几乎与搜索单词 "tattoo "一样快：

#+begin_src sql
  select count(*) from mail_messages
  where tsv @@ to_tsquery('tatoo')'
#+end_src

但是，如果我们要找的是 "wrote "这个单词，搜索时间会更长：

#+begin_src sql
  select count(*) from mail_messages
  where tsv @@ to_tsquery('wrote');
#+end_src

插入

GIN 索引不能包含重复内容；如果要添加的元素已经存在于索引中，其 TID 只需添加到已存在元素的posting list或树状
结构中即可。posting list是索引条目中的一部分，它不能占用页面中过多的空间，因此如果超出了分配的空间，列表就会变
成树状。

当一个新元素（或新 TID）被添加到树中时，可能会出现页面溢出；在这种情况下，页面会被一分为二，元素会在它们之间重新
分配。

但是，每个文档通常都包含许多需要索引的词目。因此，即使我们只创建或修改了一个文档，索引树仍然会经历大量的修改。这
就是 GIN 更新相当缓慢的原因。

下图显示了在表中插入 TID 为 (4,1) 的 "Everywhere clucks, moos, and oinks "行后树的状态。扩展了 "cluk"、
"moo "和 "oink "的词条列表；"everywher "的词条列表超过了最大值，被分割成一棵独立的树。

不过，如果一次更新索引以纳入与多个文档相关的更改，那么与连续更改相比，总工作量可能会减少，因为这些文档可能包含一些
共同词目。

这一优化由 fastupdate 存储参数控制。延迟的索引更新会累积到一个无序的待定列表中，该列表实际存储在元素树之外的单独
列表页中。该列表的最大大小由 4MB gin_pending_list_limit 参数或同名索引存储参数确定。

[[./images/vqGXad.png]]

默认情况下，这种延迟更新是启用的，但你应该记住，它们会减慢搜索速度：除了树本身，还必须扫描整个无序词条列表。此外，
插入时间的可预测性也会降低，因为任何变化都可能导致溢出，从而引发昂贵的合并过程。在索引抽真空过程中，合并也可以异步
进行，这在一定程度上缩短了合并时间。

创建新索引 时，元素也是分批添加的，而不是逐个添加，因为这样速度太慢。所有更改不会被保存到磁盘上的无序列表中，而是累
积到一个 64MB 的 maintenance_work_mem 内存块中，一旦该内存块没有可用空间，就会被转移到索引中。为这一操作分配的
内存越多，建立索引的速度就越快。

本章提供的示例证明，就搜索精度而言，GIN 优于 GiST 签名树。因此，GIN 通常被用于全文检索。不过，如果数据更新频繁，
GIN 更新速度慢的问题可能会使 GiST 更受青睐。

限制结果集大小

GIN 访问方法总是以位图的形式返回结果，不可能逐个获取 TID。换句话说，支持 BITMAP SCAN 属性，但不支持 INDEX SCAN
属性。

造成这种限制的原因是延迟更新的无序列表。在索引访问的情况下，该列表会被扫描以建立一个位图，然后用树的数据更新该位图。
如果在搜索过程中无序列表与树合并（作为索引更新的结果或在抽真空过程中），一个相同的值可能会返回两次，这是不可接受的。
但对于位图来说，这不会造成任何问题：相同的位只会被设置两次。

因此，使用 LIMIT 子句和 GIN 索引的效率并不高，因为位图仍需全部建立，这在总成本中占了相当大的比例：

#+begin_src sql
  expalin select * from mail_messages
  where tsv @@ to_tsquery('hacker')
  limit 1000;
#+end_src

因此，GIN 方法提供了一个特殊功能，可以限制索引扫描所返回结果的数量。该限制由 gin_fuzzy_search_limit 参数施加，
默认情况下该参数处于关闭状态。如果启用该参数，索引访问方法将随机跳过某些值，以获得大致指定的行数（因此被称为 "模
糊"）：

#+begin_src sql
  set gin_fuzzy_search_limit=1000;
  select count(*)
  from mail_messages
  where tsv @@ to_tsquery('hacker');
#+end_src

#+begin_src sql
  select count(*)
  from mail_messages
  where tsv @@ to_tsquery('hacker');
#+end_src


#+begin_src sql
  reset gin_fuzzy_search_limig;
#+end_src

请注意，这些查询中没有 LIMIT 子句。这是使用索引扫描和堆扫描获取不同数据的唯一合法方式。规划器对 GIN 索引的这种行
为一无所知，因此在估算成本时不会考虑该参数值。

属性

gin 访问方法的所有属性在所有级别上都是相同的，它们并不依赖于特定的操作符类别。

访问方法属性

#+begin_src sql
  select a.amname, p.name, pg_indexam_has_property(a.oid, p.name)
  from pg_am a, unnest(array[
  'can_order', 'can_unique', 'can_multi_col',
  'can_exclude', 'can_include'
  ])p(name)
  where a.amname='gin';
#+end_src

GIN 既不支持排序，也不支持唯一约束。

支持多列索引，但值得一提的是，其列的顺序并不重要。与普通的 B 树不同，多列 GIN 索引不存储复合键，而是用相应的列编
号扩展独立的元素。

由于 INDEX SCAN 属性不可用，因此无法支持排除限制。

GIN 不支持额外的 INCLUDE 列。这类列在这里没有太大意义，因为几乎不可能使用 GIN 索引作为覆盖：它只包含索引值的单独
元素，而索引值本身存储在表中。

索引级属性

#+begin_src sql
  select p.name, pg_index_has_property('mail_gin_idx', p.name)
  from unnest(array[
  'clusterable', 'index_scan', 'bitmap_scan', 'backwoard_scan'
  ])p(name);
#+end_src

不支持逐个获取结果：索引访问总是返回一个位图。

出于同样的原因，使用 GIN 索引对表重新排序也是没有意义的：位图总是与表中数据的物理布局相对应，不管它是什么。

不支持后向扫描：该功能适用于常规索引扫描，不适用于位图扫描。

列级属性

#+begin_src sql
  select p.name,
  pg_index_column_has_property('mail_gin_idx', 1, p.name)
  from unnest(array[
  'orderable', 'search_array', 'search_nulls',
  'returnable', 'distance_orderable'
  ])p(name);
#+end_src

列级属性都不可用：既不能排序（原因显而易见），也不能使用索引作为覆盖（因为文档本身并不存储在索引中）。也不支持 NULL
（对于非原子类型的元素没有意义）。

GIN的限制和RUM指数

尽管 GIN 功能强大，但它仍无法解决全文检索的所有难题。尽管tsvector 类型确实能指示词目位置，但这些信息并不能进入
索引。因此，GIN 无法用于加快短语搜索，因为短语搜索需要考虑词素的邻近性。此外，搜索引擎通常按照相关性（不管这个词是
什么意思）来返回结果，由于 GIN 不支持排序运算符，因此唯一的解决方案就是为每一行结果计算排序函数，这当然会非常慢。

RUM 访问方法（它的名字让我们怀疑开发人员对 GIN 真正含义的诚意）解决了这些缺点。

这种访问方法是作为扩展提供的；您可以从 PGDG 软件库中下载相应的软件包，或者获取源代码本身。

RUM 基于 GIN，但两者有两个主要区别。首先，RUM 不提供延迟更新，因此除了位图扫描外，它还支持常规的索引扫描，并实现
了排序操作符。其次，RUM 索引键可以扩展附加信息。这一功能在某种程度上类似于 INCLUDE 列，但在这里，附加信息被绑定
到特定的键上。在全文搜索中，RUM 运算符类可将词素出现映射到其在文档中的位置，从而加快短语搜索和结果排序。

这种方法的缺点是更新速度较慢，索引规模较大。此外，由于RUM访问方法是作为扩展提供的，它依赖于通用 WAL 机制，这比
内置日志更慢，而且会产生更大的 WAL。

** Trigrams

pg_trgm 扩展可以通过比较重合的三个字母序列（trigrams）的数量来评估词语的相似性。单词相似性可与全文搜索一起使用，
即使要搜索的单词在输入时有错别字，也能返回一些结果。

gin_trgm_ops 运算符类实现了文本字符串索引。为了找出文本值中的元素，它提取各种三字母子串，而不是单词或词目（只考
虑字母和数字，其他字符忽略不计）。在索引中，三字符串表示为整数。需要注意的是，对于UTF-8 编码中需要 2 至 4 个字节
的非拉丁字符，这种表示法无法解码原始符号。

#+begin_src sql
  create extension pg_trgm;
  select unnest(show_trgm('macdonald')),
         unnest(show_trgm('McDonald'));
#+end_src

该类支持精确和模糊比较字符串和单词的操作符。

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='gin_trgm_ops'
  order by amopstrategy;
#+end_src

为了进行模糊比较，我们可以将字符串之间的距离定义为共同卦数与查询字符串中卦数之比。但如前所述，GIN 不支持排序操作
符，因此该类中的所有操作符都必须是布尔型的。因此，对于执行模糊比较策略的 %、%> 和 %>> 操作符，如果计算出的距离不
超过定义的阈值，一致性函数就会返回 true。

对于 = 和 LIKE 操作符，一致性函数要求值包含查询字符串中的所有三元组。根据正则表达式匹配文档需要进行更复杂的检查。

无论如何，trigram搜索总是模糊的，搜索结果必须重新检查。

**  索引数组

GIN 还支持数组数据类型。通过在数组元素上建立 GIN 索引，可以快速确定一个数组是否与另一个数组重叠或包含在另一个数组
中：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='array_ops'
  order by amopstrategy;
#+end_src

以演示数据库中显示航班信息的路线视图为例。Days_of_week 列是一个数组，包含一周中执行航班的天数。要建立索引，我们首
先要将视图实体化：

#+begin_src sql
  create table routes_tbl as select * from routes;
  create index on routes_tbl using gin(days_of_week);
#+end_src

让我们使用创建的索引来选择在周二、周四和周日起飞的航班。我关闭了顺序扫描；否则，计划器不会为这样一个小表使用索引：

#+begin_src sql
  set enable_seqscan=off;
  explain (costs off) select * from routes_tbl
  where days_of_week=array[2,4,7];
#+end_src

原来，这样的航班共有 11 次：

#+begin_src sql
  select flight_no, departure_airport, arrival_aiport,
  days_of_week
  from routes_tbl
  where days_of_week = array[2,4,7];
#+end_src

建立的索引只包含七个元素：从 1 到 7 的整数，代表一周的天数。

查询的执行与之前展示的全文检索非常相似。在这种特殊情况下，搜索查询由普通数组而非特殊数据类型表示；我们假定索引数组
必须包含所有指定元素。这里的一个重要区别是，相等条件还要求索引数组不包含其他元素。一致性函数通过策略编号知道了这一
要求，但它无法验证是否存在不需要的元素，因此它要求索引引擎通过表格重新检查结果：

#+begin_src sql
  explain (analyze, costs off, timing off, summary off)
  select * from routes_tbl
  where days_of_week=array[2,4,7];
#+end_src

使用附加列扩展 GIN 索引可能很有用。例如，为了搜索每周二、周四和周日从莫斯科起飞的航班，索引缺少 departure_city
列。但常规标量数据类型没有操作符类：

#+begin_src sql
  create index on routes_tbl using gin(days_of_week, departure_city);
#+end_src

这种情况可以通过 btree_gin 扩展来解决。它添加了 GIN 运算符类，通过将标量值表示为包含单个元素的复合值来模拟常规的
B 树处理。

#+begin_src sql
  create extension btree_gin;
  create index on routes_tbl using gin(days_of_week, departure_city);
  explain (costs off)
  select * from routes_tbl
  where days_of_week = array[2,4,7]
  and departure_city='Moscow';
  reset enable_seqscan;
#+end_src

关于 btree_gist 的评论也适用于 btree_gin：在进行比较操作时，B 树的效率要高得多，因此只有在真正需要 GIN 索引时，
才有必要使用 btree_gin 扩展。例如，通过小于或小于等于条件进行的搜索可以在 B 树中通过后向扫描执行，但在 GIN 中则
不行。


** 索引JSON

jsonb_ops 操作符类是默认的操作符类。原始 JSON 文档中的所有键、值和数组元素都会转换成索引项。它能加快检查是否包含
JSON 值 (@>)、是否存在键 (?、?| 和 ?&) 或是否与 JSON 路径匹配 (@? 和 @@) 的查询速度：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='jsonb_ops'
  order by amopstrategy;
#+end_src

让我们把路由视图中的几行转换成 JSON 格式：

#+begin_src sql
  create table routes_jsonb as
  select to_jsonb(t) route
  from (
  select departure_aiport_name, arrival_airport_name, days_of_week
  from routes
  order by flight_no
  limit 4
  );
  select ctid, jsonb_pretty(route) from routes_jsonb;
#+end_src

#+begin_src sql
  create index on routes_jsonb using gin(route);
#+end_src

创建的索引如下所示：

[[./images/AWQKPK.png]]

让我们考虑一个带条件路由 @> '{"days_of_week"： [6]}'，它会选择包含指定路径（即周六执行的航班）的 JSON 文档。

支持函数从搜索查询的 JSON 值中提取搜索键： 支持函数从搜索查询的值中提取搜索关键字："days_of_week "和 "6"。
对于包含策略，该函数要求所有搜索键都可用，但结果仍需由表格重新检查：从索引的角度来看，指定路径也可以对应于类似
{"days_of_week"： [2], "foo"： [6]}.

jsonb_path_ops操作类

第二个类名为 jsonb_path_ops，包含的操作符较少：

#+begin_src sql
  select amopopr::regoperator, oprcode::regproc, amopstrategy
  from pg_am am
  join pg_opclass opc on opcmethod=am.oid
  join pg_amop amop on amopfamily=opcfamily
  join pg_operator opr on opr.oid=amopopr
  where amname='gin'
  and opcname='jsonb_path_ops'
  order by amopstrategy;
#+end_src

如果使用该类，索引将包含从文档根指向所有值和所有数组元素的路径，而不是孤立的 JSON 片段。这将使搜索更精确、更高效，
但对于使用独立键而非路径表示的参数的操作，速度不会提高。

由于路径可能相当长，因此真正被索引的不是路径本身，而是其哈希值。

让我们使用该操作符类为同一个表创建一个索引：

#+begin_src sql
  create index on routes_jsonb using gin(route jsonb_path_ops);
#+end_src

创建的索引可以用以下树形结构表示：

[[./images/iE6aBN.png]]


当执行具有相同条件路由 @> '{"days_of_week"： [6]}"时，支持函数提取的是整个路径 "days_of_week, 6"，而不是其
单独的组成部分。这样就能立即在元素树中找到两个匹配文档的 TID。

显然，这些条目将由一致性函数进行检查，然后由索引引擎重新检查（例如，排除哈希碰撞）。但是，通过树进行搜索的效率要高
得多，因此，如果 jsonb_path_ops 类的运算符提供的索引支持足以满足查询的需要，那么选择 jsonb_path_ops 类是有道
理的。


** 索引其他数据类型

还通过扩展为以下数据类型提供 GIN 支持：

+ 整型数组intarray 扩展为整数数组添加了 gin__int_ops 操作符类。它与标准的 array_ops 运算符类非常相似，但它支持
  匹配运算符 @@，可将文档与搜索查询进行匹配。
+ 键值存储 hstore 扩展实现了键值对的存储，并提供了 gin_hstore_ops 运算符类。键和值都有索引。
+ JSON查询语言 外部 jsquery 扩展为 JSON 提供了自己的查询语言和 GIN 索引支持。

#+begin_comment
 在采用 SQL:2016 标准并在 PostgreSQL 中实现 SQL/JSON 查询语言后，标准内置功能似乎是更好的选择。
#+end_comment





